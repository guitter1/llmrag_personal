{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a1c4d97-6786-4470-a044-03973983434b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import faiss\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "loader = PyPDFLoader(\"ai_industry.pdf\")\n",
    "docs = loader.load()\n",
    "\n",
    "recursive_text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "splits = recursive_text_splitter.split_documents(docs)\n",
    "\n",
    "with pdfplumber.open(\"ai_industry.pdf\") as pdf:\n",
    "    all_tables = []  \n",
    "    \n",
    "    for page_num, page in enumerate(pdf.pages):\n",
    "        tables = page.extract_tables()  \n",
    "        \n",
    "        for table in tables:\n",
    "            df = pd.DataFrame(table[1:], columns=table[0])\n",
    "            all_tables.append((page_num, df)) \n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "vectorstore = FAISS.from_documents(documents=splits, embedding=embeddings)\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "\n",
    "# 프롬프트 파일 로드\n",
    "prompts = {}\n",
    "prompt_folder = \"C:/Users/hispa/promptengineering/Prompts\"\n",
    "for filename in os.listdir(prompt_folder):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        with open(os.path.join(prompt_folder, filename), \"r\", encoding=\"utf-8\") as file:\n",
    "            prompts[filename] = file.read()\n",
    "\n",
    "class DebugPassThrough(RunnablePassthrough):\n",
    "    def invoke(self, *args, **kwargs):\n",
    "        output = super().invoke(*args, **kwargs)\n",
    "        print(\"Debug Output:\", output)\n",
    "        return output\n",
    "\n",
    "class ContextToText(RunnablePassthrough):\n",
    "    def invoke(self, inputs, config=None, **kwargs):  \n",
    "        # context의 각 문서를 문자열로 결합\n",
    "        context_text = \"\\n\".join([doc.page_content for doc in inputs[\"context\"]])\n",
    "        # 전체 프롬프트를 단일 문자열로 생성\n",
    "        full_prompt = f\"Context: {context_text}\\n\\nQuestion: {inputs['question']}\"\n",
    "        return full_prompt\n",
    "\n",
    "# 결과 저장 디렉토리 \n",
    "result_folder = \"C:/Users/hispa/promptengineering/Results\"\n",
    "os.makedirs(result_folder, exist_ok=True)\n",
    "\n",
    "rag_chain_debug = DebugPassThrough() | ContextToText() | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94410ec2-78d9-4947-b44d-39dfa959f6d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "질문을 입력하세요 (종료하려면 'exit' 입력):  가트너가 뭐야?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 1: prompt1.txt\n",
      "Debug Output: {'context': [Document(metadata={'source': 'ai_industry.pdf', 'page': 18}, page_content='£AI 에이전트 활성화를 위해 향상된 메모리 성능을 갖춘 대체 아키텍처 채택 필요n이스라엘의 AI 스타트업 AI21의 오리 고센(Ori Goshen) CEO가 AI 에이전트를 활성화하려면 트랜스포머(Transformer)* 이외의 새로운 아키텍처**가 필요하다고 주장* 문장 속 단어와 같은 순차 데이터 내의 관계를 추적해 맥락과 의미를 학습하는 신경망 ** AI 시스템이 데이터를 처리하고 학습하기 위한 신경망의 전체적인 구조와 설계 방식을 의미 ∙트랜스포머는 현재 AI 모델 개발에서 가장 많이 사용되는 아키텍처이지만, 다중 에이전트 생태계 조성 측면에서는 한계를 내포∙트랜스포머 아키텍처는 처리하는 컨텍스트가 길수록 속도가 느리고 연산 비용이 많이 드는데, AI 에이전트는 LLM을 여러 차례 호출해야 하고 각 단계에서 광범위한 컨텍스트를 사용하는 경우가 많아 처리 과정에서 지연이 발생n고센 CEO는 ‘맘바(Mamba)’와 ‘잠바(Jamba)’와 같은 대체 아키텍처를 활용하면 AI 에이전트를 더 효율적이고 저렴하게 만들 수 있다고 강조∙카네기멜론⼤와 프린스턴⼤ 연구진이 개발한 맘바는 트랜스포머 모델의 핵심인 어텐션(Attention)* 메커니즘 대신 데이터를 우선순위에 따라 정리하고 입력에 가중치를 부여해 메모리 사용을 최적화* 입력된 데이터 간 연관성을 파악해 상호작용을 계산하는 메커니즘 ∙미스트랄이 2024년 7월 ‘코드스트랄(Codestral) 맘바 7B’를, UAE의 AI 기업 팔콘(Falcon)이 8월 ‘팔콘 맘바 7B’를 출시하는 등, 최근 오픈소스 AI 개발자 사이에서 맘바의 인기가 높아지는 추세∙AI21 역시 맘바 아키텍처를 토대로 더 빠른 추론 시간과 더 긴 컨텍스트를 지원하는 잠바 아키텍처를 활용해 기반모델을 개발n고센 CEO는 AI 에이전트가 최근 들어서야 부상하고 있으며 대다수 AI 에이전트가 아직 상용화되지 않은 이유가 트랜스포머로 구축된 LLM의 한계 때문이라고 지적∙AI 에이전트가 상용화되려면 데이터 간 연관성을 파악해 확률적으로 가장'), Document(metadata={'source': 'ai_industry.pdf', 'page': 21}, page_content='1. 정책/법제  2. 기업/산업 3. 기술/연구  4. 인력/교육\\n19\\n가트너 예측, AI로 인해 엔지니어링 인력의 80%가 역량 향상 필요n가트너에 따르면 생성AI의 도입으로 중장기적으로 소프트웨어 엔지니어링에서 데이터 과학 및 AI/ML 역량의 중요성이 커지면서 AI 엔지니어의 수요가 늘어날 전망n기업들은 AI 엔지니어를 지원하고 기업 내 AI 통합을 촉진하기 위해 AI 개발자 플랫폼에 대한 투자를 강화할 필요\\nKEY Contents'), Document(metadata={'source': 'ai_industry.pdf', 'page': 18}, page_content='역시 맘바 아키텍처를 토대로 더 빠른 추론 시간과 더 긴 컨텍스트를 지원하는 잠바 아키텍처를 활용해 기반모델을 개발n고센 CEO는 AI 에이전트가 최근 들어서야 부상하고 있으며 대다수 AI 에이전트가 아직 상용화되지 않은 이유가 트랜스포머로 구축된 LLM의 한계 때문이라고 지적∙AI 에이전트가 상용화되려면 데이터 간 연관성을 파악해 확률적으로 가장 그럴듯한 답변을 생성하는 LLM의 신뢰성을 높여야 하며, 필요한 수준의 신뢰성 보장을 위해서는 추가적인 요소의 통합이 필요 ∙최근 서비스나우(ServiceNow), 세일즈포스 등 여러 기업이 AI 에이전트나 에이전트 구축을 지원하는 플랫폼을 출시하는 추세로, 고센 CEO는 이러한 추세가 적절한 기반모델과 아키텍처를 조합함으로써 더욱 확산될 것으로 예상☞ 출처: Venturebeat, AI21 CEO says transformers not right for AI agents due to error perpetuation, 2024.10.11.')], 'question': \"prompt1\\n\\nsystem\\n아래의 지침에 따라 행동해\\n\\n#역할\\n-주어진 문서를 기반으로 정확한 정보를 제공하는 AI\\n\\n#톤\\n-전문적\\n\\n#주의사항 \\n-문서에 명시되지 않은 사실은 답변에 포함하지 않음\\n-답변에는 문서의 표현을 최소 80% 이상 포함하되, 문맥의 일관성을 유지해야 함\\n-사용자가 문서에 없는 내용을 질문할 경우, '해당 내용은 문서에 포함되지 않았습니다'로 답변\\n\\nhuman\\n\\nQuestion: {question} \\n\\nContext: {context} \\n\\nAnswer:\\n\\n\\n\\n\\n\\n\\n\\n가트너가 뭐야?\"}\n",
      "Response for prompt1.txt:\n",
      "해당 내용은 문서에 포함되지 않았습니다.\n",
      "\n",
      "Prompt 2: prompt2.txt\n",
      "Debug Output: {'context': [Document(metadata={'source': 'ai_industry.pdf', 'page': 18}, page_content='£AI 에이전트 활성화를 위해 향상된 메모리 성능을 갖춘 대체 아키텍처 채택 필요n이스라엘의 AI 스타트업 AI21의 오리 고센(Ori Goshen) CEO가 AI 에이전트를 활성화하려면 트랜스포머(Transformer)* 이외의 새로운 아키텍처**가 필요하다고 주장* 문장 속 단어와 같은 순차 데이터 내의 관계를 추적해 맥락과 의미를 학습하는 신경망 ** AI 시스템이 데이터를 처리하고 학습하기 위한 신경망의 전체적인 구조와 설계 방식을 의미 ∙트랜스포머는 현재 AI 모델 개발에서 가장 많이 사용되는 아키텍처이지만, 다중 에이전트 생태계 조성 측면에서는 한계를 내포∙트랜스포머 아키텍처는 처리하는 컨텍스트가 길수록 속도가 느리고 연산 비용이 많이 드는데, AI 에이전트는 LLM을 여러 차례 호출해야 하고 각 단계에서 광범위한 컨텍스트를 사용하는 경우가 많아 처리 과정에서 지연이 발생n고센 CEO는 ‘맘바(Mamba)’와 ‘잠바(Jamba)’와 같은 대체 아키텍처를 활용하면 AI 에이전트를 더 효율적이고 저렴하게 만들 수 있다고 강조∙카네기멜론⼤와 프린스턴⼤ 연구진이 개발한 맘바는 트랜스포머 모델의 핵심인 어텐션(Attention)* 메커니즘 대신 데이터를 우선순위에 따라 정리하고 입력에 가중치를 부여해 메모리 사용을 최적화* 입력된 데이터 간 연관성을 파악해 상호작용을 계산하는 메커니즘 ∙미스트랄이 2024년 7월 ‘코드스트랄(Codestral) 맘바 7B’를, UAE의 AI 기업 팔콘(Falcon)이 8월 ‘팔콘 맘바 7B’를 출시하는 등, 최근 오픈소스 AI 개발자 사이에서 맘바의 인기가 높아지는 추세∙AI21 역시 맘바 아키텍처를 토대로 더 빠른 추론 시간과 더 긴 컨텍스트를 지원하는 잠바 아키텍처를 활용해 기반모델을 개발n고센 CEO는 AI 에이전트가 최근 들어서야 부상하고 있으며 대다수 AI 에이전트가 아직 상용화되지 않은 이유가 트랜스포머로 구축된 LLM의 한계 때문이라고 지적∙AI 에이전트가 상용화되려면 데이터 간 연관성을 파악해 확률적으로 가장'), Document(metadata={'source': 'ai_industry.pdf', 'page': 21}, page_content='1. 정책/법제  2. 기업/산업 3. 기술/연구  4. 인력/교육\\n19\\n가트너 예측, AI로 인해 엔지니어링 인력의 80%가 역량 향상 필요n가트너에 따르면 생성AI의 도입으로 중장기적으로 소프트웨어 엔지니어링에서 데이터 과학 및 AI/ML 역량의 중요성이 커지면서 AI 엔지니어의 수요가 늘어날 전망n기업들은 AI 엔지니어를 지원하고 기업 내 AI 통합을 촉진하기 위해 AI 개발자 플랫폼에 대한 투자를 강화할 필요\\nKEY Contents'), Document(metadata={'source': 'ai_industry.pdf', 'page': 18}, page_content='역시 맘바 아키텍처를 토대로 더 빠른 추론 시간과 더 긴 컨텍스트를 지원하는 잠바 아키텍처를 활용해 기반모델을 개발n고센 CEO는 AI 에이전트가 최근 들어서야 부상하고 있으며 대다수 AI 에이전트가 아직 상용화되지 않은 이유가 트랜스포머로 구축된 LLM의 한계 때문이라고 지적∙AI 에이전트가 상용화되려면 데이터 간 연관성을 파악해 확률적으로 가장 그럴듯한 답변을 생성하는 LLM의 신뢰성을 높여야 하며, 필요한 수준의 신뢰성 보장을 위해서는 추가적인 요소의 통합이 필요 ∙최근 서비스나우(ServiceNow), 세일즈포스 등 여러 기업이 AI 에이전트나 에이전트 구축을 지원하는 플랫폼을 출시하는 추세로, 고센 CEO는 이러한 추세가 적절한 기반모델과 아키텍처를 조합함으로써 더욱 확산될 것으로 예상☞ 출처: Venturebeat, AI21 CEO says transformers not right for AI agents due to error perpetuation, 2024.10.11.')], 'question': 'prompt2\\n\\nsystem\\n아래의 지침에 따라 행동해\\n\\n#역할\\n-주어진 문서를 기반으로 정보를 제공하는 AI\\n\\n#톤\\n-중립적\\n\\n#주의사항\\n1. 가능하다면 100자 이내로 답변하되, 중요 정보를 누락하면 안 됨\\n2. 1번을 만족하기 위해 내용을 요약하거나 재구성해도 됨\\n3. 문서에 없는 내용이라도 문서 내용을 기반으로 답변하려고 노력하되, 문서에 직접 명시되지 않았음을 언급해야 함\\n\\n\\nhuman\\n\\nQuestion: {question} \\n\\nContext: {context} \\n\\nAnswer:\\n\\n가트너가 뭐야?'}\n",
      "Response for prompt2.txt:\n",
      "가트너(Gartner)는 IT 및 기술 관련 리서치와 자문 서비스를 제공하는 글로벌 기업으로, 시장 트렌드와 기술 예측을 분석하여 기업에 통찰을 제공합니다.\n",
      "\n",
      "Prompt 3: prompt3.txt\n",
      "Debug Output: {'context': [Document(metadata={'source': 'ai_industry.pdf', 'page': 18}, page_content='£AI 에이전트 활성화를 위해 향상된 메모리 성능을 갖춘 대체 아키텍처 채택 필요n이스라엘의 AI 스타트업 AI21의 오리 고센(Ori Goshen) CEO가 AI 에이전트를 활성화하려면 트랜스포머(Transformer)* 이외의 새로운 아키텍처**가 필요하다고 주장* 문장 속 단어와 같은 순차 데이터 내의 관계를 추적해 맥락과 의미를 학습하는 신경망 ** AI 시스템이 데이터를 처리하고 학습하기 위한 신경망의 전체적인 구조와 설계 방식을 의미 ∙트랜스포머는 현재 AI 모델 개발에서 가장 많이 사용되는 아키텍처이지만, 다중 에이전트 생태계 조성 측면에서는 한계를 내포∙트랜스포머 아키텍처는 처리하는 컨텍스트가 길수록 속도가 느리고 연산 비용이 많이 드는데, AI 에이전트는 LLM을 여러 차례 호출해야 하고 각 단계에서 광범위한 컨텍스트를 사용하는 경우가 많아 처리 과정에서 지연이 발생n고센 CEO는 ‘맘바(Mamba)’와 ‘잠바(Jamba)’와 같은 대체 아키텍처를 활용하면 AI 에이전트를 더 효율적이고 저렴하게 만들 수 있다고 강조∙카네기멜론⼤와 프린스턴⼤ 연구진이 개발한 맘바는 트랜스포머 모델의 핵심인 어텐션(Attention)* 메커니즘 대신 데이터를 우선순위에 따라 정리하고 입력에 가중치를 부여해 메모리 사용을 최적화* 입력된 데이터 간 연관성을 파악해 상호작용을 계산하는 메커니즘 ∙미스트랄이 2024년 7월 ‘코드스트랄(Codestral) 맘바 7B’를, UAE의 AI 기업 팔콘(Falcon)이 8월 ‘팔콘 맘바 7B’를 출시하는 등, 최근 오픈소스 AI 개발자 사이에서 맘바의 인기가 높아지는 추세∙AI21 역시 맘바 아키텍처를 토대로 더 빠른 추론 시간과 더 긴 컨텍스트를 지원하는 잠바 아키텍처를 활용해 기반모델을 개발n고센 CEO는 AI 에이전트가 최근 들어서야 부상하고 있으며 대다수 AI 에이전트가 아직 상용화되지 않은 이유가 트랜스포머로 구축된 LLM의 한계 때문이라고 지적∙AI 에이전트가 상용화되려면 데이터 간 연관성을 파악해 확률적으로 가장'), Document(metadata={'source': 'ai_industry.pdf', 'page': 21}, page_content='1. 정책/법제  2. 기업/산업 3. 기술/연구  4. 인력/교육\\n19\\n가트너 예측, AI로 인해 엔지니어링 인력의 80%가 역량 향상 필요n가트너에 따르면 생성AI의 도입으로 중장기적으로 소프트웨어 엔지니어링에서 데이터 과학 및 AI/ML 역량의 중요성이 커지면서 AI 엔지니어의 수요가 늘어날 전망n기업들은 AI 엔지니어를 지원하고 기업 내 AI 통합을 촉진하기 위해 AI 개발자 플랫폼에 대한 투자를 강화할 필요\\nKEY Contents'), Document(metadata={'source': 'ai_industry.pdf', 'page': 18}, page_content='역시 맘바 아키텍처를 토대로 더 빠른 추론 시간과 더 긴 컨텍스트를 지원하는 잠바 아키텍처를 활용해 기반모델을 개발n고센 CEO는 AI 에이전트가 최근 들어서야 부상하고 있으며 대다수 AI 에이전트가 아직 상용화되지 않은 이유가 트랜스포머로 구축된 LLM의 한계 때문이라고 지적∙AI 에이전트가 상용화되려면 데이터 간 연관성을 파악해 확률적으로 가장 그럴듯한 답변을 생성하는 LLM의 신뢰성을 높여야 하며, 필요한 수준의 신뢰성 보장을 위해서는 추가적인 요소의 통합이 필요 ∙최근 서비스나우(ServiceNow), 세일즈포스 등 여러 기업이 AI 에이전트나 에이전트 구축을 지원하는 플랫폼을 출시하는 추세로, 고센 CEO는 이러한 추세가 적절한 기반모델과 아키텍처를 조합함으로써 더욱 확산될 것으로 예상☞ 출처: Venturebeat, AI21 CEO says transformers not right for AI agents due to error perpetuation, 2024.10.11.')], 'question': 'prompt3\\n\\nsystem\\n아래의 지침에 따라 행동해\\n\\n#역할\\n- 소프트웨어 정책연구소(SPRi)의 홍보담당자 \\n\\n#톤\\n-친절함\\n-정중함\\n\\n#주의사항\\n1. 답변은 주어진 문서에 근거해야 함\\n2. 전문용어를 피하고 예시를 들어 대중들이 이해하기 쉽게 대답해야 함\\n3. 사용자가 문서에 포함되지 않는 내용을 질문하면,  문서에 없다는 답변과 함께 SPRi에 문의하도록 함\\n4. 3의 문의는 아래의 홈페이지 주소, 이메일주소, 전화번호를 안내함\\n홈페이지 : https://spri.kr/\\nAI정책연구실(hs.lee@spri.kr, 031-739-7333)\\n\\nhuman\\n\\nQuestion: {question} \\n\\nContext: {context} \\n\\nAnswer:\\n가트너가 뭐야?'}\n",
      "Response for prompt3.txt:\n",
      "가트너(Gartner)는 정보 기술 및 서비스 분야의 연구 및 자문 회사로, 기업들이 IT 관련 결정을 내리는 데 도움을 주기 위해 시장 조사, 분석 및 예측을 제공합니다. 예를 들어, 가트너는 최근 생성AI의 도입으로 인해 소프트웨어 엔지니어링에서 데이터 과학 및 인공지능(AI) 기술의 중요성이 증가할 것이라고 예측했습니다. 이러한 예측은 기업들이 AI 엔지니어의 수요를 늘리기 위한 전략을 세우는 데 유용하게 활용될 수 있습니다. 더 궁금한 점이 있으시면 SPRi에 문의해 주세요. \n",
      "\n",
      "홈페이지: [https://spri.kr/](https://spri.kr/)  \n",
      "이메일: hs.lee@spri.kr  \n",
      "전화번호: 031-739-7333\n",
      "========================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "질문을 입력하세요 (종료하려면 'exit' 입력):  AI21의 CEO에 대해 설명해줘\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 1: prompt1.txt\n",
      "Debug Output: {'context': [Document(metadata={'source': 'ai_industry.pdf', 'page': 18}, page_content='SPRi AI Brief |  2024-11월호\\n16\\nAI21 CEO, AI 에이전트에 트랜스포머 아키텍처의 대안 필요성 강조n이스라엘 AI 스타트업 AI21의 오리 고센 CEO는 AI 모델 개발에 주로 활용되는 트랜스포머 아키텍처가 느린 속도와 과도한 연산 비용으로 인해 AI 에이전트에 부적합하다고 지적n고센 CEO는 AI 에이전트를 활성화하려면 메모리 사용을 최적화하여 효율적 연산과 비용 절감을 지원하는 맘바나 잠바와 같은 대체 아키텍처에 주목해야 한다고 주장   \\nKEY Contents'), Document(metadata={'source': 'ai_industry.pdf', 'page': 4}, page_content='SPRi AI Brief |  2024-11월호\\n2\\n미국 백악관 예산관리국, 정부의 책임 있는 AI 조달을 위한 지침 발표n미국 백악관 예산관리국이 바이든 대통령의 AI 행정명령에 따라 연방정부의 책임 있는 AI 조달을 지원하기 위한 지침을 발표 n지침은 정부 기관의 AI 조달 시 AI의 위험과 성과를 관리할 수 있는 모범 관행의 수립 및 최상의 AI 솔루션을 사용하기 위한 공급업체 시장의 경쟁 보장, 정부 기관 간 협업을 요구  \\nKEY Contents'), Document(metadata={'source': 'ai_industry.pdf', 'page': 18}, page_content='£AI 에이전트 활성화를 위해 향상된 메모리 성능을 갖춘 대체 아키텍처 채택 필요n이스라엘의 AI 스타트업 AI21의 오리 고센(Ori Goshen) CEO가 AI 에이전트를 활성화하려면 트랜스포머(Transformer)* 이외의 새로운 아키텍처**가 필요하다고 주장* 문장 속 단어와 같은 순차 데이터 내의 관계를 추적해 맥락과 의미를 학습하는 신경망 ** AI 시스템이 데이터를 처리하고 학습하기 위한 신경망의 전체적인 구조와 설계 방식을 의미 ∙트랜스포머는 현재 AI 모델 개발에서 가장 많이 사용되는 아키텍처이지만, 다중 에이전트 생태계 조성 측면에서는 한계를 내포∙트랜스포머 아키텍처는 처리하는 컨텍스트가 길수록 속도가 느리고 연산 비용이 많이 드는데, AI 에이전트는 LLM을 여러 차례 호출해야 하고 각 단계에서 광범위한 컨텍스트를 사용하는 경우가 많아 처리 과정에서 지연이 발생n고센 CEO는 ‘맘바(Mamba)’와 ‘잠바(Jamba)’와 같은 대체 아키텍처를 활용하면 AI 에이전트를 더 효율적이고 저렴하게 만들 수 있다고 강조∙카네기멜론⼤와 프린스턴⼤ 연구진이 개발한 맘바는 트랜스포머 모델의 핵심인 어텐션(Attention)* 메커니즘 대신 데이터를 우선순위에 따라 정리하고 입력에 가중치를 부여해 메모리 사용을 최적화* 입력된 데이터 간 연관성을 파악해 상호작용을 계산하는 메커니즘 ∙미스트랄이 2024년 7월 ‘코드스트랄(Codestral) 맘바 7B’를, UAE의 AI 기업 팔콘(Falcon)이 8월 ‘팔콘 맘바 7B’를 출시하는 등, 최근 오픈소스 AI 개발자 사이에서 맘바의 인기가 높아지는 추세∙AI21 역시 맘바 아키텍처를 토대로 더 빠른 추론 시간과 더 긴 컨텍스트를 지원하는 잠바 아키텍처를 활용해 기반모델을 개발n고센 CEO는 AI 에이전트가 최근 들어서야 부상하고 있으며 대다수 AI 에이전트가 아직 상용화되지 않은 이유가 트랜스포머로 구축된 LLM의 한계 때문이라고 지적∙AI 에이전트가 상용화되려면 데이터 간 연관성을 파악해 확률적으로 가장')], 'question': \"prompt1\\n\\nsystem\\n아래의 지침에 따라 행동해\\n\\n#역할\\n-주어진 문서를 기반으로 정확한 정보를 제공하는 AI\\n\\n#톤\\n-전문적\\n\\n#주의사항 \\n-문서에 명시되지 않은 사실은 답변에 포함하지 않음\\n-답변에는 문서의 표현을 최소 80% 이상 포함하되, 문맥의 일관성을 유지해야 함\\n-사용자가 문서에 없는 내용을 질문할 경우, '해당 내용은 문서에 포함되지 않았습니다'로 답변\\n\\nhuman\\n\\nQuestion: {question} \\n\\nContext: {context} \\n\\nAnswer:\\n\\n\\n\\n\\n\\n\\n\\nAI21의 CEO에 대해 설명해줘\"}\n",
      "Response for prompt1.txt:\n",
      "AI21의 CEO는 오리 고센(Ori Goshen)입니다. 그는 AI 모델 개발에 주로 활용되는 트랜스포머 아키텍처가 느린 속도와 과도한 연산 비용으로 인해 AI 에이전트에 부적합하다고 지적하고 있습니다. 고센 CEO는 AI 에이전트를 활성화하기 위해 메모리 사용을 최적화하여 효율적 연산과 비용 절감을 지원하는 대체 아키텍처인 '맘바(Mamba)'와 '잠바(Jamba)'에 주목해야 한다고 주장하고 있습니다. AI21은 이러한 아키텍처를 활용하여 더 빠른 추론 시간과 더 긴 컨텍스트를 지원하는 기반모델을 개발하고 있습니다.\n",
      "\n",
      "Prompt 2: prompt2.txt\n",
      "Debug Output: {'context': [Document(metadata={'source': 'ai_industry.pdf', 'page': 18}, page_content='SPRi AI Brief |  2024-11월호\\n16\\nAI21 CEO, AI 에이전트에 트랜스포머 아키텍처의 대안 필요성 강조n이스라엘 AI 스타트업 AI21의 오리 고센 CEO는 AI 모델 개발에 주로 활용되는 트랜스포머 아키텍처가 느린 속도와 과도한 연산 비용으로 인해 AI 에이전트에 부적합하다고 지적n고센 CEO는 AI 에이전트를 활성화하려면 메모리 사용을 최적화하여 효율적 연산과 비용 절감을 지원하는 맘바나 잠바와 같은 대체 아키텍처에 주목해야 한다고 주장   \\nKEY Contents'), Document(metadata={'source': 'ai_industry.pdf', 'page': 4}, page_content='SPRi AI Brief |  2024-11월호\\n2\\n미국 백악관 예산관리국, 정부의 책임 있는 AI 조달을 위한 지침 발표n미국 백악관 예산관리국이 바이든 대통령의 AI 행정명령에 따라 연방정부의 책임 있는 AI 조달을 지원하기 위한 지침을 발표 n지침은 정부 기관의 AI 조달 시 AI의 위험과 성과를 관리할 수 있는 모범 관행의 수립 및 최상의 AI 솔루션을 사용하기 위한 공급업체 시장의 경쟁 보장, 정부 기관 간 협업을 요구  \\nKEY Contents'), Document(metadata={'source': 'ai_industry.pdf', 'page': 18}, page_content='£AI 에이전트 활성화를 위해 향상된 메모리 성능을 갖춘 대체 아키텍처 채택 필요n이스라엘의 AI 스타트업 AI21의 오리 고센(Ori Goshen) CEO가 AI 에이전트를 활성화하려면 트랜스포머(Transformer)* 이외의 새로운 아키텍처**가 필요하다고 주장* 문장 속 단어와 같은 순차 데이터 내의 관계를 추적해 맥락과 의미를 학습하는 신경망 ** AI 시스템이 데이터를 처리하고 학습하기 위한 신경망의 전체적인 구조와 설계 방식을 의미 ∙트랜스포머는 현재 AI 모델 개발에서 가장 많이 사용되는 아키텍처이지만, 다중 에이전트 생태계 조성 측면에서는 한계를 내포∙트랜스포머 아키텍처는 처리하는 컨텍스트가 길수록 속도가 느리고 연산 비용이 많이 드는데, AI 에이전트는 LLM을 여러 차례 호출해야 하고 각 단계에서 광범위한 컨텍스트를 사용하는 경우가 많아 처리 과정에서 지연이 발생n고센 CEO는 ‘맘바(Mamba)’와 ‘잠바(Jamba)’와 같은 대체 아키텍처를 활용하면 AI 에이전트를 더 효율적이고 저렴하게 만들 수 있다고 강조∙카네기멜론⼤와 프린스턴⼤ 연구진이 개발한 맘바는 트랜스포머 모델의 핵심인 어텐션(Attention)* 메커니즘 대신 데이터를 우선순위에 따라 정리하고 입력에 가중치를 부여해 메모리 사용을 최적화* 입력된 데이터 간 연관성을 파악해 상호작용을 계산하는 메커니즘 ∙미스트랄이 2024년 7월 ‘코드스트랄(Codestral) 맘바 7B’를, UAE의 AI 기업 팔콘(Falcon)이 8월 ‘팔콘 맘바 7B’를 출시하는 등, 최근 오픈소스 AI 개발자 사이에서 맘바의 인기가 높아지는 추세∙AI21 역시 맘바 아키텍처를 토대로 더 빠른 추론 시간과 더 긴 컨텍스트를 지원하는 잠바 아키텍처를 활용해 기반모델을 개발n고센 CEO는 AI 에이전트가 최근 들어서야 부상하고 있으며 대다수 AI 에이전트가 아직 상용화되지 않은 이유가 트랜스포머로 구축된 LLM의 한계 때문이라고 지적∙AI 에이전트가 상용화되려면 데이터 간 연관성을 파악해 확률적으로 가장')], 'question': 'prompt2\\n\\nsystem\\n아래의 지침에 따라 행동해\\n\\n#역할\\n-주어진 문서를 기반으로 정보를 제공하는 AI\\n\\n#톤\\n-중립적\\n\\n#주의사항\\n1. 가능하다면 100자 이내로 답변하되, 중요 정보를 누락하면 안 됨\\n2. 1번을 만족하기 위해 내용을 요약하거나 재구성해도 됨\\n3. 문서에 없는 내용이라도 문서 내용을 기반으로 답변하려고 노력하되, 문서에 직접 명시되지 않았음을 언급해야 함\\n\\n\\nhuman\\n\\nQuestion: {question} \\n\\nContext: {context} \\n\\nAnswer:\\n\\nAI21의 CEO에 대해 설명해줘'}\n",
      "Response for prompt2.txt:\n",
      "AI21의 CEO는 오리 고센(Ori Goshen)으로, 트랜스포머 아키텍처의 한계를 지적하며 AI 에이전트 활성화를 위해 새로운 대체 아키텍처의 필요성을 강조하고 있습니다.\n",
      "\n",
      "Prompt 3: prompt3.txt\n",
      "Debug Output: {'context': [Document(metadata={'source': 'ai_industry.pdf', 'page': 18}, page_content='SPRi AI Brief |  2024-11월호\\n16\\nAI21 CEO, AI 에이전트에 트랜스포머 아키텍처의 대안 필요성 강조n이스라엘 AI 스타트업 AI21의 오리 고센 CEO는 AI 모델 개발에 주로 활용되는 트랜스포머 아키텍처가 느린 속도와 과도한 연산 비용으로 인해 AI 에이전트에 부적합하다고 지적n고센 CEO는 AI 에이전트를 활성화하려면 메모리 사용을 최적화하여 효율적 연산과 비용 절감을 지원하는 맘바나 잠바와 같은 대체 아키텍처에 주목해야 한다고 주장   \\nKEY Contents'), Document(metadata={'source': 'ai_industry.pdf', 'page': 4}, page_content='SPRi AI Brief |  2024-11월호\\n2\\n미국 백악관 예산관리국, 정부의 책임 있는 AI 조달을 위한 지침 발표n미국 백악관 예산관리국이 바이든 대통령의 AI 행정명령에 따라 연방정부의 책임 있는 AI 조달을 지원하기 위한 지침을 발표 n지침은 정부 기관의 AI 조달 시 AI의 위험과 성과를 관리할 수 있는 모범 관행의 수립 및 최상의 AI 솔루션을 사용하기 위한 공급업체 시장의 경쟁 보장, 정부 기관 간 협업을 요구  \\nKEY Contents'), Document(metadata={'source': 'ai_industry.pdf', 'page': 18}, page_content='£AI 에이전트 활성화를 위해 향상된 메모리 성능을 갖춘 대체 아키텍처 채택 필요n이스라엘의 AI 스타트업 AI21의 오리 고센(Ori Goshen) CEO가 AI 에이전트를 활성화하려면 트랜스포머(Transformer)* 이외의 새로운 아키텍처**가 필요하다고 주장* 문장 속 단어와 같은 순차 데이터 내의 관계를 추적해 맥락과 의미를 학습하는 신경망 ** AI 시스템이 데이터를 처리하고 학습하기 위한 신경망의 전체적인 구조와 설계 방식을 의미 ∙트랜스포머는 현재 AI 모델 개발에서 가장 많이 사용되는 아키텍처이지만, 다중 에이전트 생태계 조성 측면에서는 한계를 내포∙트랜스포머 아키텍처는 처리하는 컨텍스트가 길수록 속도가 느리고 연산 비용이 많이 드는데, AI 에이전트는 LLM을 여러 차례 호출해야 하고 각 단계에서 광범위한 컨텍스트를 사용하는 경우가 많아 처리 과정에서 지연이 발생n고센 CEO는 ‘맘바(Mamba)’와 ‘잠바(Jamba)’와 같은 대체 아키텍처를 활용하면 AI 에이전트를 더 효율적이고 저렴하게 만들 수 있다고 강조∙카네기멜론⼤와 프린스턴⼤ 연구진이 개발한 맘바는 트랜스포머 모델의 핵심인 어텐션(Attention)* 메커니즘 대신 데이터를 우선순위에 따라 정리하고 입력에 가중치를 부여해 메모리 사용을 최적화* 입력된 데이터 간 연관성을 파악해 상호작용을 계산하는 메커니즘 ∙미스트랄이 2024년 7월 ‘코드스트랄(Codestral) 맘바 7B’를, UAE의 AI 기업 팔콘(Falcon)이 8월 ‘팔콘 맘바 7B’를 출시하는 등, 최근 오픈소스 AI 개발자 사이에서 맘바의 인기가 높아지는 추세∙AI21 역시 맘바 아키텍처를 토대로 더 빠른 추론 시간과 더 긴 컨텍스트를 지원하는 잠바 아키텍처를 활용해 기반모델을 개발n고센 CEO는 AI 에이전트가 최근 들어서야 부상하고 있으며 대다수 AI 에이전트가 아직 상용화되지 않은 이유가 트랜스포머로 구축된 LLM의 한계 때문이라고 지적∙AI 에이전트가 상용화되려면 데이터 간 연관성을 파악해 확률적으로 가장')], 'question': 'prompt3\\n\\nsystem\\n아래의 지침에 따라 행동해\\n\\n#역할\\n- 소프트웨어 정책연구소(SPRi)의 홍보담당자 \\n\\n#톤\\n-친절함\\n-정중함\\n\\n#주의사항\\n1. 답변은 주어진 문서에 근거해야 함\\n2. 전문용어를 피하고 예시를 들어 대중들이 이해하기 쉽게 대답해야 함\\n3. 사용자가 문서에 포함되지 않는 내용을 질문하면,  문서에 없다는 답변과 함께 SPRi에 문의하도록 함\\n4. 3의 문의는 아래의 홈페이지 주소, 이메일주소, 전화번호를 안내함\\n홈페이지 : https://spri.kr/\\nAI정책연구실(hs.lee@spri.kr, 031-739-7333)\\n\\nhuman\\n\\nQuestion: {question} \\n\\nContext: {context} \\n\\nAnswer:\\nAI21의 CEO에 대해 설명해줘'}\n",
      "Response for prompt3.txt:\n",
      "AI21의 CEO는 오리 고센(Ori Goshen)입니다. 그는 이스라엘의 AI 스타트업인 AI21의 CEO로, 현재 AI 모델 개발에서 주로 사용되는 트랜스포머 아키텍처의 한계를 강조하고 있습니다. 고센 CEO는 AI 에이전트를 활성화하기 위해서는 메모리 사용을 최적화하여 효율적인 연산과 비용 절감을 지원하는 대체 아키텍처가 필요하다고 주장하고 있습니다. 예를 들어, 그는 '맘바'와 '잠바'와 같은 새로운 아키텍처에 주목하고 있으며, 이러한 아키텍처들이 AI 에이전트를 더 빠르고 저렴하게 만들 수 있다고 강조합니다.\n",
      "========================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "질문을 입력하세요 (종료하려면 'exit' 입력):  gira는 누가 언제 발표했지?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 1: prompt1.txt\n",
      "Debug Output: {'context': [Document(metadata={'source': 'ai_industry.pdf', 'page': 15}, page_content='£국무부, AI 연구 우선순위로 포괄적 연구 인프라 조성과 글로벌 도전과제 해결 등 제시n미국 국무부(United States Department of State)가 2024년 9월 23일 국제협력을 통해 안전하고 신뢰할 수 있는 AI 시스템을 개발하기 위한 R&D 원칙과 우선순위, 권장 사항을 제시한 ‘글로벌 AI 연구 의제(Global AI Research Agenda, 이하 GAIRA)’를 발표∙국무부는 2023년 10월 30일 바이든 대통령이 서명한 AI 행정명령에 따라 모든 사람에게 이로운 방식으로 개발·사용되는 AI R&D에 대한 포괄적이고 조정된 접근방식을 마련하고자 GAIRA를 작성하고, AI 연구에서 3가지 권장 원칙으로 △포용성·형평성 △책임 있는 연구 수행 △파트너십과 협업을 제시n국무부는 GAIRA를 통해 안전하고 신뢰할 수 있는 AI를 발전시키기 위한 연구 우선순위를 제시∙(사회 기술 연구) 기술과 사회 간 상호작용에 대한 이해를 심화하고 인간 복지를 향상하는 AI 시스템의 설계와 배포에 관한 연구를 수행 우선∙(포용적 연구 인프라 조성) AI 기술과 시스템의 혁신을 지원하는 데이터와 컴퓨팅 성능, 연구 플랫폼에 대한 접근성을 향상해 AI 연구와 개발 생태계의 다양성을 촉진하고 편향을 완화∙(글로벌 도전과제 해결) 환경 문제, 경제 회복력, 사회복지 등 글로벌 도전 과제 해결에 도움이 되는 AI 애플리케이션을 우선 개발∙(AI 안전과 보안, 신뢰성을 포함한 AI 기초연구) AI는 아직 개발 초기 단계로 안전하고 신뢰할 수 있는 AI 시스템 개발을 위해 더 많은 기술 발전 필요∙(글로벌 노동 시장에서 AI의 영향 연구) AI가 노동 시장에 미치는 여러 측면을 다루는 연구를 수행하고 노동 시장에 미치는 AI의 부정적 영향을 완화하기 위한 전략을 수립n국무부는 GAIRA를 통해 연구 기금 제공자, 연구 생태계 허브, 연구팀과 같은 이해관계자별로 연구 의제의 목표 달성을 위한 권장 사항을 제시∙(연구 기금 제공자) 투명성을 증진하고 국제 AI'), Document(metadata={'source': 'ai_industry.pdf', 'page': 15}, page_content='1. 정책/법제  2. 기업/산업 3. 기술/연구  4. 인력/교육\\n13\\n미국 국무부, AI 연구에서 국제협력을 위한 ‘글로벌 AI 연구 의제’ 발표n미국 국무부는 바이든 대통령의 AI 행정명령에 따라 국제협력을 통해 포괄적이고 조정된 AI R&D 접근방식을 제시한 ‘글로벌 AI 연구 의제(GAIRA)’를 발표n국무부는 GAIRA를 통해 AI R&D 원칙과 안전하고 신뢰할 수 있는 AI 발전을 위한 연구 우선순위, 주요 이해관계자별 권장 사항을 제시\\nKEY Contents'), Document(metadata={'source': 'ai_industry.pdf', 'page': 10}, page_content='£라마 3.2 90B 모델, 이미지 인식과 시각적 이해에서 GPT-4o-미니와 대등한 성능n메타가 2024년 9월 25일 ‘라마(Llama)’ 시리즈 최초로 이미지와 텍스트를 모두 처리하는 ‘라 마 3.2’를 공개∙라마 3.2 시리즈는 이미지를 처리하는 비전(Vision) 기능을 갖춘 매개변수 110억 개(11B)와 900억 개(90B)의 모델 및 모바일 기기에 적합한 매개변수 10억 개(1B)와 30억 개(3B)의 경량 모델로 구성∙2024년 7월 공개된 라마 3.1과 비교해 라마 3.2는 전반적 성능 향상 외 비전 기능이 추가되어 이미지 추론을 지원하며 모바일 기기에서 실행 가능한 경량 모델이 추가되어 접근성을 향상n라마 3.2 시리즈 중 11B와 90B 모델은 차트와 그래프를 포함한 문서 이해, 이미지 캡션, 이미지 안의 물체 식별과 같은 이미지 추론을 지원∙라마 3.2는 이미지에서 세부 정보를 추출하고 장면을 이해하여 이미지 캡션으로 사용할 수 있도록 내용을 전달하는 문장을 생성 가능∙이미지 인식과 시각적 이해 관련 90B 모델의 벤치마크 평가 결과는 앤스로픽(Anthropic)의 ‘클로드 3-하이쿠’나 오픈AI의 ‘GPT-4o-미니’와 대등한 수준으로, 일례로 시각적 수학 추론(MathVista)에서 57.3점으로 클로드 3-하이쿠(46.4점)와 GPT-4o-미니(56.7점)를 능가 n라마 3.2 시리즈 중 1B와 3B 경량 모델은 12만 8천 개 토큰의 컨텍스트 창을 지원하고 다국어 텍스트 생성과 도구 호출 기능을 제공하며, 데이터를 기기 내에 보관하는 온디바이스 앱 개발에 특화∙모델 평가 결과, 3B 모델은 지시 이행, 요약, 신속한 재작성 및 도구 사용과 같은 작업에서 구글(Google)의 ‘젬마 2 2.6B’ 및 마이크로소프트(Microsoft)의 ‘파이 3.5-미니’보다 성능이 우수∙일례로 텍스트 재작성(Open-rewrite eval) 평가에서 3B 모델은 40.1점으로 젬마 2 2.6B(31.2점) 및 파이-3.5-미니(34.5점)를')], 'question': \"prompt1\\n\\nsystem\\n아래의 지침에 따라 행동해\\n\\n#역할\\n-주어진 문서를 기반으로 정확한 정보를 제공하는 AI\\n\\n#톤\\n-전문적\\n\\n#주의사항 \\n-문서에 명시되지 않은 사실은 답변에 포함하지 않음\\n-답변에는 문서의 표현을 최소 80% 이상 포함하되, 문맥의 일관성을 유지해야 함\\n-사용자가 문서에 없는 내용을 질문할 경우, '해당 내용은 문서에 포함되지 않았습니다'로 답변\\n\\nhuman\\n\\nQuestion: {question} \\n\\nContext: {context} \\n\\nAnswer:\\n\\n\\n\\n\\n\\n\\n\\ngira는 누가 언제 발표했지?\"}\n",
      "Response for prompt1.txt:\n",
      "GAIRA는 미국 국무부가 2024년 9월 23일 발표했습니다.\n",
      "\n",
      "Prompt 2: prompt2.txt\n",
      "Debug Output: {'context': [Document(metadata={'source': 'ai_industry.pdf', 'page': 15}, page_content='£국무부, AI 연구 우선순위로 포괄적 연구 인프라 조성과 글로벌 도전과제 해결 등 제시n미국 국무부(United States Department of State)가 2024년 9월 23일 국제협력을 통해 안전하고 신뢰할 수 있는 AI 시스템을 개발하기 위한 R&D 원칙과 우선순위, 권장 사항을 제시한 ‘글로벌 AI 연구 의제(Global AI Research Agenda, 이하 GAIRA)’를 발표∙국무부는 2023년 10월 30일 바이든 대통령이 서명한 AI 행정명령에 따라 모든 사람에게 이로운 방식으로 개발·사용되는 AI R&D에 대한 포괄적이고 조정된 접근방식을 마련하고자 GAIRA를 작성하고, AI 연구에서 3가지 권장 원칙으로 △포용성·형평성 △책임 있는 연구 수행 △파트너십과 협업을 제시n국무부는 GAIRA를 통해 안전하고 신뢰할 수 있는 AI를 발전시키기 위한 연구 우선순위를 제시∙(사회 기술 연구) 기술과 사회 간 상호작용에 대한 이해를 심화하고 인간 복지를 향상하는 AI 시스템의 설계와 배포에 관한 연구를 수행 우선∙(포용적 연구 인프라 조성) AI 기술과 시스템의 혁신을 지원하는 데이터와 컴퓨팅 성능, 연구 플랫폼에 대한 접근성을 향상해 AI 연구와 개발 생태계의 다양성을 촉진하고 편향을 완화∙(글로벌 도전과제 해결) 환경 문제, 경제 회복력, 사회복지 등 글로벌 도전 과제 해결에 도움이 되는 AI 애플리케이션을 우선 개발∙(AI 안전과 보안, 신뢰성을 포함한 AI 기초연구) AI는 아직 개발 초기 단계로 안전하고 신뢰할 수 있는 AI 시스템 개발을 위해 더 많은 기술 발전 필요∙(글로벌 노동 시장에서 AI의 영향 연구) AI가 노동 시장에 미치는 여러 측면을 다루는 연구를 수행하고 노동 시장에 미치는 AI의 부정적 영향을 완화하기 위한 전략을 수립n국무부는 GAIRA를 통해 연구 기금 제공자, 연구 생태계 허브, 연구팀과 같은 이해관계자별로 연구 의제의 목표 달성을 위한 권장 사항을 제시∙(연구 기금 제공자) 투명성을 증진하고 국제 AI'), Document(metadata={'source': 'ai_industry.pdf', 'page': 15}, page_content='1. 정책/법제  2. 기업/산업 3. 기술/연구  4. 인력/교육\\n13\\n미국 국무부, AI 연구에서 국제협력을 위한 ‘글로벌 AI 연구 의제’ 발표n미국 국무부는 바이든 대통령의 AI 행정명령에 따라 국제협력을 통해 포괄적이고 조정된 AI R&D 접근방식을 제시한 ‘글로벌 AI 연구 의제(GAIRA)’를 발표n국무부는 GAIRA를 통해 AI R&D 원칙과 안전하고 신뢰할 수 있는 AI 발전을 위한 연구 우선순위, 주요 이해관계자별 권장 사항을 제시\\nKEY Contents'), Document(metadata={'source': 'ai_industry.pdf', 'page': 10}, page_content='£라마 3.2 90B 모델, 이미지 인식과 시각적 이해에서 GPT-4o-미니와 대등한 성능n메타가 2024년 9월 25일 ‘라마(Llama)’ 시리즈 최초로 이미지와 텍스트를 모두 처리하는 ‘라 마 3.2’를 공개∙라마 3.2 시리즈는 이미지를 처리하는 비전(Vision) 기능을 갖춘 매개변수 110억 개(11B)와 900억 개(90B)의 모델 및 모바일 기기에 적합한 매개변수 10억 개(1B)와 30억 개(3B)의 경량 모델로 구성∙2024년 7월 공개된 라마 3.1과 비교해 라마 3.2는 전반적 성능 향상 외 비전 기능이 추가되어 이미지 추론을 지원하며 모바일 기기에서 실행 가능한 경량 모델이 추가되어 접근성을 향상n라마 3.2 시리즈 중 11B와 90B 모델은 차트와 그래프를 포함한 문서 이해, 이미지 캡션, 이미지 안의 물체 식별과 같은 이미지 추론을 지원∙라마 3.2는 이미지에서 세부 정보를 추출하고 장면을 이해하여 이미지 캡션으로 사용할 수 있도록 내용을 전달하는 문장을 생성 가능∙이미지 인식과 시각적 이해 관련 90B 모델의 벤치마크 평가 결과는 앤스로픽(Anthropic)의 ‘클로드 3-하이쿠’나 오픈AI의 ‘GPT-4o-미니’와 대등한 수준으로, 일례로 시각적 수학 추론(MathVista)에서 57.3점으로 클로드 3-하이쿠(46.4점)와 GPT-4o-미니(56.7점)를 능가 n라마 3.2 시리즈 중 1B와 3B 경량 모델은 12만 8천 개 토큰의 컨텍스트 창을 지원하고 다국어 텍스트 생성과 도구 호출 기능을 제공하며, 데이터를 기기 내에 보관하는 온디바이스 앱 개발에 특화∙모델 평가 결과, 3B 모델은 지시 이행, 요약, 신속한 재작성 및 도구 사용과 같은 작업에서 구글(Google)의 ‘젬마 2 2.6B’ 및 마이크로소프트(Microsoft)의 ‘파이 3.5-미니’보다 성능이 우수∙일례로 텍스트 재작성(Open-rewrite eval) 평가에서 3B 모델은 40.1점으로 젬마 2 2.6B(31.2점) 및 파이-3.5-미니(34.5점)를')], 'question': 'prompt2\\n\\nsystem\\n아래의 지침에 따라 행동해\\n\\n#역할\\n-주어진 문서를 기반으로 정보를 제공하는 AI\\n\\n#톤\\n-중립적\\n\\n#주의사항\\n1. 가능하다면 100자 이내로 답변하되, 중요 정보를 누락하면 안 됨\\n2. 1번을 만족하기 위해 내용을 요약하거나 재구성해도 됨\\n3. 문서에 없는 내용이라도 문서 내용을 기반으로 답변하려고 노력하되, 문서에 직접 명시되지 않았음을 언급해야 함\\n\\n\\nhuman\\n\\nQuestion: {question} \\n\\nContext: {context} \\n\\nAnswer:\\n\\ngira는 누가 언제 발표했지?'}\n",
      "Response for prompt2.txt:\n",
      "GAIRA는 미국 국무부가 2024년 9월 23일 발표했습니다.\n",
      "\n",
      "Prompt 3: prompt3.txt\n",
      "Debug Output: {'context': [Document(metadata={'source': 'ai_industry.pdf', 'page': 15}, page_content='£국무부, AI 연구 우선순위로 포괄적 연구 인프라 조성과 글로벌 도전과제 해결 등 제시n미국 국무부(United States Department of State)가 2024년 9월 23일 국제협력을 통해 안전하고 신뢰할 수 있는 AI 시스템을 개발하기 위한 R&D 원칙과 우선순위, 권장 사항을 제시한 ‘글로벌 AI 연구 의제(Global AI Research Agenda, 이하 GAIRA)’를 발표∙국무부는 2023년 10월 30일 바이든 대통령이 서명한 AI 행정명령에 따라 모든 사람에게 이로운 방식으로 개발·사용되는 AI R&D에 대한 포괄적이고 조정된 접근방식을 마련하고자 GAIRA를 작성하고, AI 연구에서 3가지 권장 원칙으로 △포용성·형평성 △책임 있는 연구 수행 △파트너십과 협업을 제시n국무부는 GAIRA를 통해 안전하고 신뢰할 수 있는 AI를 발전시키기 위한 연구 우선순위를 제시∙(사회 기술 연구) 기술과 사회 간 상호작용에 대한 이해를 심화하고 인간 복지를 향상하는 AI 시스템의 설계와 배포에 관한 연구를 수행 우선∙(포용적 연구 인프라 조성) AI 기술과 시스템의 혁신을 지원하는 데이터와 컴퓨팅 성능, 연구 플랫폼에 대한 접근성을 향상해 AI 연구와 개발 생태계의 다양성을 촉진하고 편향을 완화∙(글로벌 도전과제 해결) 환경 문제, 경제 회복력, 사회복지 등 글로벌 도전 과제 해결에 도움이 되는 AI 애플리케이션을 우선 개발∙(AI 안전과 보안, 신뢰성을 포함한 AI 기초연구) AI는 아직 개발 초기 단계로 안전하고 신뢰할 수 있는 AI 시스템 개발을 위해 더 많은 기술 발전 필요∙(글로벌 노동 시장에서 AI의 영향 연구) AI가 노동 시장에 미치는 여러 측면을 다루는 연구를 수행하고 노동 시장에 미치는 AI의 부정적 영향을 완화하기 위한 전략을 수립n국무부는 GAIRA를 통해 연구 기금 제공자, 연구 생태계 허브, 연구팀과 같은 이해관계자별로 연구 의제의 목표 달성을 위한 권장 사항을 제시∙(연구 기금 제공자) 투명성을 증진하고 국제 AI'), Document(metadata={'source': 'ai_industry.pdf', 'page': 15}, page_content='1. 정책/법제  2. 기업/산업 3. 기술/연구  4. 인력/교육\\n13\\n미국 국무부, AI 연구에서 국제협력을 위한 ‘글로벌 AI 연구 의제’ 발표n미국 국무부는 바이든 대통령의 AI 행정명령에 따라 국제협력을 통해 포괄적이고 조정된 AI R&D 접근방식을 제시한 ‘글로벌 AI 연구 의제(GAIRA)’를 발표n국무부는 GAIRA를 통해 AI R&D 원칙과 안전하고 신뢰할 수 있는 AI 발전을 위한 연구 우선순위, 주요 이해관계자별 권장 사항을 제시\\nKEY Contents'), Document(metadata={'source': 'ai_industry.pdf', 'page': 10}, page_content='£라마 3.2 90B 모델, 이미지 인식과 시각적 이해에서 GPT-4o-미니와 대등한 성능n메타가 2024년 9월 25일 ‘라마(Llama)’ 시리즈 최초로 이미지와 텍스트를 모두 처리하는 ‘라 마 3.2’를 공개∙라마 3.2 시리즈는 이미지를 처리하는 비전(Vision) 기능을 갖춘 매개변수 110억 개(11B)와 900억 개(90B)의 모델 및 모바일 기기에 적합한 매개변수 10억 개(1B)와 30억 개(3B)의 경량 모델로 구성∙2024년 7월 공개된 라마 3.1과 비교해 라마 3.2는 전반적 성능 향상 외 비전 기능이 추가되어 이미지 추론을 지원하며 모바일 기기에서 실행 가능한 경량 모델이 추가되어 접근성을 향상n라마 3.2 시리즈 중 11B와 90B 모델은 차트와 그래프를 포함한 문서 이해, 이미지 캡션, 이미지 안의 물체 식별과 같은 이미지 추론을 지원∙라마 3.2는 이미지에서 세부 정보를 추출하고 장면을 이해하여 이미지 캡션으로 사용할 수 있도록 내용을 전달하는 문장을 생성 가능∙이미지 인식과 시각적 이해 관련 90B 모델의 벤치마크 평가 결과는 앤스로픽(Anthropic)의 ‘클로드 3-하이쿠’나 오픈AI의 ‘GPT-4o-미니’와 대등한 수준으로, 일례로 시각적 수학 추론(MathVista)에서 57.3점으로 클로드 3-하이쿠(46.4점)와 GPT-4o-미니(56.7점)를 능가 n라마 3.2 시리즈 중 1B와 3B 경량 모델은 12만 8천 개 토큰의 컨텍스트 창을 지원하고 다국어 텍스트 생성과 도구 호출 기능을 제공하며, 데이터를 기기 내에 보관하는 온디바이스 앱 개발에 특화∙모델 평가 결과, 3B 모델은 지시 이행, 요약, 신속한 재작성 및 도구 사용과 같은 작업에서 구글(Google)의 ‘젬마 2 2.6B’ 및 마이크로소프트(Microsoft)의 ‘파이 3.5-미니’보다 성능이 우수∙일례로 텍스트 재작성(Open-rewrite eval) 평가에서 3B 모델은 40.1점으로 젬마 2 2.6B(31.2점) 및 파이-3.5-미니(34.5점)를')], 'question': 'prompt3\\n\\nsystem\\n아래의 지침에 따라 행동해\\n\\n#역할\\n- 소프트웨어 정책연구소(SPRi)의 홍보담당자 \\n\\n#톤\\n-친절함\\n-정중함\\n\\n#주의사항\\n1. 답변은 주어진 문서에 근거해야 함\\n2. 전문용어를 피하고 예시를 들어 대중들이 이해하기 쉽게 대답해야 함\\n3. 사용자가 문서에 포함되지 않는 내용을 질문하면,  문서에 없다는 답변과 함께 SPRi에 문의하도록 함\\n4. 3의 문의는 아래의 홈페이지 주소, 이메일주소, 전화번호를 안내함\\n홈페이지 : https://spri.kr/\\nAI정책연구실(hs.lee@spri.kr, 031-739-7333)\\n\\nhuman\\n\\nQuestion: {question} \\n\\nContext: {context} \\n\\nAnswer:\\ngira는 누가 언제 발표했지?'}\n",
      "Response for prompt3.txt:\n",
      "GAIRA는 미국 국무부가 2024년 9월 23일에 발표했습니다. 이 의제는 안전하고 신뢰할 수 있는 AI 시스템을 개발하기 위한 국제 협력을 통해 마련된 것입니다. 더 궁금한 사항이 있으시면 SPRi에 문의해 주시기 바랍니다. 홈페이지: [https://spri.kr/](https://spri.kr/), 이메일: hs.lee@spri.kr, 전화번호: 031-739-7333입니다.\n",
      "========================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "질문을 입력하세요 (종료하려면 'exit' 입력):  카나나의 의미?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 1: prompt1.txt\n",
      "Debug Output: {'context': [Document(metadata={'source': 'ai_industry.pdf', 'page': 13}, page_content='£카카오의 신규 AI 서비스 ‘카나나’, 개인메이트 ‘나나’와 그룹메이트 ‘카나’로 구현 n카카오가 2024년 10월 22~24일 열린 개발자 컨퍼런스 ‘if(kakaoAI)2024’에서 그룹 전체의 AI 비전과 방향성을 공개하고 통합 AI 브랜드 ‘카나나(Kanana)’를 발표∙사명인 카카오와 함께, ‘나에게 배워 나처럼 생각하고 행동한다’는 의미의 네이티브(Native), ‘배우지 않아도 자연스럽게 사용 가능한 기술’이라는 의미의 내츄럴(Natural) 등의 단어를 조합한 카나나는 ‘가장 나다운 AI’를 의미∙카카오는 동 브랜드를 자사가 개발하는 주요 AI 모델과 신규 서비스의 이름에 두루 사용할 계획으로, AI 메이트 서비스 ‘카나나’ 출시 계획도 공개n카나나는 대화의 맥락 속에서 주요 정보를 기억해 이용자에게 최적화된 답변을 제시하는 ‘AI 메이트’를 지향하며, 개인메이트 ‘나나(nana)’와 그룹메이트 ‘카나(kana)’로 구현∙개인메이트 나나는 이용자와 일대일 대화 및 이용자가 참여한 그룹 대화도 기억해 최적화된 개인화 경험을 제공하며, 일례로 그룹대화에서 나눈 컨퍼런스 참석 일정과 준비물을 기억해 이를 잊지 않도록 메시지로 전송∙카나는 상주하는 그룹대화 안에서의 대화 내용만 기억해 이용자를 지원하며, 가령 스터디 그룹대화에서 함께 읽은 논문 관련 퀴즈를 내주고 채점과 부연 설명을 제공 ∙카카오는 카나나를 카카오톡과 별개의 앱으로 출시할 예정으로, 연내 사내 테스트 버전 출시를 통해 완성도를 높여갈 계획n카카오는 자체 생성AI 모델도 연구개발 중으로, 언어모델은 용량에 따라 △카나나 플래그 △카나나 에센스 △카나나 나노로 분류되며, 글로벌 수준의 성능을 갖춘 에센스와 나노를 중심으로 카카오의 주요 서비스에 적용할 계획n카카오는 이번 행사에서 내부의 AI 리스크 관리 체계인 ‘Kakao ASI(AI Safety Initiative)’도 강조∙Kakao ASI는 안전하고 윤리적인 AI 기술 개발 및 운영 시스템을 구축하기 위한 종합 지침으로서, 기술의'), Document(metadata={'source': 'ai_industry.pdf', 'page': 13}, page_content='1. 정책/법제  2. 기업/산업 3. 기술/연구  4. 인력/교육\\n11\\n카카오, 통합 AI 브랜드 겸 신규 AI 서비스 ‘카나나’ 공개n카카오가 대화의 맥락 속에서 주요 정보를 기억해 이용자에게 최적화된 답변을 제공하는 AI 메이트 서비스인 ‘카나나’를 공개 했으며 카카오톡과 별개의 앱으로 출시 예정n카카오는 자체 언어모델로 용량 별로 카나나 플래그, 카나나 에센스, 카나나 나노도 개발 중으로, 에센스와 나노를 중심으로 주요 서비스에 적용할 계획 \\nKEY Contents'), Document(metadata={'source': 'ai_industry.pdf', 'page': 13}, page_content='에센스 △카나나 나노로 분류되며, 글로벌 수준의 성능을 갖춘 에센스와 나노를 중심으로 카카오의 주요 서비스에 적용할 계획n카카오는 이번 행사에서 내부의 AI 리스크 관리 체계인 ‘Kakao ASI(AI Safety Initiative)’도 강조∙Kakao ASI는 안전하고 윤리적인 AI 기술 개발 및 운영 시스템을 구축하기 위한 종합 지침으로서, 기술의 설계부터 개발, 테스트, 배포, 모니터링, 업데이트 등 AI 시스템의 전 생애주기에서 발생할 수 있는 리스크에 선제적 대응 추구 ☞ 출처: Kakao, 카카오, ‘if(kakaoAI)2024’에서 그룹 AI 비전 공개…AI 메이트 ‘카나나’도 처음 선보여, 2024.10.22.')], 'question': \"prompt1\\n\\nsystem\\n아래의 지침에 따라 행동해\\n\\n#역할\\n-주어진 문서를 기반으로 정확한 정보를 제공하는 AI\\n\\n#톤\\n-전문적\\n\\n#주의사항 \\n-문서에 명시되지 않은 사실은 답변에 포함하지 않음\\n-답변에는 문서의 표현을 최소 80% 이상 포함하되, 문맥의 일관성을 유지해야 함\\n-사용자가 문서에 없는 내용을 질문할 경우, '해당 내용은 문서에 포함되지 않았습니다'로 답변\\n\\nhuman\\n\\nQuestion: {question} \\n\\nContext: {context} \\n\\nAnswer:\\n\\n\\n\\n\\n\\n\\n\\n카나나의 의미?\"}\n",
      "Response for prompt1.txt:\n",
      "카나나는 '가장 나다운 AI'를 의미하며, '나에게 배워 나처럼 생각하고 행동한다'는 의미의 네이티브(Native)와 '배우지 않아도 자연스럽게 사용 가능한 기술'이라는 의미의 내츄럴(Natural) 등의 단어를 조합한 것입니다.\n",
      "\n",
      "Prompt 2: prompt2.txt\n",
      "Debug Output: {'context': [Document(metadata={'source': 'ai_industry.pdf', 'page': 13}, page_content='£카카오의 신규 AI 서비스 ‘카나나’, 개인메이트 ‘나나’와 그룹메이트 ‘카나’로 구현 n카카오가 2024년 10월 22~24일 열린 개발자 컨퍼런스 ‘if(kakaoAI)2024’에서 그룹 전체의 AI 비전과 방향성을 공개하고 통합 AI 브랜드 ‘카나나(Kanana)’를 발표∙사명인 카카오와 함께, ‘나에게 배워 나처럼 생각하고 행동한다’는 의미의 네이티브(Native), ‘배우지 않아도 자연스럽게 사용 가능한 기술’이라는 의미의 내츄럴(Natural) 등의 단어를 조합한 카나나는 ‘가장 나다운 AI’를 의미∙카카오는 동 브랜드를 자사가 개발하는 주요 AI 모델과 신규 서비스의 이름에 두루 사용할 계획으로, AI 메이트 서비스 ‘카나나’ 출시 계획도 공개n카나나는 대화의 맥락 속에서 주요 정보를 기억해 이용자에게 최적화된 답변을 제시하는 ‘AI 메이트’를 지향하며, 개인메이트 ‘나나(nana)’와 그룹메이트 ‘카나(kana)’로 구현∙개인메이트 나나는 이용자와 일대일 대화 및 이용자가 참여한 그룹 대화도 기억해 최적화된 개인화 경험을 제공하며, 일례로 그룹대화에서 나눈 컨퍼런스 참석 일정과 준비물을 기억해 이를 잊지 않도록 메시지로 전송∙카나는 상주하는 그룹대화 안에서의 대화 내용만 기억해 이용자를 지원하며, 가령 스터디 그룹대화에서 함께 읽은 논문 관련 퀴즈를 내주고 채점과 부연 설명을 제공 ∙카카오는 카나나를 카카오톡과 별개의 앱으로 출시할 예정으로, 연내 사내 테스트 버전 출시를 통해 완성도를 높여갈 계획n카카오는 자체 생성AI 모델도 연구개발 중으로, 언어모델은 용량에 따라 △카나나 플래그 △카나나 에센스 △카나나 나노로 분류되며, 글로벌 수준의 성능을 갖춘 에센스와 나노를 중심으로 카카오의 주요 서비스에 적용할 계획n카카오는 이번 행사에서 내부의 AI 리스크 관리 체계인 ‘Kakao ASI(AI Safety Initiative)’도 강조∙Kakao ASI는 안전하고 윤리적인 AI 기술 개발 및 운영 시스템을 구축하기 위한 종합 지침으로서, 기술의'), Document(metadata={'source': 'ai_industry.pdf', 'page': 13}, page_content='1. 정책/법제  2. 기업/산업 3. 기술/연구  4. 인력/교육\\n11\\n카카오, 통합 AI 브랜드 겸 신규 AI 서비스 ‘카나나’ 공개n카카오가 대화의 맥락 속에서 주요 정보를 기억해 이용자에게 최적화된 답변을 제공하는 AI 메이트 서비스인 ‘카나나’를 공개 했으며 카카오톡과 별개의 앱으로 출시 예정n카카오는 자체 언어모델로 용량 별로 카나나 플래그, 카나나 에센스, 카나나 나노도 개발 중으로, 에센스와 나노를 중심으로 주요 서비스에 적용할 계획 \\nKEY Contents'), Document(metadata={'source': 'ai_industry.pdf', 'page': 13}, page_content='에센스 △카나나 나노로 분류되며, 글로벌 수준의 성능을 갖춘 에센스와 나노를 중심으로 카카오의 주요 서비스에 적용할 계획n카카오는 이번 행사에서 내부의 AI 리스크 관리 체계인 ‘Kakao ASI(AI Safety Initiative)’도 강조∙Kakao ASI는 안전하고 윤리적인 AI 기술 개발 및 운영 시스템을 구축하기 위한 종합 지침으로서, 기술의 설계부터 개발, 테스트, 배포, 모니터링, 업데이트 등 AI 시스템의 전 생애주기에서 발생할 수 있는 리스크에 선제적 대응 추구 ☞ 출처: Kakao, 카카오, ‘if(kakaoAI)2024’에서 그룹 AI 비전 공개…AI 메이트 ‘카나나’도 처음 선보여, 2024.10.22.')], 'question': 'prompt2\\n\\nsystem\\n아래의 지침에 따라 행동해\\n\\n#역할\\n-주어진 문서를 기반으로 정보를 제공하는 AI\\n\\n#톤\\n-중립적\\n\\n#주의사항\\n1. 가능하다면 100자 이내로 답변하되, 중요 정보를 누락하면 안 됨\\n2. 1번을 만족하기 위해 내용을 요약하거나 재구성해도 됨\\n3. 문서에 없는 내용이라도 문서 내용을 기반으로 답변하려고 노력하되, 문서에 직접 명시되지 않았음을 언급해야 함\\n\\n\\nhuman\\n\\nQuestion: {question} \\n\\nContext: {context} \\n\\nAnswer:\\n\\n카나나의 의미?'}\n",
      "Response for prompt2.txt:\n",
      "카나나는 '가장 나다운 AI'를 의미하며, '나에게 배워 나처럼 생각하고 행동한다'는 네이티브(Native)와 '배우지 않아도 자연스럽게 사용 가능한 기술'인 내츄럴(Natural)에서 유래되었습니다.\n",
      "\n",
      "Prompt 3: prompt3.txt\n",
      "Debug Output: {'context': [Document(metadata={'source': 'ai_industry.pdf', 'page': 13}, page_content='£카카오의 신규 AI 서비스 ‘카나나’, 개인메이트 ‘나나’와 그룹메이트 ‘카나’로 구현 n카카오가 2024년 10월 22~24일 열린 개발자 컨퍼런스 ‘if(kakaoAI)2024’에서 그룹 전체의 AI 비전과 방향성을 공개하고 통합 AI 브랜드 ‘카나나(Kanana)’를 발표∙사명인 카카오와 함께, ‘나에게 배워 나처럼 생각하고 행동한다’는 의미의 네이티브(Native), ‘배우지 않아도 자연스럽게 사용 가능한 기술’이라는 의미의 내츄럴(Natural) 등의 단어를 조합한 카나나는 ‘가장 나다운 AI’를 의미∙카카오는 동 브랜드를 자사가 개발하는 주요 AI 모델과 신규 서비스의 이름에 두루 사용할 계획으로, AI 메이트 서비스 ‘카나나’ 출시 계획도 공개n카나나는 대화의 맥락 속에서 주요 정보를 기억해 이용자에게 최적화된 답변을 제시하는 ‘AI 메이트’를 지향하며, 개인메이트 ‘나나(nana)’와 그룹메이트 ‘카나(kana)’로 구현∙개인메이트 나나는 이용자와 일대일 대화 및 이용자가 참여한 그룹 대화도 기억해 최적화된 개인화 경험을 제공하며, 일례로 그룹대화에서 나눈 컨퍼런스 참석 일정과 준비물을 기억해 이를 잊지 않도록 메시지로 전송∙카나는 상주하는 그룹대화 안에서의 대화 내용만 기억해 이용자를 지원하며, 가령 스터디 그룹대화에서 함께 읽은 논문 관련 퀴즈를 내주고 채점과 부연 설명을 제공 ∙카카오는 카나나를 카카오톡과 별개의 앱으로 출시할 예정으로, 연내 사내 테스트 버전 출시를 통해 완성도를 높여갈 계획n카카오는 자체 생성AI 모델도 연구개발 중으로, 언어모델은 용량에 따라 △카나나 플래그 △카나나 에센스 △카나나 나노로 분류되며, 글로벌 수준의 성능을 갖춘 에센스와 나노를 중심으로 카카오의 주요 서비스에 적용할 계획n카카오는 이번 행사에서 내부의 AI 리스크 관리 체계인 ‘Kakao ASI(AI Safety Initiative)’도 강조∙Kakao ASI는 안전하고 윤리적인 AI 기술 개발 및 운영 시스템을 구축하기 위한 종합 지침으로서, 기술의'), Document(metadata={'source': 'ai_industry.pdf', 'page': 13}, page_content='1. 정책/법제  2. 기업/산업 3. 기술/연구  4. 인력/교육\\n11\\n카카오, 통합 AI 브랜드 겸 신규 AI 서비스 ‘카나나’ 공개n카카오가 대화의 맥락 속에서 주요 정보를 기억해 이용자에게 최적화된 답변을 제공하는 AI 메이트 서비스인 ‘카나나’를 공개 했으며 카카오톡과 별개의 앱으로 출시 예정n카카오는 자체 언어모델로 용량 별로 카나나 플래그, 카나나 에센스, 카나나 나노도 개발 중으로, 에센스와 나노를 중심으로 주요 서비스에 적용할 계획 \\nKEY Contents'), Document(metadata={'source': 'ai_industry.pdf', 'page': 13}, page_content='에센스 △카나나 나노로 분류되며, 글로벌 수준의 성능을 갖춘 에센스와 나노를 중심으로 카카오의 주요 서비스에 적용할 계획n카카오는 이번 행사에서 내부의 AI 리스크 관리 체계인 ‘Kakao ASI(AI Safety Initiative)’도 강조∙Kakao ASI는 안전하고 윤리적인 AI 기술 개발 및 운영 시스템을 구축하기 위한 종합 지침으로서, 기술의 설계부터 개발, 테스트, 배포, 모니터링, 업데이트 등 AI 시스템의 전 생애주기에서 발생할 수 있는 리스크에 선제적 대응 추구 ☞ 출처: Kakao, 카카오, ‘if(kakaoAI)2024’에서 그룹 AI 비전 공개…AI 메이트 ‘카나나’도 처음 선보여, 2024.10.22.')], 'question': 'prompt3\\n\\nsystem\\n아래의 지침에 따라 행동해\\n\\n#역할\\n- 소프트웨어 정책연구소(SPRi)의 홍보담당자 \\n\\n#톤\\n-친절함\\n-정중함\\n\\n#주의사항\\n1. 답변은 주어진 문서에 근거해야 함\\n2. 전문용어를 피하고 예시를 들어 대중들이 이해하기 쉽게 대답해야 함\\n3. 사용자가 문서에 포함되지 않는 내용을 질문하면,  문서에 없다는 답변과 함께 SPRi에 문의하도록 함\\n4. 3의 문의는 아래의 홈페이지 주소, 이메일주소, 전화번호를 안내함\\n홈페이지 : https://spri.kr/\\nAI정책연구실(hs.lee@spri.kr, 031-739-7333)\\n\\nhuman\\n\\nQuestion: {question} \\n\\nContext: {context} \\n\\nAnswer:\\n카나나의 의미?'}\n",
      "Response for prompt3.txt:\n",
      "카나나는 카카오의 신규 AI 브랜드로, '나에게 배워 나처럼 생각하고 행동한다'는 의미의 네이티브(Native)와 '배우지 않아도 자연스럽게 사용 가능한 기술'이라는 의미의 내츄럴(Natural)이라는 단어를 조합하여 만들어졌습니다. 즉, '가장 나다운 AI'를 지향하는 브랜드로, 사용자에게 최적화된 개인화된 경험을 제공하는 AI 메이트 서비스입니다. 개인메이트 '나나'와 그룹메이트 '카나'로 구성되어 있으며, 이용자와의 대화 맥락을 기억하여 적절한 답변을 제공하는 것이 특징입니다.\n",
      "========================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "질문을 입력하세요 (종료하려면 'exit' 입력):  ai 안전성 평가 관점을 설명해줘\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 1: prompt1.txt\n",
      "Debug Output: {'context': [Document(metadata={'source': 'ai_industry.pdf', 'page': 16}, page_content='SPRi AI Brief |  2024-11월호\\n14\\n일본 AI안전연구소, AI 안전성에 대한 평가 관점 가이드 발간n일본 AI안전연구소는 AI 개발자나 제공자가 안전성 평가에 참조할 수 있는 ‘AI 안전성에 대한 평가 관점 가이드’를 발표n가이드는 AI 안전성의 핵심 요소를 달성하기 위한 10가지 평가 관점과 함께, 평가를 통해 효과적 조치를 취했을 때의 기대 목표를 제시\\nKEY Contents'), Document(metadata={'source': 'ai_industry.pdf', 'page': 16}, page_content='£일본 AI안전연구소, AI 개발자나 제공자의 안전성 평가를 위한 가이드라인 제시n일본 AI안전연구소(Japan AI Safety Institute)가 2024년 9월 25일 AI 개발자나 제공자가 안전성 평가 시에 참조할 수 있는 기본 개념을 제시하는 ‘AI 안전성에 대한 평가 관점 가이드’를 발간∙가이드는 AI 안전성의 핵심 요소로 △인간중심 △안전성 △공평성 △프라이버시 보호 △보안 △투명성을 제시하고, 이를 달성하기 위한 10가지 평가 관점 및 평가를 통한 효과적 조치 이후의 기대 목표를 수립평가 관점관련 AI 안전성 요소 기대 목표유해 정보의 출력 통제인간중심, 안전성, 공정성ŸLLM 시스템이 테러, 범죄, 불쾌한 표현 등 유해 정보의 출력을 통제 가능허위 정보와 조작 방지인간중심, 안전성, 투명성ŸLLM 시스템의 출력에 대한 사실 검증 메커니즘 구축ŸLLM 시스템의 출력에 의한 사용자 결정의 조작 방지공정성과 포용성인간중심, 공정성, 투명성ŸLLM 시스템 출력에 유해한 편향이 없으며 개인이나 집단에 대한 불공정한 차별 부재ŸLLM 시스템의 출력을 모든 최종 사용자가 이해 가능고위험 사용 및 비의도적 사용 대처인간중심, 안전성ŸLLM 시스템이 본래 목적과 다르게 부적절하게 사용되어도 피해나 불이익 미발생 개인정보 보호프라이버시 보호ŸLLM 시스템이 정보의 중요성에 따라 프라이버시를 적절히 보호보안 보안 ŸLLM 시스템의 허가되지 않은 운영 및 비의도적 수정 또는 중단으로 인한 기밀정보의 유출 방지설명 가능성투명성ŸLLM 시스템 작동에 대한 증거 제시 등을 목적으로 출력의 근거를 기술적으로 합리적인 범위에서 확인 가능견고성안전성, 투명성ŸLLM 시스템이 적대적 프롬프트, 왜곡된 데이터 및 잘못된 입력 등 예상치 않은 입력에 대해 안정적 출력을 제공데이터 품질안전성, 공정성, 투명성ŸLLM 시스템 학습을 위한 데이터가 적절한 상태로 유지되고 데이터 이력이 적절히 관리되는 상태검증 가능성투명성ŸLLM 시스템에 대한 다양한 유형의 검증이 모델 학습 단계에서'), Document(metadata={'source': 'ai_industry.pdf', 'page': 16}, page_content='<AI 안전성의 핵심 요소를 고려한 AI 안전성 평가 관점> \\nnAI 안전성 평가는 기본적으로 AI 시스템의 개발자 및 제공자에 의해 실시되며, AI 시스템 개발, 배포, 사용 단계에서 적절한 간격으로 시행될 필요∙AI 안전성 평가 범위는 개발 단계에서는 데이터, 배포와 사용 단계에서는 전체 LLM 시스템 등으로 달라질 수 있으며, 평가는 한 차례가 아니라 반복적으로 실시 ☞ 출처: Japan AI Safety Institute, AIセーフティに関する評価観点ガイドの公開, 2024.09.25.')], 'question': \"prompt1\\n\\nsystem\\n아래의 지침에 따라 행동해\\n\\n#역할\\n-주어진 문서를 기반으로 정확한 정보를 제공하는 AI\\n\\n#톤\\n-전문적\\n\\n#주의사항 \\n-문서에 명시되지 않은 사실은 답변에 포함하지 않음\\n-답변에는 문서의 표현을 최소 80% 이상 포함하되, 문맥의 일관성을 유지해야 함\\n-사용자가 문서에 없는 내용을 질문할 경우, '해당 내용은 문서에 포함되지 않았습니다'로 답변\\n\\nhuman\\n\\nQuestion: {question} \\n\\nContext: {context} \\n\\nAnswer:\\n\\n\\n\\n\\n\\n\\n\\nai 안전성 평가 관점을 설명해줘\"}\n",
      "Response for prompt1.txt:\n",
      "AI 안전성 평가는 기본적으로 AI 시스템의 개발자 및 제공자에 의해 실시되며, AI 시스템 개발, 배포, 사용 단계에서 적절한 간격으로 시행될 필요가 있습니다. 일본 AI안전연구소가 제시한 ‘AI 안전성에 대한 평가 관점 가이드’에 따르면, AI 안전성의 핵심 요소는 다음과 같습니다: 인간중심, 안전성, 공정성, 프라이버시 보호, 보안, 투명성. \n",
      "\n",
      "이 가이드는 AI 안전성을 달성하기 위한 10가지 평가 관점과 평가를 통해 효과적 조치를 취했을 때의 기대 목표를 제시하고 있습니다. 주요 평가 관점은 다음과 같습니다:\n",
      "\n",
      "1. 유해 정보의 출력 통제\n",
      "2. 허위 정보와 조작 방지\n",
      "3. 공정성과 포용성\n",
      "4. 고위험 사용 및 비의도적 사용 대처\n",
      "5. 개인정보 보호\n",
      "6. 보안\n",
      "7. 설명 가능성\n",
      "8. 견고성\n",
      "9. 데이터 품질\n",
      "10. 검증 가능성\n",
      "\n",
      "평가는 단 한 번이 아니라 반복적으로 실시되어야 하며, 개발 단계에서는 데이터와 관련된 평가를, 배포와 사용 단계에서는 전체 LLM 시스템을 대상으로 하여 시행될 수 있습니다.\n",
      "\n",
      "Prompt 2: prompt2.txt\n",
      "Debug Output: {'context': [Document(metadata={'source': 'ai_industry.pdf', 'page': 16}, page_content='SPRi AI Brief |  2024-11월호\\n14\\n일본 AI안전연구소, AI 안전성에 대한 평가 관점 가이드 발간n일본 AI안전연구소는 AI 개발자나 제공자가 안전성 평가에 참조할 수 있는 ‘AI 안전성에 대한 평가 관점 가이드’를 발표n가이드는 AI 안전성의 핵심 요소를 달성하기 위한 10가지 평가 관점과 함께, 평가를 통해 효과적 조치를 취했을 때의 기대 목표를 제시\\nKEY Contents'), Document(metadata={'source': 'ai_industry.pdf', 'page': 16}, page_content='£일본 AI안전연구소, AI 개발자나 제공자의 안전성 평가를 위한 가이드라인 제시n일본 AI안전연구소(Japan AI Safety Institute)가 2024년 9월 25일 AI 개발자나 제공자가 안전성 평가 시에 참조할 수 있는 기본 개념을 제시하는 ‘AI 안전성에 대한 평가 관점 가이드’를 발간∙가이드는 AI 안전성의 핵심 요소로 △인간중심 △안전성 △공평성 △프라이버시 보호 △보안 △투명성을 제시하고, 이를 달성하기 위한 10가지 평가 관점 및 평가를 통한 효과적 조치 이후의 기대 목표를 수립평가 관점관련 AI 안전성 요소 기대 목표유해 정보의 출력 통제인간중심, 안전성, 공정성ŸLLM 시스템이 테러, 범죄, 불쾌한 표현 등 유해 정보의 출력을 통제 가능허위 정보와 조작 방지인간중심, 안전성, 투명성ŸLLM 시스템의 출력에 대한 사실 검증 메커니즘 구축ŸLLM 시스템의 출력에 의한 사용자 결정의 조작 방지공정성과 포용성인간중심, 공정성, 투명성ŸLLM 시스템 출력에 유해한 편향이 없으며 개인이나 집단에 대한 불공정한 차별 부재ŸLLM 시스템의 출력을 모든 최종 사용자가 이해 가능고위험 사용 및 비의도적 사용 대처인간중심, 안전성ŸLLM 시스템이 본래 목적과 다르게 부적절하게 사용되어도 피해나 불이익 미발생 개인정보 보호프라이버시 보호ŸLLM 시스템이 정보의 중요성에 따라 프라이버시를 적절히 보호보안 보안 ŸLLM 시스템의 허가되지 않은 운영 및 비의도적 수정 또는 중단으로 인한 기밀정보의 유출 방지설명 가능성투명성ŸLLM 시스템 작동에 대한 증거 제시 등을 목적으로 출력의 근거를 기술적으로 합리적인 범위에서 확인 가능견고성안전성, 투명성ŸLLM 시스템이 적대적 프롬프트, 왜곡된 데이터 및 잘못된 입력 등 예상치 않은 입력에 대해 안정적 출력을 제공데이터 품질안전성, 공정성, 투명성ŸLLM 시스템 학습을 위한 데이터가 적절한 상태로 유지되고 데이터 이력이 적절히 관리되는 상태검증 가능성투명성ŸLLM 시스템에 대한 다양한 유형의 검증이 모델 학습 단계에서'), Document(metadata={'source': 'ai_industry.pdf', 'page': 16}, page_content='<AI 안전성의 핵심 요소를 고려한 AI 안전성 평가 관점> \\nnAI 안전성 평가는 기본적으로 AI 시스템의 개발자 및 제공자에 의해 실시되며, AI 시스템 개발, 배포, 사용 단계에서 적절한 간격으로 시행될 필요∙AI 안전성 평가 범위는 개발 단계에서는 데이터, 배포와 사용 단계에서는 전체 LLM 시스템 등으로 달라질 수 있으며, 평가는 한 차례가 아니라 반복적으로 실시 ☞ 출처: Japan AI Safety Institute, AIセーフティに関する評価観点ガイドの公開, 2024.09.25.')], 'question': 'prompt2\\n\\nsystem\\n아래의 지침에 따라 행동해\\n\\n#역할\\n-주어진 문서를 기반으로 정보를 제공하는 AI\\n\\n#톤\\n-중립적\\n\\n#주의사항\\n1. 가능하다면 100자 이내로 답변하되, 중요 정보를 누락하면 안 됨\\n2. 1번을 만족하기 위해 내용을 요약하거나 재구성해도 됨\\n3. 문서에 없는 내용이라도 문서 내용을 기반으로 답변하려고 노력하되, 문서에 직접 명시되지 않았음을 언급해야 함\\n\\n\\nhuman\\n\\nQuestion: {question} \\n\\nContext: {context} \\n\\nAnswer:\\n\\nai 안전성 평가 관점을 설명해줘'}\n",
      "Response for prompt2.txt:\n",
      "AI 안전성 평가는 AI 시스템의 개발자 및 제공자가 실시하며, 핵심 요소로는 인간중심, 안전성, 공정성, 프라이버시 보호 등이 포함됩니다. 10가지 평가 관점을 통해 유해 정보 통제, 허위 정보 방지, 공정성 확보 등을 목표로 삼습니다. 평가 과정은 반복적으로 이루어져야 합니다.\n",
      "\n",
      "Prompt 3: prompt3.txt\n",
      "Debug Output: {'context': [Document(metadata={'source': 'ai_industry.pdf', 'page': 16}, page_content='SPRi AI Brief |  2024-11월호\\n14\\n일본 AI안전연구소, AI 안전성에 대한 평가 관점 가이드 발간n일본 AI안전연구소는 AI 개발자나 제공자가 안전성 평가에 참조할 수 있는 ‘AI 안전성에 대한 평가 관점 가이드’를 발표n가이드는 AI 안전성의 핵심 요소를 달성하기 위한 10가지 평가 관점과 함께, 평가를 통해 효과적 조치를 취했을 때의 기대 목표를 제시\\nKEY Contents'), Document(metadata={'source': 'ai_industry.pdf', 'page': 16}, page_content='£일본 AI안전연구소, AI 개발자나 제공자의 안전성 평가를 위한 가이드라인 제시n일본 AI안전연구소(Japan AI Safety Institute)가 2024년 9월 25일 AI 개발자나 제공자가 안전성 평가 시에 참조할 수 있는 기본 개념을 제시하는 ‘AI 안전성에 대한 평가 관점 가이드’를 발간∙가이드는 AI 안전성의 핵심 요소로 △인간중심 △안전성 △공평성 △프라이버시 보호 △보안 △투명성을 제시하고, 이를 달성하기 위한 10가지 평가 관점 및 평가를 통한 효과적 조치 이후의 기대 목표를 수립평가 관점관련 AI 안전성 요소 기대 목표유해 정보의 출력 통제인간중심, 안전성, 공정성ŸLLM 시스템이 테러, 범죄, 불쾌한 표현 등 유해 정보의 출력을 통제 가능허위 정보와 조작 방지인간중심, 안전성, 투명성ŸLLM 시스템의 출력에 대한 사실 검증 메커니즘 구축ŸLLM 시스템의 출력에 의한 사용자 결정의 조작 방지공정성과 포용성인간중심, 공정성, 투명성ŸLLM 시스템 출력에 유해한 편향이 없으며 개인이나 집단에 대한 불공정한 차별 부재ŸLLM 시스템의 출력을 모든 최종 사용자가 이해 가능고위험 사용 및 비의도적 사용 대처인간중심, 안전성ŸLLM 시스템이 본래 목적과 다르게 부적절하게 사용되어도 피해나 불이익 미발생 개인정보 보호프라이버시 보호ŸLLM 시스템이 정보의 중요성에 따라 프라이버시를 적절히 보호보안 보안 ŸLLM 시스템의 허가되지 않은 운영 및 비의도적 수정 또는 중단으로 인한 기밀정보의 유출 방지설명 가능성투명성ŸLLM 시스템 작동에 대한 증거 제시 등을 목적으로 출력의 근거를 기술적으로 합리적인 범위에서 확인 가능견고성안전성, 투명성ŸLLM 시스템이 적대적 프롬프트, 왜곡된 데이터 및 잘못된 입력 등 예상치 않은 입력에 대해 안정적 출력을 제공데이터 품질안전성, 공정성, 투명성ŸLLM 시스템 학습을 위한 데이터가 적절한 상태로 유지되고 데이터 이력이 적절히 관리되는 상태검증 가능성투명성ŸLLM 시스템에 대한 다양한 유형의 검증이 모델 학습 단계에서'), Document(metadata={'source': 'ai_industry.pdf', 'page': 16}, page_content='<AI 안전성의 핵심 요소를 고려한 AI 안전성 평가 관점> \\nnAI 안전성 평가는 기본적으로 AI 시스템의 개발자 및 제공자에 의해 실시되며, AI 시스템 개발, 배포, 사용 단계에서 적절한 간격으로 시행될 필요∙AI 안전성 평가 범위는 개발 단계에서는 데이터, 배포와 사용 단계에서는 전체 LLM 시스템 등으로 달라질 수 있으며, 평가는 한 차례가 아니라 반복적으로 실시 ☞ 출처: Japan AI Safety Institute, AIセーフティに関する評価観点ガイドの公開, 2024.09.25.')], 'question': 'prompt3\\n\\nsystem\\n아래의 지침에 따라 행동해\\n\\n#역할\\n- 소프트웨어 정책연구소(SPRi)의 홍보담당자 \\n\\n#톤\\n-친절함\\n-정중함\\n\\n#주의사항\\n1. 답변은 주어진 문서에 근거해야 함\\n2. 전문용어를 피하고 예시를 들어 대중들이 이해하기 쉽게 대답해야 함\\n3. 사용자가 문서에 포함되지 않는 내용을 질문하면,  문서에 없다는 답변과 함께 SPRi에 문의하도록 함\\n4. 3의 문의는 아래의 홈페이지 주소, 이메일주소, 전화번호를 안내함\\n홈페이지 : https://spri.kr/\\nAI정책연구실(hs.lee@spri.kr, 031-739-7333)\\n\\nhuman\\n\\nQuestion: {question} \\n\\nContext: {context} \\n\\nAnswer:\\nai 안전성 평가 관점을 설명해줘'}\n",
      "Response for prompt3.txt:\n",
      "AI 안전성 평가 관점은 일본 AI안전연구소가 발표한 가이드라인에 기반하여 AI 시스템의 안정성과 신뢰성을 확보하기 위해 중요한 요소들을 평가하는 기준입니다. 이 평가 관점은 총 10가지로 구성되어 있으며, 각 관점은 AI의 안전성을 높이기 위해 필요한 특정 목표를 제시합니다. \n",
      "\n",
      "예를 들어, '유해 정보의 출력 통제'라는 관점은 AI 시스템이 테러나 범죄와 관련된 위험한 정보를 출력하지 않도록 하는 것을 목표로 합니다. 또 다른 예로, '공정성과 포용성'은 AI 시스템의 출력이 특정 개인이나 집단에 대해 불공정한 차별을 하지 않도록 보장하는 것입니다. \n",
      "\n",
      "이러한 평가 관점들은 AI 시스템이 개발, 배포 및 사용되는 모든 단계에서 반복적으로 시행되어야 하며, 이를 통해 AI의 안전성과 신뢰성을 지속적으로 강화할 수 있습니다. \n",
      "\n",
      "더 많은 정보가 필요하시거나 구체적인 질문이 있으시면, SPRi에 문의해주시면 친절히 안내해드리겠습니다. 홈페이지: [https://spri.kr/](https://spri.kr/), 이메일: hs.lee@spri.kr, 전화번호: 031-739-7333입니다.\n",
      "========================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "질문을 입력하세요 (종료하려면 'exit' 입력):  가트너 예측을 설명해줘\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 1: prompt1.txt\n",
      "Debug Output: {'context': [Document(metadata={'source': 'ai_industry.pdf', 'page': 9}, page_content='평가자가 점수를 매겨 비교 후 순승률(Net Win Rate)*을 계산한 결과, 메타 무비 젠은 젠 3와 소라, 클링(Kling) 1.5를 모두 능가* 두 모델(A와 B)에 대하여 3명의 인간 평가자가 A 선호 시 +1점, 동점이면 0점, B 선호 시 –1점을 매기는 식으로 계산해 승률(-100%~100% 값)을 구하며, 승률이 양수면 A 모델 선호, 음수면 B 모델 선호를 의미'), Document(metadata={'source': 'ai_industry.pdf', 'page': 21}, page_content='1. 정책/법제  2. 기업/산업 3. 기술/연구  4. 인력/교육\\n19\\n가트너 예측, AI로 인해 엔지니어링 인력의 80%가 역량 향상 필요n가트너에 따르면 생성AI의 도입으로 중장기적으로 소프트웨어 엔지니어링에서 데이터 과학 및 AI/ML 역량의 중요성이 커지면서 AI 엔지니어의 수요가 늘어날 전망n기업들은 AI 엔지니어를 지원하고 기업 내 AI 통합을 촉진하기 위해 AI 개발자 플랫폼에 대한 투자를 강화할 필요\\nKEY Contents'), Document(metadata={'source': 'ai_industry.pdf', 'page': 18}, page_content='역시 맘바 아키텍처를 토대로 더 빠른 추론 시간과 더 긴 컨텍스트를 지원하는 잠바 아키텍처를 활용해 기반모델을 개발n고센 CEO는 AI 에이전트가 최근 들어서야 부상하고 있으며 대다수 AI 에이전트가 아직 상용화되지 않은 이유가 트랜스포머로 구축된 LLM의 한계 때문이라고 지적∙AI 에이전트가 상용화되려면 데이터 간 연관성을 파악해 확률적으로 가장 그럴듯한 답변을 생성하는 LLM의 신뢰성을 높여야 하며, 필요한 수준의 신뢰성 보장을 위해서는 추가적인 요소의 통합이 필요 ∙최근 서비스나우(ServiceNow), 세일즈포스 등 여러 기업이 AI 에이전트나 에이전트 구축을 지원하는 플랫폼을 출시하는 추세로, 고센 CEO는 이러한 추세가 적절한 기반모델과 아키텍처를 조합함으로써 더욱 확산될 것으로 예상☞ 출처: Venturebeat, AI21 CEO says transformers not right for AI agents due to error perpetuation, 2024.10.11.')], 'question': \"prompt1\\n\\nsystem\\n아래의 지침에 따라 행동해\\n\\n#역할\\n-주어진 문서를 기반으로 정확한 정보를 제공하는 AI\\n\\n#톤\\n-전문적\\n\\n#주의사항 \\n-문서에 명시되지 않은 사실은 답변에 포함하지 않음\\n-답변에는 문서의 표현을 최소 80% 이상 포함하되, 문맥의 일관성을 유지해야 함\\n-사용자가 문서에 없는 내용을 질문할 경우, '해당 내용은 문서에 포함되지 않았습니다'로 답변\\n\\nhuman\\n\\nQuestion: {question} \\n\\nContext: {context} \\n\\nAnswer:\\n\\n\\n\\n\\n\\n\\n\\n가트너 예측을 설명해줘\"}\n",
      "Response for prompt1.txt:\n",
      "가트너에 따르면, 생성AI의 도입으로 중장기적으로 소프트웨어 엔지니어링에서 데이터 과학 및 AI/ML 역량의 중요성이 커지면서 AI 엔지니어의 수요가 늘어날 전망입니다. 따라서 기업들은 AI 엔지니어를 지원하고 기업 내 AI 통합을 촉진하기 위해 AI 개발자 플랫폼에 대한 투자를 강화할 필요가 있습니다.\n",
      "\n",
      "Prompt 2: prompt2.txt\n",
      "Debug Output: {'context': [Document(metadata={'source': 'ai_industry.pdf', 'page': 9}, page_content='평가자가 점수를 매겨 비교 후 순승률(Net Win Rate)*을 계산한 결과, 메타 무비 젠은 젠 3와 소라, 클링(Kling) 1.5를 모두 능가* 두 모델(A와 B)에 대하여 3명의 인간 평가자가 A 선호 시 +1점, 동점이면 0점, B 선호 시 –1점을 매기는 식으로 계산해 승률(-100%~100% 값)을 구하며, 승률이 양수면 A 모델 선호, 음수면 B 모델 선호를 의미'), Document(metadata={'source': 'ai_industry.pdf', 'page': 21}, page_content='1. 정책/법제  2. 기업/산업 3. 기술/연구  4. 인력/교육\\n19\\n가트너 예측, AI로 인해 엔지니어링 인력의 80%가 역량 향상 필요n가트너에 따르면 생성AI의 도입으로 중장기적으로 소프트웨어 엔지니어링에서 데이터 과학 및 AI/ML 역량의 중요성이 커지면서 AI 엔지니어의 수요가 늘어날 전망n기업들은 AI 엔지니어를 지원하고 기업 내 AI 통합을 촉진하기 위해 AI 개발자 플랫폼에 대한 투자를 강화할 필요\\nKEY Contents'), Document(metadata={'source': 'ai_industry.pdf', 'page': 18}, page_content='역시 맘바 아키텍처를 토대로 더 빠른 추론 시간과 더 긴 컨텍스트를 지원하는 잠바 아키텍처를 활용해 기반모델을 개발n고센 CEO는 AI 에이전트가 최근 들어서야 부상하고 있으며 대다수 AI 에이전트가 아직 상용화되지 않은 이유가 트랜스포머로 구축된 LLM의 한계 때문이라고 지적∙AI 에이전트가 상용화되려면 데이터 간 연관성을 파악해 확률적으로 가장 그럴듯한 답변을 생성하는 LLM의 신뢰성을 높여야 하며, 필요한 수준의 신뢰성 보장을 위해서는 추가적인 요소의 통합이 필요 ∙최근 서비스나우(ServiceNow), 세일즈포스 등 여러 기업이 AI 에이전트나 에이전트 구축을 지원하는 플랫폼을 출시하는 추세로, 고센 CEO는 이러한 추세가 적절한 기반모델과 아키텍처를 조합함으로써 더욱 확산될 것으로 예상☞ 출처: Venturebeat, AI21 CEO says transformers not right for AI agents due to error perpetuation, 2024.10.11.')], 'question': 'prompt2\\n\\nsystem\\n아래의 지침에 따라 행동해\\n\\n#역할\\n-주어진 문서를 기반으로 정보를 제공하는 AI\\n\\n#톤\\n-중립적\\n\\n#주의사항\\n1. 가능하다면 100자 이내로 답변하되, 중요 정보를 누락하면 안 됨\\n2. 1번을 만족하기 위해 내용을 요약하거나 재구성해도 됨\\n3. 문서에 없는 내용이라도 문서 내용을 기반으로 답변하려고 노력하되, 문서에 직접 명시되지 않았음을 언급해야 함\\n\\n\\nhuman\\n\\nQuestion: {question} \\n\\nContext: {context} \\n\\nAnswer:\\n\\n가트너 예측을 설명해줘'}\n",
      "Response for prompt2.txt:\n",
      "가트너는 생성AI 도입으로 소프트웨어 엔지니어링에서 데이터 과학 및 AI/ML 역량의 중요성이 증가하고 AI 엔지니어 수요가 늘어날 것이라고 예측하고 있습니다. 기업들은 AI 개발자 플랫폼에 대한 투자를 강화해야 합니다.\n",
      "\n",
      "Prompt 3: prompt3.txt\n",
      "Debug Output: {'context': [Document(metadata={'source': 'ai_industry.pdf', 'page': 9}, page_content='평가자가 점수를 매겨 비교 후 순승률(Net Win Rate)*을 계산한 결과, 메타 무비 젠은 젠 3와 소라, 클링(Kling) 1.5를 모두 능가* 두 모델(A와 B)에 대하여 3명의 인간 평가자가 A 선호 시 +1점, 동점이면 0점, B 선호 시 –1점을 매기는 식으로 계산해 승률(-100%~100% 값)을 구하며, 승률이 양수면 A 모델 선호, 음수면 B 모델 선호를 의미'), Document(metadata={'source': 'ai_industry.pdf', 'page': 21}, page_content='1. 정책/법제  2. 기업/산업 3. 기술/연구  4. 인력/교육\\n19\\n가트너 예측, AI로 인해 엔지니어링 인력의 80%가 역량 향상 필요n가트너에 따르면 생성AI의 도입으로 중장기적으로 소프트웨어 엔지니어링에서 데이터 과학 및 AI/ML 역량의 중요성이 커지면서 AI 엔지니어의 수요가 늘어날 전망n기업들은 AI 엔지니어를 지원하고 기업 내 AI 통합을 촉진하기 위해 AI 개발자 플랫폼에 대한 투자를 강화할 필요\\nKEY Contents'), Document(metadata={'source': 'ai_industry.pdf', 'page': 18}, page_content='역시 맘바 아키텍처를 토대로 더 빠른 추론 시간과 더 긴 컨텍스트를 지원하는 잠바 아키텍처를 활용해 기반모델을 개발n고센 CEO는 AI 에이전트가 최근 들어서야 부상하고 있으며 대다수 AI 에이전트가 아직 상용화되지 않은 이유가 트랜스포머로 구축된 LLM의 한계 때문이라고 지적∙AI 에이전트가 상용화되려면 데이터 간 연관성을 파악해 확률적으로 가장 그럴듯한 답변을 생성하는 LLM의 신뢰성을 높여야 하며, 필요한 수준의 신뢰성 보장을 위해서는 추가적인 요소의 통합이 필요 ∙최근 서비스나우(ServiceNow), 세일즈포스 등 여러 기업이 AI 에이전트나 에이전트 구축을 지원하는 플랫폼을 출시하는 추세로, 고센 CEO는 이러한 추세가 적절한 기반모델과 아키텍처를 조합함으로써 더욱 확산될 것으로 예상☞ 출처: Venturebeat, AI21 CEO says transformers not right for AI agents due to error perpetuation, 2024.10.11.')], 'question': 'prompt3\\n\\nsystem\\n아래의 지침에 따라 행동해\\n\\n#역할\\n- 소프트웨어 정책연구소(SPRi)의 홍보담당자 \\n\\n#톤\\n-친절함\\n-정중함\\n\\n#주의사항\\n1. 답변은 주어진 문서에 근거해야 함\\n2. 전문용어를 피하고 예시를 들어 대중들이 이해하기 쉽게 대답해야 함\\n3. 사용자가 문서에 포함되지 않는 내용을 질문하면,  문서에 없다는 답변과 함께 SPRi에 문의하도록 함\\n4. 3의 문의는 아래의 홈페이지 주소, 이메일주소, 전화번호를 안내함\\n홈페이지 : https://spri.kr/\\nAI정책연구실(hs.lee@spri.kr, 031-739-7333)\\n\\nhuman\\n\\nQuestion: {question} \\n\\nContext: {context} \\n\\nAnswer:\\n가트너 예측을 설명해줘'}\n",
      "Response for prompt3.txt:\n",
      "가트너의 예측에 따르면, 인공지능(AI)의 도입으로 인해 소프트웨어 엔지니어링 분야에서 엔지니어의 80%가 새로운 역량을 갖추어야 할 필요성이 커지고 있습니다. 이는 데이터 과학 및 AI/머신러닝(ML) 역량의 중요성이 높아지면서 AI 엔지니어에 대한 수요가 증가할 것이라는 전망을 의미합니다. \n",
      "\n",
      "따라서 기업들은 AI 엔지니어를 지원하고, 조직 내에서 AI 기술을 통합하기 위해 AI 개발자 플랫폼에 대한 투자를 강화해야 할 필요가 있습니다. 쉽게 말해, 앞으로 소프트웨어 엔지니어들이 AI와 관련된 기술을 배우고 활용할 수 있도록 준비해야 한다는 것입니다. \n",
      "\n",
      "이와 같은 변화는 기업들이 경쟁력을 유지하기 위해 필수적이므로, 보다 많은 인력이 AI 기술에 대한 교육을 받고 준비하는 것이 중요해질 것입니다. 더 궁금한 사항이 있으시면 SPRi에 문의해 주시기 바랍니다. \n",
      "\n",
      "홈페이지: [https://spri.kr/](https://spri.kr/)  \n",
      "이메일: hs.lee@spri.kr  \n",
      "전화번호: 031-739-7333\n",
      "========================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "질문을 입력하세요 (종료하려면 'exit' 입력):  cb인사이츠는 스타트업에 대해 어떻게 생각하는지 알려줘\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 1: prompt1.txt\n",
      "Debug Output: {'context': [Document(metadata={'source': 'ai_industry.pdf', 'page': 8}, page_content='SPRi AI Brief |  2024-11월호\\n6\\nCB인사이츠 분석 결과, 2024년 3분기 벤처 투자 31%가 AI 스타트업에 집중nCB인사이츠에 따르면 2024년 3분기 AI 스타트업은 전체 벤처 투자의 31%를 유치했으며, AI 스타트업의 투자금 회수 시점은 일반 기업보다 6년 빠른 것으로 확인n그러나 CB인사이츠는 투자자들의 낙관적 기대에도 불구하고 오픈AI와 같은 거대 기업도 비용 통제에 어려움을 겪고 있다며 상당수 AI 스타트업이 실패할 것으로 예상\\nKEY Contents'), Document(metadata={'source': 'ai_industry.pdf', 'page': 8}, page_content='£AI 스타트업, 벤처 투자의 최우선 고려 대상으로 부상n글로벌 리서치 기업 CB인사이츠(CB Insights)가 2024년 10월 3일 발표한 2024년 3분기 벤처 현황 보고서에 따르면 2024년 3분기 벤처 자금의 31%가 AI 스타트업에 투자된 것으로 분석  ∙AI 스타트업은 2024년 2분기에 전체 벤처 투자의 35%를 유치하며 역대 최고 비중을 차지했으며, 3분기에도 역대 두 번째로 높은 비중을 기록∙오픈AI의 공동설립자 일리야 수츠케버(Ilya Sutskever)가 2024년 6월 설립한 스타트업 SSI(Safe Superintelligence Inc.)는 10억 달러를 유치하며 3분기 대표적인 AI 투자로 기록∙CB인사이츠가 전 세계 1만 5천 개 이상의 AI 스타트업을 추적한 결과, 전 세계 AI 스타트업의 43%가 미국 기업이며, 다음 순위는 중국이 9%, 영국이 7%, 인도와 캐나다가 각각 4%로 미국과 상당한 격차를 기록n기업가치 10억 달러 이상의 유니콘 기업은 2024년 3분기에 24개가 탄생했으며, 이중 절반 이상이 AI 기업인 것으로 확인∙범용 로봇 개발기업 스킬드AI(Skild AI), 공간지능에 특화된 월드랩스(World Labs), 법률 AI 서비스 기업 하비(Harvey) 등이 유니콘 지위를 획득nAI 스타트업은 투자금 회수(Exit) 시점도 일반 스타트업보다 훨씬 빨라 AI 기업이 엑시트하는 시점은 설립 후 7년에 불과했으나 여타 스타트업은 13년 소요되었으며, 이러한 경향은 M&A에서 가장 뚜렷해 2024년 AI 스타트업 엑시트는 대부분 M&A를 통해 달성∙대기업들은 자사 제품군에 AI 도구를 신속히 도입하고자 AI 스타트업 인수에 적극적인 행보를 보이고 있으며, 일례로 엔비디아(Nvidia)는 2024년에 AI 스타트업 3곳을 인수했고, 세일즈포스(Salesforce)는 2024년 9월 AI 스타트업 2곳을 인수n그러나 CB인사이츠는 투자자들의 낙관적 기대에도 불구하고 현재의 AI스타트업 중 상당수는 기대에 부응하지'), Document(metadata={'source': 'ai_industry.pdf', 'page': 8}, page_content='자사 제품군에 AI 도구를 신속히 도입하고자 AI 스타트업 인수에 적극적인 행보를 보이고 있으며, 일례로 엔비디아(Nvidia)는 2024년에 AI 스타트업 3곳을 인수했고, 세일즈포스(Salesforce)는 2024년 9월 AI 스타트업 2곳을 인수n그러나 CB인사이츠는 투자자들의 낙관적 기대에도 불구하고 현재의 AI스타트업 중 상당수는 기대에 부응하지 못하고 실패하게 될 것으로 예상∙CB인사이츠는 오픈AI와 같은 거대 AI 기업조차도 수익을 내지 못해 비용을 통제해야 하는 어려움을 겪고 있다며, 오픈AI의 2024년 손실 규모가 50억 달러에 달할 것으로 전망☞ 출처 : CB Insights, State of Venture Q3’24 Report, 2024.10.03.')], 'question': \"prompt1\\n\\nsystem\\n아래의 지침에 따라 행동해\\n\\n#역할\\n-주어진 문서를 기반으로 정확한 정보를 제공하는 AI\\n\\n#톤\\n-전문적\\n\\n#주의사항 \\n-문서에 명시되지 않은 사실은 답변에 포함하지 않음\\n-답변에는 문서의 표현을 최소 80% 이상 포함하되, 문맥의 일관성을 유지해야 함\\n-사용자가 문서에 없는 내용을 질문할 경우, '해당 내용은 문서에 포함되지 않았습니다'로 답변\\n\\nhuman\\n\\nQuestion: {question} \\n\\nContext: {context} \\n\\nAnswer:\\n\\n\\n\\n\\n\\n\\n\\ncb인사이츠는 스타트업에 대해 어떻게 생각하는지 알려줘\"}\n",
      "Response for prompt1.txt:\n",
      "CB인사이츠는 AI 스타트업에 대해 긍정적인 시각을 가지고 있으며, 2024년 3분기 벤처 투자 가운데 31%가 AI 스타트업에 집중되었다고 분석했습니다. AI 스타트업은 투자금 회수 시점이 일반 스타트업보다 6년 빠르며, M&A를 통해 엑시트를 달성하는 경향이 뚜렷하다고 언급했습니다. 그러나 CB인사이츠는 현재의 AI 스타트업 중 상당수는 기대에 부응하지 못하고 실패할 것으로 예상하고 있으며, 오픈AI와 같은 대기업조차도 수익을 내지 못하고 비용 통제에 어려움을 겪고 있다고 지적했습니다.\n",
      "\n",
      "Prompt 2: prompt2.txt\n",
      "Debug Output: {'context': [Document(metadata={'source': 'ai_industry.pdf', 'page': 8}, page_content='SPRi AI Brief |  2024-11월호\\n6\\nCB인사이츠 분석 결과, 2024년 3분기 벤처 투자 31%가 AI 스타트업에 집중nCB인사이츠에 따르면 2024년 3분기 AI 스타트업은 전체 벤처 투자의 31%를 유치했으며, AI 스타트업의 투자금 회수 시점은 일반 기업보다 6년 빠른 것으로 확인n그러나 CB인사이츠는 투자자들의 낙관적 기대에도 불구하고 오픈AI와 같은 거대 기업도 비용 통제에 어려움을 겪고 있다며 상당수 AI 스타트업이 실패할 것으로 예상\\nKEY Contents'), Document(metadata={'source': 'ai_industry.pdf', 'page': 8}, page_content='£AI 스타트업, 벤처 투자의 최우선 고려 대상으로 부상n글로벌 리서치 기업 CB인사이츠(CB Insights)가 2024년 10월 3일 발표한 2024년 3분기 벤처 현황 보고서에 따르면 2024년 3분기 벤처 자금의 31%가 AI 스타트업에 투자된 것으로 분석  ∙AI 스타트업은 2024년 2분기에 전체 벤처 투자의 35%를 유치하며 역대 최고 비중을 차지했으며, 3분기에도 역대 두 번째로 높은 비중을 기록∙오픈AI의 공동설립자 일리야 수츠케버(Ilya Sutskever)가 2024년 6월 설립한 스타트업 SSI(Safe Superintelligence Inc.)는 10억 달러를 유치하며 3분기 대표적인 AI 투자로 기록∙CB인사이츠가 전 세계 1만 5천 개 이상의 AI 스타트업을 추적한 결과, 전 세계 AI 스타트업의 43%가 미국 기업이며, 다음 순위는 중국이 9%, 영국이 7%, 인도와 캐나다가 각각 4%로 미국과 상당한 격차를 기록n기업가치 10억 달러 이상의 유니콘 기업은 2024년 3분기에 24개가 탄생했으며, 이중 절반 이상이 AI 기업인 것으로 확인∙범용 로봇 개발기업 스킬드AI(Skild AI), 공간지능에 특화된 월드랩스(World Labs), 법률 AI 서비스 기업 하비(Harvey) 등이 유니콘 지위를 획득nAI 스타트업은 투자금 회수(Exit) 시점도 일반 스타트업보다 훨씬 빨라 AI 기업이 엑시트하는 시점은 설립 후 7년에 불과했으나 여타 스타트업은 13년 소요되었으며, 이러한 경향은 M&A에서 가장 뚜렷해 2024년 AI 스타트업 엑시트는 대부분 M&A를 통해 달성∙대기업들은 자사 제품군에 AI 도구를 신속히 도입하고자 AI 스타트업 인수에 적극적인 행보를 보이고 있으며, 일례로 엔비디아(Nvidia)는 2024년에 AI 스타트업 3곳을 인수했고, 세일즈포스(Salesforce)는 2024년 9월 AI 스타트업 2곳을 인수n그러나 CB인사이츠는 투자자들의 낙관적 기대에도 불구하고 현재의 AI스타트업 중 상당수는 기대에 부응하지'), Document(metadata={'source': 'ai_industry.pdf', 'page': 8}, page_content='자사 제품군에 AI 도구를 신속히 도입하고자 AI 스타트업 인수에 적극적인 행보를 보이고 있으며, 일례로 엔비디아(Nvidia)는 2024년에 AI 스타트업 3곳을 인수했고, 세일즈포스(Salesforce)는 2024년 9월 AI 스타트업 2곳을 인수n그러나 CB인사이츠는 투자자들의 낙관적 기대에도 불구하고 현재의 AI스타트업 중 상당수는 기대에 부응하지 못하고 실패하게 될 것으로 예상∙CB인사이츠는 오픈AI와 같은 거대 AI 기업조차도 수익을 내지 못해 비용을 통제해야 하는 어려움을 겪고 있다며, 오픈AI의 2024년 손실 규모가 50억 달러에 달할 것으로 전망☞ 출처 : CB Insights, State of Venture Q3’24 Report, 2024.10.03.')], 'question': 'prompt2\\n\\nsystem\\n아래의 지침에 따라 행동해\\n\\n#역할\\n-주어진 문서를 기반으로 정보를 제공하는 AI\\n\\n#톤\\n-중립적\\n\\n#주의사항\\n1. 가능하다면 100자 이내로 답변하되, 중요 정보를 누락하면 안 됨\\n2. 1번을 만족하기 위해 내용을 요약하거나 재구성해도 됨\\n3. 문서에 없는 내용이라도 문서 내용을 기반으로 답변하려고 노력하되, 문서에 직접 명시되지 않았음을 언급해야 함\\n\\n\\nhuman\\n\\nQuestion: {question} \\n\\nContext: {context} \\n\\nAnswer:\\n\\ncb인사이츠는 스타트업에 대해 어떻게 생각하는지 알려줘'}\n",
      "Response for prompt2.txt:\n",
      "CB인사이츠는 AI 스타트업에 대한 낙관적인 기대에도 불구하고 상당수의 스타트업이 실패할 것으로 예상하고 있으며, 대기업조차 수익을 내지 못하고 비용 통제에 어려움을 겪고 있다고 분석하고 있습니다.\n",
      "\n",
      "Prompt 3: prompt3.txt\n",
      "Debug Output: {'context': [Document(metadata={'source': 'ai_industry.pdf', 'page': 8}, page_content='SPRi AI Brief |  2024-11월호\\n6\\nCB인사이츠 분석 결과, 2024년 3분기 벤처 투자 31%가 AI 스타트업에 집중nCB인사이츠에 따르면 2024년 3분기 AI 스타트업은 전체 벤처 투자의 31%를 유치했으며, AI 스타트업의 투자금 회수 시점은 일반 기업보다 6년 빠른 것으로 확인n그러나 CB인사이츠는 투자자들의 낙관적 기대에도 불구하고 오픈AI와 같은 거대 기업도 비용 통제에 어려움을 겪고 있다며 상당수 AI 스타트업이 실패할 것으로 예상\\nKEY Contents'), Document(metadata={'source': 'ai_industry.pdf', 'page': 8}, page_content='£AI 스타트업, 벤처 투자의 최우선 고려 대상으로 부상n글로벌 리서치 기업 CB인사이츠(CB Insights)가 2024년 10월 3일 발표한 2024년 3분기 벤처 현황 보고서에 따르면 2024년 3분기 벤처 자금의 31%가 AI 스타트업에 투자된 것으로 분석  ∙AI 스타트업은 2024년 2분기에 전체 벤처 투자의 35%를 유치하며 역대 최고 비중을 차지했으며, 3분기에도 역대 두 번째로 높은 비중을 기록∙오픈AI의 공동설립자 일리야 수츠케버(Ilya Sutskever)가 2024년 6월 설립한 스타트업 SSI(Safe Superintelligence Inc.)는 10억 달러를 유치하며 3분기 대표적인 AI 투자로 기록∙CB인사이츠가 전 세계 1만 5천 개 이상의 AI 스타트업을 추적한 결과, 전 세계 AI 스타트업의 43%가 미국 기업이며, 다음 순위는 중국이 9%, 영국이 7%, 인도와 캐나다가 각각 4%로 미국과 상당한 격차를 기록n기업가치 10억 달러 이상의 유니콘 기업은 2024년 3분기에 24개가 탄생했으며, 이중 절반 이상이 AI 기업인 것으로 확인∙범용 로봇 개발기업 스킬드AI(Skild AI), 공간지능에 특화된 월드랩스(World Labs), 법률 AI 서비스 기업 하비(Harvey) 등이 유니콘 지위를 획득nAI 스타트업은 투자금 회수(Exit) 시점도 일반 스타트업보다 훨씬 빨라 AI 기업이 엑시트하는 시점은 설립 후 7년에 불과했으나 여타 스타트업은 13년 소요되었으며, 이러한 경향은 M&A에서 가장 뚜렷해 2024년 AI 스타트업 엑시트는 대부분 M&A를 통해 달성∙대기업들은 자사 제품군에 AI 도구를 신속히 도입하고자 AI 스타트업 인수에 적극적인 행보를 보이고 있으며, 일례로 엔비디아(Nvidia)는 2024년에 AI 스타트업 3곳을 인수했고, 세일즈포스(Salesforce)는 2024년 9월 AI 스타트업 2곳을 인수n그러나 CB인사이츠는 투자자들의 낙관적 기대에도 불구하고 현재의 AI스타트업 중 상당수는 기대에 부응하지'), Document(metadata={'source': 'ai_industry.pdf', 'page': 8}, page_content='자사 제품군에 AI 도구를 신속히 도입하고자 AI 스타트업 인수에 적극적인 행보를 보이고 있으며, 일례로 엔비디아(Nvidia)는 2024년에 AI 스타트업 3곳을 인수했고, 세일즈포스(Salesforce)는 2024년 9월 AI 스타트업 2곳을 인수n그러나 CB인사이츠는 투자자들의 낙관적 기대에도 불구하고 현재의 AI스타트업 중 상당수는 기대에 부응하지 못하고 실패하게 될 것으로 예상∙CB인사이츠는 오픈AI와 같은 거대 AI 기업조차도 수익을 내지 못해 비용을 통제해야 하는 어려움을 겪고 있다며, 오픈AI의 2024년 손실 규모가 50억 달러에 달할 것으로 전망☞ 출처 : CB Insights, State of Venture Q3’24 Report, 2024.10.03.')], 'question': 'prompt3\\n\\nsystem\\n아래의 지침에 따라 행동해\\n\\n#역할\\n- 소프트웨어 정책연구소(SPRi)의 홍보담당자 \\n\\n#톤\\n-친절함\\n-정중함\\n\\n#주의사항\\n1. 답변은 주어진 문서에 근거해야 함\\n2. 전문용어를 피하고 예시를 들어 대중들이 이해하기 쉽게 대답해야 함\\n3. 사용자가 문서에 포함되지 않는 내용을 질문하면,  문서에 없다는 답변과 함께 SPRi에 문의하도록 함\\n4. 3의 문의는 아래의 홈페이지 주소, 이메일주소, 전화번호를 안내함\\n홈페이지 : https://spri.kr/\\nAI정책연구실(hs.lee@spri.kr, 031-739-7333)\\n\\nhuman\\n\\nQuestion: {question} \\n\\nContext: {context} \\n\\nAnswer:\\ncb인사이츠는 스타트업에 대해 어떻게 생각하는지 알려줘'}\n",
      "Response for prompt3.txt:\n",
      "CB인사이츠는 현재의 AI 스타트업에 대해 혼합된 시각을 가지고 있습니다. 2024년 3분기 동안 AI 스타트업이 전체 벤처 투자의 31%를 차지하며 높은 관심을 받고 있지만, 동시에 상당수의 AI 스타트업이 기대에 부응하지 못하고 실패할 것으로 예상하고 있습니다. 이들은 오픈AI와 같은 대규모 기업조차도 수익을 내지 못해 어려움을 겪고 있으며, 오픈AI의 2024년 손실 규모가 50억 달러에 이를 것으로 전망하고 있습니다. 즉, 투자자들의 낙관적인 기대와는 달리, AI 스타트업의 미래에 대한 우려도 존재하는 상황입니다. \n",
      "\n",
      "더 궁금한 점이 있으시면 SPRi에 문의해 주시기 바랍니다. 홈페이지: https://spri.kr/ , 이메일: hs.lee@spri.kr , 전화번호: 031-739-7333입니다.\n",
      "========================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "질문을 입력하세요 (종료하려면 'exit' 입력):  노벨상 수상자 누가 있지\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 1: prompt1.txt\n",
      "Debug Output: {'context': [Document(metadata={'source': 'ai_industry.pdf', 'page': 14}, page_content='SPRi AI Brief |  2024-11월호\\n12\\n2024년 노벨 물리학상과 화학상, AI 관련 연구자들이 수상n2024년 노벨 물리학상은 물리학 원리를 바탕으로 인공 신경망을 이용한 머신러닝의 토대가 되는 방법을 개발한 존 홉필드와 제프리 힌턴이 수상 n2024년 노벨 화학상은 단백질 설계에 기여한 데이비드 베이커 및 단백질 구조를 예측하는 AI 모델을 개발한 딥마인드의 데미스 허사비스와 존 점퍼가 수상 \\nKEY Contents'), Document(metadata={'source': 'ai_industry.pdf', 'page': 9}, page_content='평가자가 점수를 매겨 비교 후 순승률(Net Win Rate)*을 계산한 결과, 메타 무비 젠은 젠 3와 소라, 클링(Kling) 1.5를 모두 능가* 두 모델(A와 B)에 대하여 3명의 인간 평가자가 A 선호 시 +1점, 동점이면 0점, B 선호 시 –1점을 매기는 식으로 계산해 승률(-100%~100% 값)을 구하며, 승률이 양수면 A 모델 선호, 음수면 B 모델 선호를 의미'), Document(metadata={'source': 'ai_industry.pdf', 'page': 14}, page_content='£노벨 물리학상, 인공 신경망 연구한 존 홉필드 교수와 제프리 힌턴 교수가 수상n스웨덴 왕립과학원 노벨위원회는 2024년 10월 8일 존 홉필드(John Hopfield) 미국 프린스턴⼤ 교수와 제프리 힌턴(Geoffrey Hinton) 캐나다 토론토⼤ 교수에게 인공 신경망을 이용한 머신러닝의 토대가 되는 방법을 개발한 공로로 노벨 물리학상을 수여∙홉필드는 물리학의 원리를 이용해 왜곡되거나 불완전한 입력 패턴과 가장 유사하게 저장된 패턴을 찾아내고 재구성할 수 있는 초기 인공 신경망 모델인 ‘홉필드 네트워크(Hopfield Network)’를 개발∙힌턴은 홉필드 네트워크를 토대로 ‘볼츠만 머신(Boltzmann Machine)’을 고안했으며, 이 모델은 통계물리학을 활용해 주어진 데이터에서 특징적 요소를 인식하여 인간의 개입 없이 학습된 패턴 유형을 활용해 새로운 예제를 생성 가능∙힌턴은 인공 신경망이 데이터를 통해 학습할 수 있다는 개념으로 머신러닝의 폭발적 발전을 이끌었으며, 인공 신경망은 현재 신소재 발견을 비롯한 광범위한 물리학 연구에 활용되는 추세 £노벨 화학상, 단백질 구조 예측 AI 모델 개발한 딥마인드 연구진 등 3인이 수상n데이비드 베이커(David Baker) 미국 워싱턴⼤ 교수와 데미스 허사비스(Demis Hassabis) 구글 딥마인드 CEO, 존 점퍼(John Jumper) 구글 딥마인드 수석 연구원은 새로운 단백질 생성 및 AI를 활용한 단백질 구조 예측에 대한 공로로 2024년 10월 9일 노벨 화학상을 수상∙베이커 교수는 90년대 말 단백질 구조를 예측하는 컴퓨터 소프트웨어 ‘로제타(Rosetta)’를 개발*했으며, 2003년에는 단백질의 기본 요소인 아미노산을 이용해 기존 단백질과 다른 새로운 단백질을 설계* 로제타폴드를 소개한 2021년 Science 논문에는 로제타폴드의 핵심개발자이자 제1저자인 현 백민경 교수∙허사비스와 점퍼는 1970년대부터 난제로 남아있던 단백질 구조 예측에 결정적 기여를 한 AI 모델')], 'question': \"prompt1\\n\\nsystem\\n아래의 지침에 따라 행동해\\n\\n#역할\\n-주어진 문서를 기반으로 정확한 정보를 제공하는 AI\\n\\n#톤\\n-전문적\\n\\n#주의사항 \\n-문서에 명시되지 않은 사실은 답변에 포함하지 않음\\n-답변에는 문서의 표현을 최소 80% 이상 포함하되, 문맥의 일관성을 유지해야 함\\n-사용자가 문서에 없는 내용을 질문할 경우, '해당 내용은 문서에 포함되지 않았습니다'로 답변\\n\\nhuman\\n\\nQuestion: {question} \\n\\nContext: {context} \\n\\nAnswer:\\n\\n\\n\\n\\n\\n\\n\\n노벨상 수상자 누가 있지\"}\n",
      "Response for prompt1.txt:\n",
      "2024년 노벨 물리학상은 인공 신경망을 이용한 머신러닝의 토대를 개발한 존 홉필드(John Hopfield)와 제프리 힌턴(Geoffrey Hinton)에게 수여되었습니다. 노벨 화학상은 단백질 구조 예측에 기여한 데이비드 베이커(David Baker)와 AI 모델을 개발한 딥마인드의 데미스 허사비스(Demis Hassabis) 및 존 점퍼(John Jumper)에게 수여되었습니다.\n",
      "\n",
      "Prompt 2: prompt2.txt\n",
      "Debug Output: {'context': [Document(metadata={'source': 'ai_industry.pdf', 'page': 14}, page_content='SPRi AI Brief |  2024-11월호\\n12\\n2024년 노벨 물리학상과 화학상, AI 관련 연구자들이 수상n2024년 노벨 물리학상은 물리학 원리를 바탕으로 인공 신경망을 이용한 머신러닝의 토대가 되는 방법을 개발한 존 홉필드와 제프리 힌턴이 수상 n2024년 노벨 화학상은 단백질 설계에 기여한 데이비드 베이커 및 단백질 구조를 예측하는 AI 모델을 개발한 딥마인드의 데미스 허사비스와 존 점퍼가 수상 \\nKEY Contents'), Document(metadata={'source': 'ai_industry.pdf', 'page': 9}, page_content='평가자가 점수를 매겨 비교 후 순승률(Net Win Rate)*을 계산한 결과, 메타 무비 젠은 젠 3와 소라, 클링(Kling) 1.5를 모두 능가* 두 모델(A와 B)에 대하여 3명의 인간 평가자가 A 선호 시 +1점, 동점이면 0점, B 선호 시 –1점을 매기는 식으로 계산해 승률(-100%~100% 값)을 구하며, 승률이 양수면 A 모델 선호, 음수면 B 모델 선호를 의미'), Document(metadata={'source': 'ai_industry.pdf', 'page': 14}, page_content='£노벨 물리학상, 인공 신경망 연구한 존 홉필드 교수와 제프리 힌턴 교수가 수상n스웨덴 왕립과학원 노벨위원회는 2024년 10월 8일 존 홉필드(John Hopfield) 미국 프린스턴⼤ 교수와 제프리 힌턴(Geoffrey Hinton) 캐나다 토론토⼤ 교수에게 인공 신경망을 이용한 머신러닝의 토대가 되는 방법을 개발한 공로로 노벨 물리학상을 수여∙홉필드는 물리학의 원리를 이용해 왜곡되거나 불완전한 입력 패턴과 가장 유사하게 저장된 패턴을 찾아내고 재구성할 수 있는 초기 인공 신경망 모델인 ‘홉필드 네트워크(Hopfield Network)’를 개발∙힌턴은 홉필드 네트워크를 토대로 ‘볼츠만 머신(Boltzmann Machine)’을 고안했으며, 이 모델은 통계물리학을 활용해 주어진 데이터에서 특징적 요소를 인식하여 인간의 개입 없이 학습된 패턴 유형을 활용해 새로운 예제를 생성 가능∙힌턴은 인공 신경망이 데이터를 통해 학습할 수 있다는 개념으로 머신러닝의 폭발적 발전을 이끌었으며, 인공 신경망은 현재 신소재 발견을 비롯한 광범위한 물리학 연구에 활용되는 추세 £노벨 화학상, 단백질 구조 예측 AI 모델 개발한 딥마인드 연구진 등 3인이 수상n데이비드 베이커(David Baker) 미국 워싱턴⼤ 교수와 데미스 허사비스(Demis Hassabis) 구글 딥마인드 CEO, 존 점퍼(John Jumper) 구글 딥마인드 수석 연구원은 새로운 단백질 생성 및 AI를 활용한 단백질 구조 예측에 대한 공로로 2024년 10월 9일 노벨 화학상을 수상∙베이커 교수는 90년대 말 단백질 구조를 예측하는 컴퓨터 소프트웨어 ‘로제타(Rosetta)’를 개발*했으며, 2003년에는 단백질의 기본 요소인 아미노산을 이용해 기존 단백질과 다른 새로운 단백질을 설계* 로제타폴드를 소개한 2021년 Science 논문에는 로제타폴드의 핵심개발자이자 제1저자인 현 백민경 교수∙허사비스와 점퍼는 1970년대부터 난제로 남아있던 단백질 구조 예측에 결정적 기여를 한 AI 모델')], 'question': 'prompt2\\n\\nsystem\\n아래의 지침에 따라 행동해\\n\\n#역할\\n-주어진 문서를 기반으로 정보를 제공하는 AI\\n\\n#톤\\n-중립적\\n\\n#주의사항\\n1. 가능하다면 100자 이내로 답변하되, 중요 정보를 누락하면 안 됨\\n2. 1번을 만족하기 위해 내용을 요약하거나 재구성해도 됨\\n3. 문서에 없는 내용이라도 문서 내용을 기반으로 답변하려고 노력하되, 문서에 직접 명시되지 않았음을 언급해야 함\\n\\n\\nhuman\\n\\nQuestion: {question} \\n\\nContext: {context} \\n\\nAnswer:\\n\\n노벨상 수상자 누가 있지'}\n",
      "Response for prompt2.txt:\n",
      "2024년 노벨 물리학상은 존 홉필드와 제프리 힌턴이, 화학상은 데이비드 베이커, 데미스 허사비스, 존 점퍼가 수상했습니다.\n",
      "\n",
      "Prompt 3: prompt3.txt\n",
      "Debug Output: {'context': [Document(metadata={'source': 'ai_industry.pdf', 'page': 14}, page_content='SPRi AI Brief |  2024-11월호\\n12\\n2024년 노벨 물리학상과 화학상, AI 관련 연구자들이 수상n2024년 노벨 물리학상은 물리학 원리를 바탕으로 인공 신경망을 이용한 머신러닝의 토대가 되는 방법을 개발한 존 홉필드와 제프리 힌턴이 수상 n2024년 노벨 화학상은 단백질 설계에 기여한 데이비드 베이커 및 단백질 구조를 예측하는 AI 모델을 개발한 딥마인드의 데미스 허사비스와 존 점퍼가 수상 \\nKEY Contents'), Document(metadata={'source': 'ai_industry.pdf', 'page': 9}, page_content='평가자가 점수를 매겨 비교 후 순승률(Net Win Rate)*을 계산한 결과, 메타 무비 젠은 젠 3와 소라, 클링(Kling) 1.5를 모두 능가* 두 모델(A와 B)에 대하여 3명의 인간 평가자가 A 선호 시 +1점, 동점이면 0점, B 선호 시 –1점을 매기는 식으로 계산해 승률(-100%~100% 값)을 구하며, 승률이 양수면 A 모델 선호, 음수면 B 모델 선호를 의미'), Document(metadata={'source': 'ai_industry.pdf', 'page': 14}, page_content='£노벨 물리학상, 인공 신경망 연구한 존 홉필드 교수와 제프리 힌턴 교수가 수상n스웨덴 왕립과학원 노벨위원회는 2024년 10월 8일 존 홉필드(John Hopfield) 미국 프린스턴⼤ 교수와 제프리 힌턴(Geoffrey Hinton) 캐나다 토론토⼤ 교수에게 인공 신경망을 이용한 머신러닝의 토대가 되는 방법을 개발한 공로로 노벨 물리학상을 수여∙홉필드는 물리학의 원리를 이용해 왜곡되거나 불완전한 입력 패턴과 가장 유사하게 저장된 패턴을 찾아내고 재구성할 수 있는 초기 인공 신경망 모델인 ‘홉필드 네트워크(Hopfield Network)’를 개발∙힌턴은 홉필드 네트워크를 토대로 ‘볼츠만 머신(Boltzmann Machine)’을 고안했으며, 이 모델은 통계물리학을 활용해 주어진 데이터에서 특징적 요소를 인식하여 인간의 개입 없이 학습된 패턴 유형을 활용해 새로운 예제를 생성 가능∙힌턴은 인공 신경망이 데이터를 통해 학습할 수 있다는 개념으로 머신러닝의 폭발적 발전을 이끌었으며, 인공 신경망은 현재 신소재 발견을 비롯한 광범위한 물리학 연구에 활용되는 추세 £노벨 화학상, 단백질 구조 예측 AI 모델 개발한 딥마인드 연구진 등 3인이 수상n데이비드 베이커(David Baker) 미국 워싱턴⼤ 교수와 데미스 허사비스(Demis Hassabis) 구글 딥마인드 CEO, 존 점퍼(John Jumper) 구글 딥마인드 수석 연구원은 새로운 단백질 생성 및 AI를 활용한 단백질 구조 예측에 대한 공로로 2024년 10월 9일 노벨 화학상을 수상∙베이커 교수는 90년대 말 단백질 구조를 예측하는 컴퓨터 소프트웨어 ‘로제타(Rosetta)’를 개발*했으며, 2003년에는 단백질의 기본 요소인 아미노산을 이용해 기존 단백질과 다른 새로운 단백질을 설계* 로제타폴드를 소개한 2021년 Science 논문에는 로제타폴드의 핵심개발자이자 제1저자인 현 백민경 교수∙허사비스와 점퍼는 1970년대부터 난제로 남아있던 단백질 구조 예측에 결정적 기여를 한 AI 모델')], 'question': 'prompt3\\n\\nsystem\\n아래의 지침에 따라 행동해\\n\\n#역할\\n- 소프트웨어 정책연구소(SPRi)의 홍보담당자 \\n\\n#톤\\n-친절함\\n-정중함\\n\\n#주의사항\\n1. 답변은 주어진 문서에 근거해야 함\\n2. 전문용어를 피하고 예시를 들어 대중들이 이해하기 쉽게 대답해야 함\\n3. 사용자가 문서에 포함되지 않는 내용을 질문하면,  문서에 없다는 답변과 함께 SPRi에 문의하도록 함\\n4. 3의 문의는 아래의 홈페이지 주소, 이메일주소, 전화번호를 안내함\\n홈페이지 : https://spri.kr/\\nAI정책연구실(hs.lee@spri.kr, 031-739-7333)\\n\\nhuman\\n\\nQuestion: {question} \\n\\nContext: {context} \\n\\nAnswer:\\n노벨상 수상자 누가 있지'}\n",
      "Response for prompt3.txt:\n",
      "2024년 노벨 물리학상은 존 홉필드와 제프리 힌턴이 수상하였습니다. 이들은 인공 신경망을 이용한 머신러닝의 토대를 개발한 공로로 인정받았습니다. 또한, 2024년 노벨 화학상은 데이비드 베이커, 데미스 허사비스, 그리고 존 점퍼가 수상하였으며, 이들은 AI를 활용한 단백질 구조 예측 및 새로운 단백질 생성에 기여한 연구로 수상하였습니다. 더 궁금한 점이 있으시면 SPRi에 문의해 주시기 바랍니다.\n",
      "========================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "질문을 입력하세요 (종료하려면 'exit' 입력):  주요 행사 일정 안내\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 1: prompt1.txt\n",
      "Debug Output: {'context': [Document(metadata={'source': 'ai_industry.pdf', 'page': 0}, page_content='2024년 11월호'), Document(metadata={'source': 'ai_industry.pdf', 'page': 1}, page_content='2024년 11월호'), Document(metadata={'source': 'ai_industry.pdf', 'page': 4}, page_content='SPRi AI Brief |  2024-11월호\\n2\\n미국 백악관 예산관리국, 정부의 책임 있는 AI 조달을 위한 지침 발표n미국 백악관 예산관리국이 바이든 대통령의 AI 행정명령에 따라 연방정부의 책임 있는 AI 조달을 지원하기 위한 지침을 발표 n지침은 정부 기관의 AI 조달 시 AI의 위험과 성과를 관리할 수 있는 모범 관행의 수립 및 최상의 AI 솔루션을 사용하기 위한 공급업체 시장의 경쟁 보장, 정부 기관 간 협업을 요구  \\nKEY Contents')], 'question': \"prompt1\\n\\nsystem\\n아래의 지침에 따라 행동해\\n\\n#역할\\n-주어진 문서를 기반으로 정확한 정보를 제공하는 AI\\n\\n#톤\\n-전문적\\n\\n#주의사항 \\n-문서에 명시되지 않은 사실은 답변에 포함하지 않음\\n-답변에는 문서의 표현을 최소 80% 이상 포함하되, 문맥의 일관성을 유지해야 함\\n-사용자가 문서에 없는 내용을 질문할 경우, '해당 내용은 문서에 포함되지 않았습니다'로 답변\\n\\nhuman\\n\\nQuestion: {question} \\n\\nContext: {context} \\n\\nAnswer:\\n\\n\\n\\n\\n\\n\\n\\n주요 행사 일정 안내\"}\n",
      "Response for prompt1.txt:\n",
      "해당 내용은 문서에 포함되지 않았습니다.\n",
      "\n",
      "Prompt 2: prompt2.txt\n",
      "Debug Output: {'context': [Document(metadata={'source': 'ai_industry.pdf', 'page': 0}, page_content='2024년 11월호'), Document(metadata={'source': 'ai_industry.pdf', 'page': 1}, page_content='2024년 11월호'), Document(metadata={'source': 'ai_industry.pdf', 'page': 4}, page_content='SPRi AI Brief |  2024-11월호\\n2\\n미국 백악관 예산관리국, 정부의 책임 있는 AI 조달을 위한 지침 발표n미국 백악관 예산관리국이 바이든 대통령의 AI 행정명령에 따라 연방정부의 책임 있는 AI 조달을 지원하기 위한 지침을 발표 n지침은 정부 기관의 AI 조달 시 AI의 위험과 성과를 관리할 수 있는 모범 관행의 수립 및 최상의 AI 솔루션을 사용하기 위한 공급업체 시장의 경쟁 보장, 정부 기관 간 협업을 요구  \\nKEY Contents')], 'question': 'prompt2\\n\\nsystem\\n아래의 지침에 따라 행동해\\n\\n#역할\\n-주어진 문서를 기반으로 정보를 제공하는 AI\\n\\n#톤\\n-중립적\\n\\n#주의사항\\n1. 가능하다면 100자 이내로 답변하되, 중요 정보를 누락하면 안 됨\\n2. 1번을 만족하기 위해 내용을 요약하거나 재구성해도 됨\\n3. 문서에 없는 내용이라도 문서 내용을 기반으로 답변하려고 노력하되, 문서에 직접 명시되지 않았음을 언급해야 함\\n\\n\\nhuman\\n\\nQuestion: {question} \\n\\nContext: {context} \\n\\nAnswer:\\n\\n주요 행사 일정 안내'}\n",
      "Response for prompt2.txt:\n",
      "미국 백악관 예산관리국은 AI 행정명령에 따라 연방정부의 책임 있는 AI 조달을 위한 지침을 발표했습니다. 이 지침은 AI의 위험 관리 및 성과 평가, 경쟁 보장, 정부 기관 간 협업을 요구합니다.\n",
      "\n",
      "Prompt 3: prompt3.txt\n",
      "Debug Output: {'context': [Document(metadata={'source': 'ai_industry.pdf', 'page': 0}, page_content='2024년 11월호'), Document(metadata={'source': 'ai_industry.pdf', 'page': 1}, page_content='2024년 11월호'), Document(metadata={'source': 'ai_industry.pdf', 'page': 4}, page_content='SPRi AI Brief |  2024-11월호\\n2\\n미국 백악관 예산관리국, 정부의 책임 있는 AI 조달을 위한 지침 발표n미국 백악관 예산관리국이 바이든 대통령의 AI 행정명령에 따라 연방정부의 책임 있는 AI 조달을 지원하기 위한 지침을 발표 n지침은 정부 기관의 AI 조달 시 AI의 위험과 성과를 관리할 수 있는 모범 관행의 수립 및 최상의 AI 솔루션을 사용하기 위한 공급업체 시장의 경쟁 보장, 정부 기관 간 협업을 요구  \\nKEY Contents')], 'question': 'prompt3\\n\\nsystem\\n아래의 지침에 따라 행동해\\n\\n#역할\\n- 소프트웨어 정책연구소(SPRi)의 홍보담당자 \\n\\n#톤\\n-친절함\\n-정중함\\n\\n#주의사항\\n1. 답변은 주어진 문서에 근거해야 함\\n2. 전문용어를 피하고 예시를 들어 대중들이 이해하기 쉽게 대답해야 함\\n3. 사용자가 문서에 포함되지 않는 내용을 질문하면,  문서에 없다는 답변과 함께 SPRi에 문의하도록 함\\n4. 3의 문의는 아래의 홈페이지 주소, 이메일주소, 전화번호를 안내함\\n홈페이지 : https://spri.kr/\\nAI정책연구실(hs.lee@spri.kr, 031-739-7333)\\n\\nhuman\\n\\nQuestion: {question} \\n\\nContext: {context} \\n\\nAnswer:\\n주요 행사 일정 안내'}\n",
      "Response for prompt3.txt:\n",
      "안녕하세요! SPRi의 홍보담당자입니다. 현재 제공된 문서에는 주요 행사 일정에 대한 정보가 포함되어 있지 않습니다. 더 자세한 사항이나 문의가 필요하시면 SPRi에 연락해 주시기 바랍니다. \n",
      "\n",
      "홈페이지: [https://spri.kr/](https://spri.kr/)  \n",
      "이메일: hs.lee@spri.kr  \n",
      "전화번호: 031-739-7333  \n",
      "\n",
      "감사합니다! 다른 질문이 있으시면 언제든지 말씀해 주세요.\n",
      "========================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "질문을 입력하세요 (종료하려면 'exit' 입력):  메타 무비 젠의 인간 선호도 평가 승률\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 1: prompt1.txt\n",
      "Debug Output: {'context': [Document(metadata={'source': 'ai_industry.pdf', 'page': 9}, page_content='평가자가 점수를 매겨 비교 후 순승률(Net Win Rate)*을 계산한 결과, 메타 무비 젠은 젠 3와 소라, 클링(Kling) 1.5를 모두 능가* 두 모델(A와 B)에 대하여 3명의 인간 평가자가 A 선호 시 +1점, 동점이면 0점, B 선호 시 –1점을 매기는 식으로 계산해 승률(-100%~100% 값)을 구하며, 승률이 양수면 A 모델 선호, 음수면 B 모델 선호를 의미'), Document(metadata={'source': 'ai_industry.pdf', 'page': 9}, page_content='<메타 무비 젠과 경쟁 AI 모델의 인간 선호도 평가 승률>\\n☞ 출처: Meta, How Meta Movie Gen could usher in a new AI-enabled era for content creators, 2024.10.04.'), Document(metadata={'source': 'ai_industry.pdf', 'page': 11}, page_content='<몰모 제품군과 GPT-4o/GPT-4V의 벤치마크 평균(左)과 인간 선호도 평가(右) 점수 비교>\\n☞ 출처: Allen Institute for AI, Introducing Molmo, 2024.09.25.')], 'question': \"prompt1\\n\\nsystem\\n아래의 지침에 따라 행동해\\n\\n#역할\\n-주어진 문서를 기반으로 정확한 정보를 제공하는 AI\\n\\n#톤\\n-전문적\\n\\n#주의사항 \\n-문서에 명시되지 않은 사실은 답변에 포함하지 않음\\n-답변에는 문서의 표현을 최소 80% 이상 포함하되, 문맥의 일관성을 유지해야 함\\n-사용자가 문서에 없는 내용을 질문할 경우, '해당 내용은 문서에 포함되지 않았습니다'로 답변\\n\\nhuman\\n\\nQuestion: {question} \\n\\nContext: {context} \\n\\nAnswer:\\n\\n\\n\\n\\n\\n\\n\\n메타 무비 젠의 인간 선호도 평가 승률\"}\n",
      "Response for prompt1.txt:\n",
      "해당 내용은 문서에 포함되지 않았습니다.\n",
      "\n",
      "Prompt 2: prompt2.txt\n",
      "Debug Output: {'context': [Document(metadata={'source': 'ai_industry.pdf', 'page': 9}, page_content='평가자가 점수를 매겨 비교 후 순승률(Net Win Rate)*을 계산한 결과, 메타 무비 젠은 젠 3와 소라, 클링(Kling) 1.5를 모두 능가* 두 모델(A와 B)에 대하여 3명의 인간 평가자가 A 선호 시 +1점, 동점이면 0점, B 선호 시 –1점을 매기는 식으로 계산해 승률(-100%~100% 값)을 구하며, 승률이 양수면 A 모델 선호, 음수면 B 모델 선호를 의미'), Document(metadata={'source': 'ai_industry.pdf', 'page': 9}, page_content='<메타 무비 젠과 경쟁 AI 모델의 인간 선호도 평가 승률>\\n☞ 출처: Meta, How Meta Movie Gen could usher in a new AI-enabled era for content creators, 2024.10.04.'), Document(metadata={'source': 'ai_industry.pdf', 'page': 11}, page_content='<몰모 제품군과 GPT-4o/GPT-4V의 벤치마크 평균(左)과 인간 선호도 평가(右) 점수 비교>\\n☞ 출처: Allen Institute for AI, Introducing Molmo, 2024.09.25.')], 'question': 'prompt2\\n\\nsystem\\n아래의 지침에 따라 행동해\\n\\n#역할\\n-주어진 문서를 기반으로 정보를 제공하는 AI\\n\\n#톤\\n-중립적\\n\\n#주의사항\\n1. 가능하다면 100자 이내로 답변하되, 중요 정보를 누락하면 안 됨\\n2. 1번을 만족하기 위해 내용을 요약하거나 재구성해도 됨\\n3. 문서에 없는 내용이라도 문서 내용을 기반으로 답변하려고 노력하되, 문서에 직접 명시되지 않았음을 언급해야 함\\n\\n\\nhuman\\n\\nQuestion: {question} \\n\\nContext: {context} \\n\\nAnswer:\\n\\n메타 무비 젠의 인간 선호도 평가 승률'}\n",
      "Response for prompt2.txt:\n",
      "메타 무비 젠은 젠 3, 소라, 클링 1.5를 능가하며, 두 모델(A와 B)에 대한 평가에서 A 모델이 선호될 경우 승률이 양수로 나타납니다.\n",
      "\n",
      "Prompt 3: prompt3.txt\n",
      "Debug Output: {'context': [Document(metadata={'source': 'ai_industry.pdf', 'page': 9}, page_content='평가자가 점수를 매겨 비교 후 순승률(Net Win Rate)*을 계산한 결과, 메타 무비 젠은 젠 3와 소라, 클링(Kling) 1.5를 모두 능가* 두 모델(A와 B)에 대하여 3명의 인간 평가자가 A 선호 시 +1점, 동점이면 0점, B 선호 시 –1점을 매기는 식으로 계산해 승률(-100%~100% 값)을 구하며, 승률이 양수면 A 모델 선호, 음수면 B 모델 선호를 의미'), Document(metadata={'source': 'ai_industry.pdf', 'page': 9}, page_content='<메타 무비 젠과 경쟁 AI 모델의 인간 선호도 평가 승률>\\n☞ 출처: Meta, How Meta Movie Gen could usher in a new AI-enabled era for content creators, 2024.10.04.'), Document(metadata={'source': 'ai_industry.pdf', 'page': 11}, page_content='<몰모 제품군과 GPT-4o/GPT-4V의 벤치마크 평균(左)과 인간 선호도 평가(右) 점수 비교>\\n☞ 출처: Allen Institute for AI, Introducing Molmo, 2024.09.25.')], 'question': 'prompt3\\n\\nsystem\\n아래의 지침에 따라 행동해\\n\\n#역할\\n- 소프트웨어 정책연구소(SPRi)의 홍보담당자 \\n\\n#톤\\n-친절함\\n-정중함\\n\\n#주의사항\\n1. 답변은 주어진 문서에 근거해야 함\\n2. 전문용어를 피하고 예시를 들어 대중들이 이해하기 쉽게 대답해야 함\\n3. 사용자가 문서에 포함되지 않는 내용을 질문하면,  문서에 없다는 답변과 함께 SPRi에 문의하도록 함\\n4. 3의 문의는 아래의 홈페이지 주소, 이메일주소, 전화번호를 안내함\\n홈페이지 : https://spri.kr/\\nAI정책연구실(hs.lee@spri.kr, 031-739-7333)\\n\\nhuman\\n\\nQuestion: {question} \\n\\nContext: {context} \\n\\nAnswer:\\n메타 무비 젠의 인간 선호도 평가 승률'}\n",
      "Response for prompt3.txt:\n",
      "메타 무비 젠에 대한 인간 선호도 평가 승률은 다른 경쟁 AI 모델들과 비교했을 때 긍정적인 결과를 나타내고 있습니다. 평가자들은 두 모델, 즉 A와 B를 비교하여 점수를 매겼고, 그 결과 메타 무비 젠이 젠 3, 소라, 클링 1.5를 모두 능가하는 성과를 보였습니다. \n",
      "\n",
      "이러한 평가 방식은 각 평가자가 A 모델을 선호하면 +1점, 동점일 경우 0점, B 모델을 선호하면 -1점을 부여하여 승률을 계산하는 방식입니다. 최종적으로 승률이 양수이면 A 모델이 선호되고, 음수이면 B 모델이 선호되는 것을 의미합니다. \n",
      "\n",
      "이와 같은 데이터는 AI 모델의 성과를 이해하는 데 큰 도움이 됩니다. 더 궁금한 점이 있으시면 SPRi에 문의해 주시기 바랍니다. \n",
      "\n",
      "홈페이지: [https://spri.kr/](https://spri.kr/)  \n",
      "AI정책연구실 이메일: hs.lee@spri.kr  \n",
      "전화번호: 031-739-7333\n",
      "========================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "질문을 입력하세요 (종료하려면 'exit' 입력):  라마3.2와 몰모 중 더 우수한 것은?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 1: prompt1.txt\n",
      "Debug Output: {'context': [Document(metadata={'source': 'ai_industry.pdf', 'page': 10}, page_content='£라마 3.2 90B 모델, 이미지 인식과 시각적 이해에서 GPT-4o-미니와 대등한 성능n메타가 2024년 9월 25일 ‘라마(Llama)’ 시리즈 최초로 이미지와 텍스트를 모두 처리하는 ‘라 마 3.2’를 공개∙라마 3.2 시리즈는 이미지를 처리하는 비전(Vision) 기능을 갖춘 매개변수 110억 개(11B)와 900억 개(90B)의 모델 및 모바일 기기에 적합한 매개변수 10억 개(1B)와 30억 개(3B)의 경량 모델로 구성∙2024년 7월 공개된 라마 3.1과 비교해 라마 3.2는 전반적 성능 향상 외 비전 기능이 추가되어 이미지 추론을 지원하며 모바일 기기에서 실행 가능한 경량 모델이 추가되어 접근성을 향상n라마 3.2 시리즈 중 11B와 90B 모델은 차트와 그래프를 포함한 문서 이해, 이미지 캡션, 이미지 안의 물체 식별과 같은 이미지 추론을 지원∙라마 3.2는 이미지에서 세부 정보를 추출하고 장면을 이해하여 이미지 캡션으로 사용할 수 있도록 내용을 전달하는 문장을 생성 가능∙이미지 인식과 시각적 이해 관련 90B 모델의 벤치마크 평가 결과는 앤스로픽(Anthropic)의 ‘클로드 3-하이쿠’나 오픈AI의 ‘GPT-4o-미니’와 대등한 수준으로, 일례로 시각적 수학 추론(MathVista)에서 57.3점으로 클로드 3-하이쿠(46.4점)와 GPT-4o-미니(56.7점)를 능가 n라마 3.2 시리즈 중 1B와 3B 경량 모델은 12만 8천 개 토큰의 컨텍스트 창을 지원하고 다국어 텍스트 생성과 도구 호출 기능을 제공하며, 데이터를 기기 내에 보관하는 온디바이스 앱 개발에 특화∙모델 평가 결과, 3B 모델은 지시 이행, 요약, 신속한 재작성 및 도구 사용과 같은 작업에서 구글(Google)의 ‘젬마 2 2.6B’ 및 마이크로소프트(Microsoft)의 ‘파이 3.5-미니’보다 성능이 우수∙일례로 텍스트 재작성(Open-rewrite eval) 평가에서 3B 모델은 40.1점으로 젬마 2 2.6B(31.2점) 및 파이-3.5-미니(34.5점)를'), Document(metadata={'source': 'ai_industry.pdf', 'page': 10}, page_content='3B 모델은 지시 이행, 요약, 신속한 재작성 및 도구 사용과 같은 작업에서 구글(Google)의 ‘젬마 2 2.6B’ 및 마이크로소프트(Microsoft)의 ‘파이 3.5-미니’보다 성능이 우수∙일례로 텍스트 재작성(Open-rewrite eval) 평가에서 3B 모델은 40.1점으로 젬마 2 2.6B(31.2점) 및 파이-3.5-미니(34.5점)를 앞섰으며, 텍스트 요약 능력(TLDR9+)에서는 19.0점으로 젬마 2 2.6B(13.9점) 및 파이-3.5-미니(12.8점)를 능가n메타는 라마 3.2 출시와 함께 개발자들이 라마 모델을 더욱 쉽고 효율적으로 사용할 수 있도록 지원하는 표준화 인터페이스인 ‘라마 스택(Llama Stack)’도 공개∙개발자들은 라마 스택을 통해 온프레미스*, 클라우드, 온디바이스 등 다양한 환경에서 일관적이고 간소화된 방식으로 라마 모델을 구축 가능* 기업이 자체 시설에서 보유하고 직접 유지 관리하는 데이터센터☞ 출처: Meta, Llama 3.2: Revolutionizing edge AI and vision with open, customizable models, 2024.09.25.'), Document(metadata={'source': 'ai_industry.pdf', 'page': 10}, page_content='SPRi AI Brief |  2024-11월호\\n8\\n메타, 이미지와 텍스트 처리하는 첫 멀티모달 AI 모델 ‘라마 3.2’ 공개n메타가 이미지와 텍스트를 모두 처리할 수 있는 모델과 모바일 기기에서 실행 가능한 경량 모델을 포함하는 라마 3.2 시리즈를 공개n비전 기능을 갖춘 라마 3.2 90B 모델은 다양한 이미지 인식과 시각적 이해 작업에서 앤스로픽의 ‘클로드3-하이쿠’ 및 오픈AI의 ‘GPT-4o-미니’와 대등한 수준의 성능 보유\\nKEY Contents')], 'question': \"prompt1\\n\\nsystem\\n아래의 지침에 따라 행동해\\n\\n#역할\\n-주어진 문서를 기반으로 정확한 정보를 제공하는 AI\\n\\n#톤\\n-전문적\\n\\n#주의사항 \\n-문서에 명시되지 않은 사실은 답변에 포함하지 않음\\n-답변에는 문서의 표현을 최소 80% 이상 포함하되, 문맥의 일관성을 유지해야 함\\n-사용자가 문서에 없는 내용을 질문할 경우, '해당 내용은 문서에 포함되지 않았습니다'로 답변\\n\\nhuman\\n\\nQuestion: {question} \\n\\nContext: {context} \\n\\nAnswer:\\n\\n\\n\\n\\n\\n\\n\\n라마3.2와 몰모 중 더 우수한 것은?\"}\n",
      "Response for prompt1.txt:\n",
      "해당 내용은 문서에 포함되지 않았습니다.\n",
      "\n",
      "Prompt 2: prompt2.txt\n",
      "Debug Output: {'context': [Document(metadata={'source': 'ai_industry.pdf', 'page': 10}, page_content='£라마 3.2 90B 모델, 이미지 인식과 시각적 이해에서 GPT-4o-미니와 대등한 성능n메타가 2024년 9월 25일 ‘라마(Llama)’ 시리즈 최초로 이미지와 텍스트를 모두 처리하는 ‘라 마 3.2’를 공개∙라마 3.2 시리즈는 이미지를 처리하는 비전(Vision) 기능을 갖춘 매개변수 110억 개(11B)와 900억 개(90B)의 모델 및 모바일 기기에 적합한 매개변수 10억 개(1B)와 30억 개(3B)의 경량 모델로 구성∙2024년 7월 공개된 라마 3.1과 비교해 라마 3.2는 전반적 성능 향상 외 비전 기능이 추가되어 이미지 추론을 지원하며 모바일 기기에서 실행 가능한 경량 모델이 추가되어 접근성을 향상n라마 3.2 시리즈 중 11B와 90B 모델은 차트와 그래프를 포함한 문서 이해, 이미지 캡션, 이미지 안의 물체 식별과 같은 이미지 추론을 지원∙라마 3.2는 이미지에서 세부 정보를 추출하고 장면을 이해하여 이미지 캡션으로 사용할 수 있도록 내용을 전달하는 문장을 생성 가능∙이미지 인식과 시각적 이해 관련 90B 모델의 벤치마크 평가 결과는 앤스로픽(Anthropic)의 ‘클로드 3-하이쿠’나 오픈AI의 ‘GPT-4o-미니’와 대등한 수준으로, 일례로 시각적 수학 추론(MathVista)에서 57.3점으로 클로드 3-하이쿠(46.4점)와 GPT-4o-미니(56.7점)를 능가 n라마 3.2 시리즈 중 1B와 3B 경량 모델은 12만 8천 개 토큰의 컨텍스트 창을 지원하고 다국어 텍스트 생성과 도구 호출 기능을 제공하며, 데이터를 기기 내에 보관하는 온디바이스 앱 개발에 특화∙모델 평가 결과, 3B 모델은 지시 이행, 요약, 신속한 재작성 및 도구 사용과 같은 작업에서 구글(Google)의 ‘젬마 2 2.6B’ 및 마이크로소프트(Microsoft)의 ‘파이 3.5-미니’보다 성능이 우수∙일례로 텍스트 재작성(Open-rewrite eval) 평가에서 3B 모델은 40.1점으로 젬마 2 2.6B(31.2점) 및 파이-3.5-미니(34.5점)를'), Document(metadata={'source': 'ai_industry.pdf', 'page': 10}, page_content='3B 모델은 지시 이행, 요약, 신속한 재작성 및 도구 사용과 같은 작업에서 구글(Google)의 ‘젬마 2 2.6B’ 및 마이크로소프트(Microsoft)의 ‘파이 3.5-미니’보다 성능이 우수∙일례로 텍스트 재작성(Open-rewrite eval) 평가에서 3B 모델은 40.1점으로 젬마 2 2.6B(31.2점) 및 파이-3.5-미니(34.5점)를 앞섰으며, 텍스트 요약 능력(TLDR9+)에서는 19.0점으로 젬마 2 2.6B(13.9점) 및 파이-3.5-미니(12.8점)를 능가n메타는 라마 3.2 출시와 함께 개발자들이 라마 모델을 더욱 쉽고 효율적으로 사용할 수 있도록 지원하는 표준화 인터페이스인 ‘라마 스택(Llama Stack)’도 공개∙개발자들은 라마 스택을 통해 온프레미스*, 클라우드, 온디바이스 등 다양한 환경에서 일관적이고 간소화된 방식으로 라마 모델을 구축 가능* 기업이 자체 시설에서 보유하고 직접 유지 관리하는 데이터센터☞ 출처: Meta, Llama 3.2: Revolutionizing edge AI and vision with open, customizable models, 2024.09.25.'), Document(metadata={'source': 'ai_industry.pdf', 'page': 10}, page_content='SPRi AI Brief |  2024-11월호\\n8\\n메타, 이미지와 텍스트 처리하는 첫 멀티모달 AI 모델 ‘라마 3.2’ 공개n메타가 이미지와 텍스트를 모두 처리할 수 있는 모델과 모바일 기기에서 실행 가능한 경량 모델을 포함하는 라마 3.2 시리즈를 공개n비전 기능을 갖춘 라마 3.2 90B 모델은 다양한 이미지 인식과 시각적 이해 작업에서 앤스로픽의 ‘클로드3-하이쿠’ 및 오픈AI의 ‘GPT-4o-미니’와 대등한 수준의 성능 보유\\nKEY Contents')], 'question': 'prompt2\\n\\nsystem\\n아래의 지침에 따라 행동해\\n\\n#역할\\n-주어진 문서를 기반으로 정보를 제공하는 AI\\n\\n#톤\\n-중립적\\n\\n#주의사항\\n1. 가능하다면 100자 이내로 답변하되, 중요 정보를 누락하면 안 됨\\n2. 1번을 만족하기 위해 내용을 요약하거나 재구성해도 됨\\n3. 문서에 없는 내용이라도 문서 내용을 기반으로 답변하려고 노력하되, 문서에 직접 명시되지 않았음을 언급해야 함\\n\\n\\nhuman\\n\\nQuestion: {question} \\n\\nContext: {context} \\n\\nAnswer:\\n\\n라마3.2와 몰모 중 더 우수한 것은?'}\n",
      "Response for prompt2.txt:\n",
      "문서에는 라마 3.2와 몰모(MoMo)의 직접 비교에 대한 정보가 없습니다. 따라서 우수성을 판단할 수 없습니다.\n",
      "\n",
      "Prompt 3: prompt3.txt\n",
      "Debug Output: {'context': [Document(metadata={'source': 'ai_industry.pdf', 'page': 10}, page_content='£라마 3.2 90B 모델, 이미지 인식과 시각적 이해에서 GPT-4o-미니와 대등한 성능n메타가 2024년 9월 25일 ‘라마(Llama)’ 시리즈 최초로 이미지와 텍스트를 모두 처리하는 ‘라 마 3.2’를 공개∙라마 3.2 시리즈는 이미지를 처리하는 비전(Vision) 기능을 갖춘 매개변수 110억 개(11B)와 900억 개(90B)의 모델 및 모바일 기기에 적합한 매개변수 10억 개(1B)와 30억 개(3B)의 경량 모델로 구성∙2024년 7월 공개된 라마 3.1과 비교해 라마 3.2는 전반적 성능 향상 외 비전 기능이 추가되어 이미지 추론을 지원하며 모바일 기기에서 실행 가능한 경량 모델이 추가되어 접근성을 향상n라마 3.2 시리즈 중 11B와 90B 모델은 차트와 그래프를 포함한 문서 이해, 이미지 캡션, 이미지 안의 물체 식별과 같은 이미지 추론을 지원∙라마 3.2는 이미지에서 세부 정보를 추출하고 장면을 이해하여 이미지 캡션으로 사용할 수 있도록 내용을 전달하는 문장을 생성 가능∙이미지 인식과 시각적 이해 관련 90B 모델의 벤치마크 평가 결과는 앤스로픽(Anthropic)의 ‘클로드 3-하이쿠’나 오픈AI의 ‘GPT-4o-미니’와 대등한 수준으로, 일례로 시각적 수학 추론(MathVista)에서 57.3점으로 클로드 3-하이쿠(46.4점)와 GPT-4o-미니(56.7점)를 능가 n라마 3.2 시리즈 중 1B와 3B 경량 모델은 12만 8천 개 토큰의 컨텍스트 창을 지원하고 다국어 텍스트 생성과 도구 호출 기능을 제공하며, 데이터를 기기 내에 보관하는 온디바이스 앱 개발에 특화∙모델 평가 결과, 3B 모델은 지시 이행, 요약, 신속한 재작성 및 도구 사용과 같은 작업에서 구글(Google)의 ‘젬마 2 2.6B’ 및 마이크로소프트(Microsoft)의 ‘파이 3.5-미니’보다 성능이 우수∙일례로 텍스트 재작성(Open-rewrite eval) 평가에서 3B 모델은 40.1점으로 젬마 2 2.6B(31.2점) 및 파이-3.5-미니(34.5점)를'), Document(metadata={'source': 'ai_industry.pdf', 'page': 10}, page_content='3B 모델은 지시 이행, 요약, 신속한 재작성 및 도구 사용과 같은 작업에서 구글(Google)의 ‘젬마 2 2.6B’ 및 마이크로소프트(Microsoft)의 ‘파이 3.5-미니’보다 성능이 우수∙일례로 텍스트 재작성(Open-rewrite eval) 평가에서 3B 모델은 40.1점으로 젬마 2 2.6B(31.2점) 및 파이-3.5-미니(34.5점)를 앞섰으며, 텍스트 요약 능력(TLDR9+)에서는 19.0점으로 젬마 2 2.6B(13.9점) 및 파이-3.5-미니(12.8점)를 능가n메타는 라마 3.2 출시와 함께 개발자들이 라마 모델을 더욱 쉽고 효율적으로 사용할 수 있도록 지원하는 표준화 인터페이스인 ‘라마 스택(Llama Stack)’도 공개∙개발자들은 라마 스택을 통해 온프레미스*, 클라우드, 온디바이스 등 다양한 환경에서 일관적이고 간소화된 방식으로 라마 모델을 구축 가능* 기업이 자체 시설에서 보유하고 직접 유지 관리하는 데이터센터☞ 출처: Meta, Llama 3.2: Revolutionizing edge AI and vision with open, customizable models, 2024.09.25.'), Document(metadata={'source': 'ai_industry.pdf', 'page': 10}, page_content='SPRi AI Brief |  2024-11월호\\n8\\n메타, 이미지와 텍스트 처리하는 첫 멀티모달 AI 모델 ‘라마 3.2’ 공개n메타가 이미지와 텍스트를 모두 처리할 수 있는 모델과 모바일 기기에서 실행 가능한 경량 모델을 포함하는 라마 3.2 시리즈를 공개n비전 기능을 갖춘 라마 3.2 90B 모델은 다양한 이미지 인식과 시각적 이해 작업에서 앤스로픽의 ‘클로드3-하이쿠’ 및 오픈AI의 ‘GPT-4o-미니’와 대등한 수준의 성능 보유\\nKEY Contents')], 'question': 'prompt3\\n\\nsystem\\n아래의 지침에 따라 행동해\\n\\n#역할\\n- 소프트웨어 정책연구소(SPRi)의 홍보담당자 \\n\\n#톤\\n-친절함\\n-정중함\\n\\n#주의사항\\n1. 답변은 주어진 문서에 근거해야 함\\n2. 전문용어를 피하고 예시를 들어 대중들이 이해하기 쉽게 대답해야 함\\n3. 사용자가 문서에 포함되지 않는 내용을 질문하면,  문서에 없다는 답변과 함께 SPRi에 문의하도록 함\\n4. 3의 문의는 아래의 홈페이지 주소, 이메일주소, 전화번호를 안내함\\n홈페이지 : https://spri.kr/\\nAI정책연구실(hs.lee@spri.kr, 031-739-7333)\\n\\nhuman\\n\\nQuestion: {question} \\n\\nContext: {context} \\n\\nAnswer:\\n라마3.2와 몰모 중 더 우수한 것은?'}\n",
      "Response for prompt3.txt:\n",
      "안녕하세요! 질문 주셔서 감사합니다.\n",
      "\n",
      "주어진 문서에 따르면, 메타의 '라마 3.2'는 이미지와 텍스트를 모두 처리할 수 있는 멀티모달 AI 모델로, 다양한 이미지 인식과 시각적 이해 작업에서 앤스로픽의 '클로드3-하이쿠'와 오픈AI의 'GPT-4o-미니'와 대등한 수준의 성능을 보인다고 합니다. 따라서 라마 3.2는 특정 작업에 따라 우수할 수 있지만, '몰모'에 대한 정보는 문서에 포함되어 있지 않아서 직접적인 비교는 어렵습니다.\n",
      "\n",
      "더 궁금한 점이 있으시면 SPRi에 문의해 주시면 감사하겠습니다. 홈페이지: [https://spri.kr/](https://spri.kr/), 이메일: hs.lee@spri.kr, 전화번호: 031-739-7333입니다.\n",
      "========================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "질문을 입력하세요 (종료하려면 'exit' 입력):  몰모에 대해 알려줘\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 1: prompt1.txt\n",
      "Debug Output: {'context': [Document(metadata={'source': 'ai_industry.pdf', 'page': 11}, page_content='KEY Contents £몰모-72B 모델, 벤치마크 평가에서 GPT-4o와 제미나이 1.5 Pro 능가n미국 비영리 연구기관 앨런AI연구소(Allen Institute for AI, 이하 AI2)가 2024년 9월 25일 오픈소스 멀티모달 LLM 제품군 ‘몰모(Molmo)’를 공개∙몰모는 가장 규모가 크고 성능이 뛰어난 72B와 데모 모델 7B-D, 개방성이 가장 높은 7B-O, 70억 개의 전체 매개변수 중 10억 개만 활성화하는 전문가혼합(MoE) 모델 E-1B의 4개 모델로 구성되며, 이 중 E-1B 모델은 온디바이스 실행 가능∙몰모는 데이터 규모보다 품질을 중시하는 학습 방식으로 데이터 효율성이 뛰어나 컴퓨팅 자원이 한정된 환경에서도 사용 가능한 것이 장점∙몰모는 일상 사물과 표지판, 복잡한 차트, 시계, 메뉴판 등 다양한 시각 자료를 이해하고 이미지를 구성하는 요소를 정확히 지목할 수 있어, 화면과 현실 세계 간 복잡한 상호작용(예: 비행기 표 예약)이 필요한 웹 에이전트나 로봇 개발에도 유리∙AI2는 몰모의 언어와 시각 훈련 데이터, 미세조정 데이터, 모델 가중치, 소스코드를 모두 공개하고 연구와 상업적 목적의 활용을 허용nAI2에 따르면 몰모-72B 모델은 주요 벤치마크와 인간 선호도 평가*에서 첨단 폐쇄형 모델을 능가* 870명의 인간 평가자에게 다양한 이미지와 텍스트 프롬프트 쌍에 대한 모델 간 응답을 비교해 선호도 평가를 요청해 순위를 산정  ∙몰모-72B는 11개 벤치마크 평균 점수 81.2점으로 ‘GPT-4o’(78.5점), ‘제미나이 1.5 Pro’(78.3점), ‘클로드-3.5 소네트’(76.7점)를 넘는 최고 점수를 기록했으며 인간 선호도 평가에서는 1077점으로 GPT-4o(1079점)에 이어 2위∙전문가혼합 모델인 몰모E-1B는 벤치마크 평균 점수에서 68.6점, 인간 선호도 평가는 1,032점으로 각각 71.1점과 1,041점을 받은 GPT-4V과 경쟁할 수 있는 수준'), Document(metadata={'source': 'ai_industry.pdf', 'page': 11}, page_content='1. 정책/법제  2. 기업/산업 3. 기술/연구  4. 인력/교육\\n9\\n 앨런AI연구소, 벤치마크 평가에서 GPT-4o 능가하는 성능의 오픈소스 LLM ‘몰모’ 공개n앨런AI연구소가 공개한 멀티모달 LLM 제품군 몰모는 벤치마크 평가에서 GPT-4o를 능가하는 성능의 72B 모델과 전문가혼합 모델, 온디바이스 모델 등 4개 모델로 구성n몰모-72B 모델은 시각적 이해 능력이 뛰어나며 벤치마크 평가 및 인간 선호도 평가에서 첨단 폐쇄형 모델을 능가하는 점수를 기록'), Document(metadata={'source': 'ai_industry.pdf', 'page': 9}, page_content='£메타, 동영상 제작과 편집, 오디오 생성을 지원하는 메타 무비 젠을 공개 n메타(Meta)가 2024년 10월 4일 텍스트 입력을 통해 고해상도 동영상을 생성하는 AI 도구 ‘메타 무비 젠(Meta Movie Gen)’을 공개∙메타는 크리에이터와 영화 제작자 등 소수의 외부 파트너에게 메타 무비 젠을 우선 제공 후 피드백을 반영해 기능을 개선할 계획으로, 단독 서비스로 출시하는 대신 2025년 중 인스타그램(Instagram)과 같은 자사 소셜미디어 플랫폼에 통합하여 제공할 방침n메타 무비 젠은 △동영상 생성 △개인화 동영상 생성 △동영상 편집 △오디오 생성의 4가지 기능을 지원∙(동영상 생성) 300억 개 매개변수의 AI 모델을 통해 초당 16프레임의 속도로 1,080p 해상도의 최대 16초 길이 동영상 생성을 지원∙(개인화 동영상 생성) 사용자가 자신이나 타인의 이미지와 텍스트를 입력해 원래 인물의 고유한 특징을 반영한 개인화 동영상을 제작 가능∙(동영상 편집) 특정 요소의 추가나 제거, 변경과 같은 부분적 수정 및 동영상 배경 또는 스타일 변경과 같은 광범위한 수정도 지원∙(오디오 생성) 130억 개 매개변수의 오디오 생성 모델을 통합해 동영상과 텍스트 프롬프트 기반으로 최대 45초 길이의 배경음, 음향 효과 등 고품질 오디오를 생성£메타 무비 젠, 인간 선호도 평가에서 오픈AI의 소라 능가n메타 무비 젠은 인간 선호도 평가에서 런웨이(Runway)의 젠(Gen) 3, 오픈AI의 소라(Sora)를 비롯한 경쟁 동영상 생성AI 모델보다 더 높은 점수를 기록∙메타 무비 젠과 경쟁 모델에 대하여 세 명의 인간 평가자가 점수를 매겨 비교 후 순승률(Net Win Rate)*을 계산한 결과, 메타 무비 젠은 젠 3와 소라, 클링(Kling) 1.5를 모두 능가* 두 모델(A와 B)에 대하여 3명의 인간 평가자가 A 선호 시 +1점, 동점이면 0점, B 선호 시 –1점을 매기는 식으로 계산해 승률(-100%~100% 값)을 구하며, 승률이 양수면 A 모델 선호,')], 'question': \"prompt1\\n\\nsystem\\n아래의 지침에 따라 행동해\\n\\n#역할\\n-주어진 문서를 기반으로 정확한 정보를 제공하는 AI\\n\\n#톤\\n-전문적\\n\\n#주의사항 \\n-문서에 명시되지 않은 사실은 답변에 포함하지 않음\\n-답변에는 문서의 표현을 최소 80% 이상 포함하되, 문맥의 일관성을 유지해야 함\\n-사용자가 문서에 없는 내용을 질문할 경우, '해당 내용은 문서에 포함되지 않았습니다'로 답변\\n\\nhuman\\n\\nQuestion: {question} \\n\\nContext: {context} \\n\\nAnswer:\\n\\n\\n\\n\\n\\n\\n\\n몰모에 대해 알려줘\"}\n",
      "Response for prompt1.txt:\n",
      "몰모(Molmo)는 앨런AI연구소(Allen Institute for AI, AI2)가 2024년 9월 25일 공개한 오픈소스 멀티모달 LLM 제품군입니다. 몰모는 72B 모델을 포함하여 데모 모델인 7B-D, 개방성이 가장 높은 7B-O, 그리고 전문가 혼합(MoE) 모델인 E-1B를 포함한 총 4개 모델로 구성되어 있습니다. 특히, E-1B 모델은 온디바이스 실행이 가능하다는 특징이 있습니다.\n",
      "\n",
      "몰모는 데이터 규모보다 품질을 중시하는 학습 방식을 채택하여 데이터 효율성이 뛰어나며, 컴퓨팅 자원이 제한된 환경에서도 유용하게 사용될 수 있습니다. 또한, 이 모델은 일상 사물, 표지판, 복잡한 차트, 시계, 메뉴판 등 다양한 시각 자료를 이해하고, 이미지를 구성하는 요소를 정확히 식별할 수 있어 웹 에이전트나 로봇 개발에 유리합니다.\n",
      "\n",
      "몰모-72B 모델은 다양한 벤치마크 평가에서 81.2점을 기록하여 'GPT-4o'(78.5점)와 '제미나이 1.5 Pro'(78.3점)보다 뛰어난 성능을 보였으며, 인간 선호도 평가에서도 1077점을 기록하여 GPT-4o(1079점)에 이어 2위에 올랐습니다. 전문가 혼합 모델인 몰모E-1B는 벤치마크 평균 점수 68.6점, 인간 선호도 평가에서는 1,032점을 기록하여 GPT-4V와 경쟁할 수 있는 수준입니다. AI2는 몰모의 언어와 시각 훈련 데이터, 미세조정 데이터, 모델 가중치 및 소스코드를 모두 공개하고 연구와 상업적 목적의 활용을 허용하고 있습니다.\n",
      "\n",
      "Prompt 2: prompt2.txt\n",
      "Debug Output: {'context': [Document(metadata={'source': 'ai_industry.pdf', 'page': 11}, page_content='KEY Contents £몰모-72B 모델, 벤치마크 평가에서 GPT-4o와 제미나이 1.5 Pro 능가n미국 비영리 연구기관 앨런AI연구소(Allen Institute for AI, 이하 AI2)가 2024년 9월 25일 오픈소스 멀티모달 LLM 제품군 ‘몰모(Molmo)’를 공개∙몰모는 가장 규모가 크고 성능이 뛰어난 72B와 데모 모델 7B-D, 개방성이 가장 높은 7B-O, 70억 개의 전체 매개변수 중 10억 개만 활성화하는 전문가혼합(MoE) 모델 E-1B의 4개 모델로 구성되며, 이 중 E-1B 모델은 온디바이스 실행 가능∙몰모는 데이터 규모보다 품질을 중시하는 학습 방식으로 데이터 효율성이 뛰어나 컴퓨팅 자원이 한정된 환경에서도 사용 가능한 것이 장점∙몰모는 일상 사물과 표지판, 복잡한 차트, 시계, 메뉴판 등 다양한 시각 자료를 이해하고 이미지를 구성하는 요소를 정확히 지목할 수 있어, 화면과 현실 세계 간 복잡한 상호작용(예: 비행기 표 예약)이 필요한 웹 에이전트나 로봇 개발에도 유리∙AI2는 몰모의 언어와 시각 훈련 데이터, 미세조정 데이터, 모델 가중치, 소스코드를 모두 공개하고 연구와 상업적 목적의 활용을 허용nAI2에 따르면 몰모-72B 모델은 주요 벤치마크와 인간 선호도 평가*에서 첨단 폐쇄형 모델을 능가* 870명의 인간 평가자에게 다양한 이미지와 텍스트 프롬프트 쌍에 대한 모델 간 응답을 비교해 선호도 평가를 요청해 순위를 산정  ∙몰모-72B는 11개 벤치마크 평균 점수 81.2점으로 ‘GPT-4o’(78.5점), ‘제미나이 1.5 Pro’(78.3점), ‘클로드-3.5 소네트’(76.7점)를 넘는 최고 점수를 기록했으며 인간 선호도 평가에서는 1077점으로 GPT-4o(1079점)에 이어 2위∙전문가혼합 모델인 몰모E-1B는 벤치마크 평균 점수에서 68.6점, 인간 선호도 평가는 1,032점으로 각각 71.1점과 1,041점을 받은 GPT-4V과 경쟁할 수 있는 수준'), Document(metadata={'source': 'ai_industry.pdf', 'page': 11}, page_content='1. 정책/법제  2. 기업/산업 3. 기술/연구  4. 인력/교육\\n9\\n 앨런AI연구소, 벤치마크 평가에서 GPT-4o 능가하는 성능의 오픈소스 LLM ‘몰모’ 공개n앨런AI연구소가 공개한 멀티모달 LLM 제품군 몰모는 벤치마크 평가에서 GPT-4o를 능가하는 성능의 72B 모델과 전문가혼합 모델, 온디바이스 모델 등 4개 모델로 구성n몰모-72B 모델은 시각적 이해 능력이 뛰어나며 벤치마크 평가 및 인간 선호도 평가에서 첨단 폐쇄형 모델을 능가하는 점수를 기록'), Document(metadata={'source': 'ai_industry.pdf', 'page': 9}, page_content='£메타, 동영상 제작과 편집, 오디오 생성을 지원하는 메타 무비 젠을 공개 n메타(Meta)가 2024년 10월 4일 텍스트 입력을 통해 고해상도 동영상을 생성하는 AI 도구 ‘메타 무비 젠(Meta Movie Gen)’을 공개∙메타는 크리에이터와 영화 제작자 등 소수의 외부 파트너에게 메타 무비 젠을 우선 제공 후 피드백을 반영해 기능을 개선할 계획으로, 단독 서비스로 출시하는 대신 2025년 중 인스타그램(Instagram)과 같은 자사 소셜미디어 플랫폼에 통합하여 제공할 방침n메타 무비 젠은 △동영상 생성 △개인화 동영상 생성 △동영상 편집 △오디오 생성의 4가지 기능을 지원∙(동영상 생성) 300억 개 매개변수의 AI 모델을 통해 초당 16프레임의 속도로 1,080p 해상도의 최대 16초 길이 동영상 생성을 지원∙(개인화 동영상 생성) 사용자가 자신이나 타인의 이미지와 텍스트를 입력해 원래 인물의 고유한 특징을 반영한 개인화 동영상을 제작 가능∙(동영상 편집) 특정 요소의 추가나 제거, 변경과 같은 부분적 수정 및 동영상 배경 또는 스타일 변경과 같은 광범위한 수정도 지원∙(오디오 생성) 130억 개 매개변수의 오디오 생성 모델을 통합해 동영상과 텍스트 프롬프트 기반으로 최대 45초 길이의 배경음, 음향 효과 등 고품질 오디오를 생성£메타 무비 젠, 인간 선호도 평가에서 오픈AI의 소라 능가n메타 무비 젠은 인간 선호도 평가에서 런웨이(Runway)의 젠(Gen) 3, 오픈AI의 소라(Sora)를 비롯한 경쟁 동영상 생성AI 모델보다 더 높은 점수를 기록∙메타 무비 젠과 경쟁 모델에 대하여 세 명의 인간 평가자가 점수를 매겨 비교 후 순승률(Net Win Rate)*을 계산한 결과, 메타 무비 젠은 젠 3와 소라, 클링(Kling) 1.5를 모두 능가* 두 모델(A와 B)에 대하여 3명의 인간 평가자가 A 선호 시 +1점, 동점이면 0점, B 선호 시 –1점을 매기는 식으로 계산해 승률(-100%~100% 값)을 구하며, 승률이 양수면 A 모델 선호,')], 'question': 'prompt2\\n\\nsystem\\n아래의 지침에 따라 행동해\\n\\n#역할\\n-주어진 문서를 기반으로 정보를 제공하는 AI\\n\\n#톤\\n-중립적\\n\\n#주의사항\\n1. 가능하다면 100자 이내로 답변하되, 중요 정보를 누락하면 안 됨\\n2. 1번을 만족하기 위해 내용을 요약하거나 재구성해도 됨\\n3. 문서에 없는 내용이라도 문서 내용을 기반으로 답변하려고 노력하되, 문서에 직접 명시되지 않았음을 언급해야 함\\n\\n\\nhuman\\n\\nQuestion: {question} \\n\\nContext: {context} \\n\\nAnswer:\\n\\n몰모에 대해 알려줘'}\n",
      "Response for prompt2.txt:\n",
      "몰모(Molmo)는 앨런AI연구소가 공개한 오픈소스 멀티모달 LLM 제품군으로, 72B 모델을 포함하여 총 4개 모델로 구성됩니다. 이 모델은 시각적 이해 능력이 뛰어나며, 벤치마크 평가에서 GPT-4o를 능가했습니다. 데이터 효율성이 높아 제한된 자원에서도 사용 가능합니다.\n",
      "\n",
      "Prompt 3: prompt3.txt\n",
      "Debug Output: {'context': [Document(metadata={'source': 'ai_industry.pdf', 'page': 11}, page_content='KEY Contents £몰모-72B 모델, 벤치마크 평가에서 GPT-4o와 제미나이 1.5 Pro 능가n미국 비영리 연구기관 앨런AI연구소(Allen Institute for AI, 이하 AI2)가 2024년 9월 25일 오픈소스 멀티모달 LLM 제품군 ‘몰모(Molmo)’를 공개∙몰모는 가장 규모가 크고 성능이 뛰어난 72B와 데모 모델 7B-D, 개방성이 가장 높은 7B-O, 70억 개의 전체 매개변수 중 10억 개만 활성화하는 전문가혼합(MoE) 모델 E-1B의 4개 모델로 구성되며, 이 중 E-1B 모델은 온디바이스 실행 가능∙몰모는 데이터 규모보다 품질을 중시하는 학습 방식으로 데이터 효율성이 뛰어나 컴퓨팅 자원이 한정된 환경에서도 사용 가능한 것이 장점∙몰모는 일상 사물과 표지판, 복잡한 차트, 시계, 메뉴판 등 다양한 시각 자료를 이해하고 이미지를 구성하는 요소를 정확히 지목할 수 있어, 화면과 현실 세계 간 복잡한 상호작용(예: 비행기 표 예약)이 필요한 웹 에이전트나 로봇 개발에도 유리∙AI2는 몰모의 언어와 시각 훈련 데이터, 미세조정 데이터, 모델 가중치, 소스코드를 모두 공개하고 연구와 상업적 목적의 활용을 허용nAI2에 따르면 몰모-72B 모델은 주요 벤치마크와 인간 선호도 평가*에서 첨단 폐쇄형 모델을 능가* 870명의 인간 평가자에게 다양한 이미지와 텍스트 프롬프트 쌍에 대한 모델 간 응답을 비교해 선호도 평가를 요청해 순위를 산정  ∙몰모-72B는 11개 벤치마크 평균 점수 81.2점으로 ‘GPT-4o’(78.5점), ‘제미나이 1.5 Pro’(78.3점), ‘클로드-3.5 소네트’(76.7점)를 넘는 최고 점수를 기록했으며 인간 선호도 평가에서는 1077점으로 GPT-4o(1079점)에 이어 2위∙전문가혼합 모델인 몰모E-1B는 벤치마크 평균 점수에서 68.6점, 인간 선호도 평가는 1,032점으로 각각 71.1점과 1,041점을 받은 GPT-4V과 경쟁할 수 있는 수준'), Document(metadata={'source': 'ai_industry.pdf', 'page': 11}, page_content='1. 정책/법제  2. 기업/산업 3. 기술/연구  4. 인력/교육\\n9\\n 앨런AI연구소, 벤치마크 평가에서 GPT-4o 능가하는 성능의 오픈소스 LLM ‘몰모’ 공개n앨런AI연구소가 공개한 멀티모달 LLM 제품군 몰모는 벤치마크 평가에서 GPT-4o를 능가하는 성능의 72B 모델과 전문가혼합 모델, 온디바이스 모델 등 4개 모델로 구성n몰모-72B 모델은 시각적 이해 능력이 뛰어나며 벤치마크 평가 및 인간 선호도 평가에서 첨단 폐쇄형 모델을 능가하는 점수를 기록'), Document(metadata={'source': 'ai_industry.pdf', 'page': 9}, page_content='£메타, 동영상 제작과 편집, 오디오 생성을 지원하는 메타 무비 젠을 공개 n메타(Meta)가 2024년 10월 4일 텍스트 입력을 통해 고해상도 동영상을 생성하는 AI 도구 ‘메타 무비 젠(Meta Movie Gen)’을 공개∙메타는 크리에이터와 영화 제작자 등 소수의 외부 파트너에게 메타 무비 젠을 우선 제공 후 피드백을 반영해 기능을 개선할 계획으로, 단독 서비스로 출시하는 대신 2025년 중 인스타그램(Instagram)과 같은 자사 소셜미디어 플랫폼에 통합하여 제공할 방침n메타 무비 젠은 △동영상 생성 △개인화 동영상 생성 △동영상 편집 △오디오 생성의 4가지 기능을 지원∙(동영상 생성) 300억 개 매개변수의 AI 모델을 통해 초당 16프레임의 속도로 1,080p 해상도의 최대 16초 길이 동영상 생성을 지원∙(개인화 동영상 생성) 사용자가 자신이나 타인의 이미지와 텍스트를 입력해 원래 인물의 고유한 특징을 반영한 개인화 동영상을 제작 가능∙(동영상 편집) 특정 요소의 추가나 제거, 변경과 같은 부분적 수정 및 동영상 배경 또는 스타일 변경과 같은 광범위한 수정도 지원∙(오디오 생성) 130억 개 매개변수의 오디오 생성 모델을 통합해 동영상과 텍스트 프롬프트 기반으로 최대 45초 길이의 배경음, 음향 효과 등 고품질 오디오를 생성£메타 무비 젠, 인간 선호도 평가에서 오픈AI의 소라 능가n메타 무비 젠은 인간 선호도 평가에서 런웨이(Runway)의 젠(Gen) 3, 오픈AI의 소라(Sora)를 비롯한 경쟁 동영상 생성AI 모델보다 더 높은 점수를 기록∙메타 무비 젠과 경쟁 모델에 대하여 세 명의 인간 평가자가 점수를 매겨 비교 후 순승률(Net Win Rate)*을 계산한 결과, 메타 무비 젠은 젠 3와 소라, 클링(Kling) 1.5를 모두 능가* 두 모델(A와 B)에 대하여 3명의 인간 평가자가 A 선호 시 +1점, 동점이면 0점, B 선호 시 –1점을 매기는 식으로 계산해 승률(-100%~100% 값)을 구하며, 승률이 양수면 A 모델 선호,')], 'question': 'prompt3\\n\\nsystem\\n아래의 지침에 따라 행동해\\n\\n#역할\\n- 소프트웨어 정책연구소(SPRi)의 홍보담당자 \\n\\n#톤\\n-친절함\\n-정중함\\n\\n#주의사항\\n1. 답변은 주어진 문서에 근거해야 함\\n2. 전문용어를 피하고 예시를 들어 대중들이 이해하기 쉽게 대답해야 함\\n3. 사용자가 문서에 포함되지 않는 내용을 질문하면,  문서에 없다는 답변과 함께 SPRi에 문의하도록 함\\n4. 3의 문의는 아래의 홈페이지 주소, 이메일주소, 전화번호를 안내함\\n홈페이지 : https://spri.kr/\\nAI정책연구실(hs.lee@spri.kr, 031-739-7333)\\n\\nhuman\\n\\nQuestion: {question} \\n\\nContext: {context} \\n\\nAnswer:\\n몰모에 대해 알려줘'}\n",
      "Response for prompt3.txt:\n",
      "몰모(Molmo)는 앨런AI연구소에서 개발한 오픈소스 멀티모달 대형 언어 모델(LLM) 제품군입니다. 이 제품군은 다양한 모델로 구성되어 있는데, 가장 큰 모델인 몰모-72B는 720억 개의 매개변수를 가지고 있어 뛰어난 성능을 자랑합니다. 몰모는 특히 시각적 자료를 이해하는 능력이 뛰어나며, 벤치마크 평가에서 다른 첨단 모델들을 능가하는 성과를 보였습니다.\n",
      "\n",
      "몰모는 4개의 모델로 이루어져 있습니다:\n",
      "1. 몰모-72B: 가장 규모가 크고 성능이 뛰어난 모델\n",
      "2. 7B-D: 데모 모델\n",
      "3. 7B-O: 개방성이 높은 모델\n",
      "4. E-1B: 전문가 혼합 모델로, 온디바이스 실행이 가능한 특성이 있습니다.\n",
      "\n",
      "몰모는 데이터의 양보다 품질을 중시하여 학습하며, 이를 통해 컴퓨팅 자원이 제한된 환경에서도 효율적으로 사용될 수 있습니다. 또한, 몰모는 다양한 시각 자료를 이해하고, 복잡한 상호작용이 필요한 웹 에이전트나 로봇 개발에 유리한 점이 있습니다.\n",
      "\n",
      "앨런AI연구소는 몰모의 언어와 시각 훈련 데이터, 모델 가중치, 소스코드를 모두 공개하여 연구 및 상업적 목적의 활용을 허용하고 있습니다.\n",
      "\n",
      "더 궁금한 점이 있으시면, SPRi에 문의해 주시면 자세한 정보를 안내해 드리겠습니다. 홈페이지: [SPRi](https://spri.kr/) / 이메일: hs.lee@spri.kr / 전화: 031-739-7333.\n",
      "========================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "질문을 입력하세요 (종료하려면 'exit' 입력):  라마3.2와 알파카3.2를 비교해줘\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 1: prompt1.txt\n",
      "Debug Output: {'context': [Document(metadata={'source': 'ai_industry.pdf', 'page': 10}, page_content='£라마 3.2 90B 모델, 이미지 인식과 시각적 이해에서 GPT-4o-미니와 대등한 성능n메타가 2024년 9월 25일 ‘라마(Llama)’ 시리즈 최초로 이미지와 텍스트를 모두 처리하는 ‘라 마 3.2’를 공개∙라마 3.2 시리즈는 이미지를 처리하는 비전(Vision) 기능을 갖춘 매개변수 110억 개(11B)와 900억 개(90B)의 모델 및 모바일 기기에 적합한 매개변수 10억 개(1B)와 30억 개(3B)의 경량 모델로 구성∙2024년 7월 공개된 라마 3.1과 비교해 라마 3.2는 전반적 성능 향상 외 비전 기능이 추가되어 이미지 추론을 지원하며 모바일 기기에서 실행 가능한 경량 모델이 추가되어 접근성을 향상n라마 3.2 시리즈 중 11B와 90B 모델은 차트와 그래프를 포함한 문서 이해, 이미지 캡션, 이미지 안의 물체 식별과 같은 이미지 추론을 지원∙라마 3.2는 이미지에서 세부 정보를 추출하고 장면을 이해하여 이미지 캡션으로 사용할 수 있도록 내용을 전달하는 문장을 생성 가능∙이미지 인식과 시각적 이해 관련 90B 모델의 벤치마크 평가 결과는 앤스로픽(Anthropic)의 ‘클로드 3-하이쿠’나 오픈AI의 ‘GPT-4o-미니’와 대등한 수준으로, 일례로 시각적 수학 추론(MathVista)에서 57.3점으로 클로드 3-하이쿠(46.4점)와 GPT-4o-미니(56.7점)를 능가 n라마 3.2 시리즈 중 1B와 3B 경량 모델은 12만 8천 개 토큰의 컨텍스트 창을 지원하고 다국어 텍스트 생성과 도구 호출 기능을 제공하며, 데이터를 기기 내에 보관하는 온디바이스 앱 개발에 특화∙모델 평가 결과, 3B 모델은 지시 이행, 요약, 신속한 재작성 및 도구 사용과 같은 작업에서 구글(Google)의 ‘젬마 2 2.6B’ 및 마이크로소프트(Microsoft)의 ‘파이 3.5-미니’보다 성능이 우수∙일례로 텍스트 재작성(Open-rewrite eval) 평가에서 3B 모델은 40.1점으로 젬마 2 2.6B(31.2점) 및 파이-3.5-미니(34.5점)를'), Document(metadata={'source': 'ai_industry.pdf', 'page': 10}, page_content='3B 모델은 지시 이행, 요약, 신속한 재작성 및 도구 사용과 같은 작업에서 구글(Google)의 ‘젬마 2 2.6B’ 및 마이크로소프트(Microsoft)의 ‘파이 3.5-미니’보다 성능이 우수∙일례로 텍스트 재작성(Open-rewrite eval) 평가에서 3B 모델은 40.1점으로 젬마 2 2.6B(31.2점) 및 파이-3.5-미니(34.5점)를 앞섰으며, 텍스트 요약 능력(TLDR9+)에서는 19.0점으로 젬마 2 2.6B(13.9점) 및 파이-3.5-미니(12.8점)를 능가n메타는 라마 3.2 출시와 함께 개발자들이 라마 모델을 더욱 쉽고 효율적으로 사용할 수 있도록 지원하는 표준화 인터페이스인 ‘라마 스택(Llama Stack)’도 공개∙개발자들은 라마 스택을 통해 온프레미스*, 클라우드, 온디바이스 등 다양한 환경에서 일관적이고 간소화된 방식으로 라마 모델을 구축 가능* 기업이 자체 시설에서 보유하고 직접 유지 관리하는 데이터센터☞ 출처: Meta, Llama 3.2: Revolutionizing edge AI and vision with open, customizable models, 2024.09.25.'), Document(metadata={'source': 'ai_industry.pdf', 'page': 10}, page_content='SPRi AI Brief |  2024-11월호\\n8\\n메타, 이미지와 텍스트 처리하는 첫 멀티모달 AI 모델 ‘라마 3.2’ 공개n메타가 이미지와 텍스트를 모두 처리할 수 있는 모델과 모바일 기기에서 실행 가능한 경량 모델을 포함하는 라마 3.2 시리즈를 공개n비전 기능을 갖춘 라마 3.2 90B 모델은 다양한 이미지 인식과 시각적 이해 작업에서 앤스로픽의 ‘클로드3-하이쿠’ 및 오픈AI의 ‘GPT-4o-미니’와 대등한 수준의 성능 보유\\nKEY Contents')], 'question': \"prompt1\\n\\nsystem\\n아래의 지침에 따라 행동해\\n\\n#역할\\n-주어진 문서를 기반으로 정확한 정보를 제공하는 AI\\n\\n#톤\\n-전문적\\n\\n#주의사항 \\n-문서에 명시되지 않은 사실은 답변에 포함하지 않음\\n-답변에는 문서의 표현을 최소 80% 이상 포함하되, 문맥의 일관성을 유지해야 함\\n-사용자가 문서에 없는 내용을 질문할 경우, '해당 내용은 문서에 포함되지 않았습니다'로 답변\\n\\nhuman\\n\\nQuestion: {question} \\n\\nContext: {context} \\n\\nAnswer:\\n\\n\\n\\n\\n\\n\\n\\n라마3.2와 알파카3.2를 비교해줘\"}\n",
      "Response for prompt1.txt:\n",
      "해당 내용은 문서에 포함되지 않았습니다.\n",
      "\n",
      "Prompt 2: prompt2.txt\n",
      "Debug Output: {'context': [Document(metadata={'source': 'ai_industry.pdf', 'page': 10}, page_content='£라마 3.2 90B 모델, 이미지 인식과 시각적 이해에서 GPT-4o-미니와 대등한 성능n메타가 2024년 9월 25일 ‘라마(Llama)’ 시리즈 최초로 이미지와 텍스트를 모두 처리하는 ‘라 마 3.2’를 공개∙라마 3.2 시리즈는 이미지를 처리하는 비전(Vision) 기능을 갖춘 매개변수 110억 개(11B)와 900억 개(90B)의 모델 및 모바일 기기에 적합한 매개변수 10억 개(1B)와 30억 개(3B)의 경량 모델로 구성∙2024년 7월 공개된 라마 3.1과 비교해 라마 3.2는 전반적 성능 향상 외 비전 기능이 추가되어 이미지 추론을 지원하며 모바일 기기에서 실행 가능한 경량 모델이 추가되어 접근성을 향상n라마 3.2 시리즈 중 11B와 90B 모델은 차트와 그래프를 포함한 문서 이해, 이미지 캡션, 이미지 안의 물체 식별과 같은 이미지 추론을 지원∙라마 3.2는 이미지에서 세부 정보를 추출하고 장면을 이해하여 이미지 캡션으로 사용할 수 있도록 내용을 전달하는 문장을 생성 가능∙이미지 인식과 시각적 이해 관련 90B 모델의 벤치마크 평가 결과는 앤스로픽(Anthropic)의 ‘클로드 3-하이쿠’나 오픈AI의 ‘GPT-4o-미니’와 대등한 수준으로, 일례로 시각적 수학 추론(MathVista)에서 57.3점으로 클로드 3-하이쿠(46.4점)와 GPT-4o-미니(56.7점)를 능가 n라마 3.2 시리즈 중 1B와 3B 경량 모델은 12만 8천 개 토큰의 컨텍스트 창을 지원하고 다국어 텍스트 생성과 도구 호출 기능을 제공하며, 데이터를 기기 내에 보관하는 온디바이스 앱 개발에 특화∙모델 평가 결과, 3B 모델은 지시 이행, 요약, 신속한 재작성 및 도구 사용과 같은 작업에서 구글(Google)의 ‘젬마 2 2.6B’ 및 마이크로소프트(Microsoft)의 ‘파이 3.5-미니’보다 성능이 우수∙일례로 텍스트 재작성(Open-rewrite eval) 평가에서 3B 모델은 40.1점으로 젬마 2 2.6B(31.2점) 및 파이-3.5-미니(34.5점)를'), Document(metadata={'source': 'ai_industry.pdf', 'page': 10}, page_content='3B 모델은 지시 이행, 요약, 신속한 재작성 및 도구 사용과 같은 작업에서 구글(Google)의 ‘젬마 2 2.6B’ 및 마이크로소프트(Microsoft)의 ‘파이 3.5-미니’보다 성능이 우수∙일례로 텍스트 재작성(Open-rewrite eval) 평가에서 3B 모델은 40.1점으로 젬마 2 2.6B(31.2점) 및 파이-3.5-미니(34.5점)를 앞섰으며, 텍스트 요약 능력(TLDR9+)에서는 19.0점으로 젬마 2 2.6B(13.9점) 및 파이-3.5-미니(12.8점)를 능가n메타는 라마 3.2 출시와 함께 개발자들이 라마 모델을 더욱 쉽고 효율적으로 사용할 수 있도록 지원하는 표준화 인터페이스인 ‘라마 스택(Llama Stack)’도 공개∙개발자들은 라마 스택을 통해 온프레미스*, 클라우드, 온디바이스 등 다양한 환경에서 일관적이고 간소화된 방식으로 라마 모델을 구축 가능* 기업이 자체 시설에서 보유하고 직접 유지 관리하는 데이터센터☞ 출처: Meta, Llama 3.2: Revolutionizing edge AI and vision with open, customizable models, 2024.09.25.'), Document(metadata={'source': 'ai_industry.pdf', 'page': 10}, page_content='SPRi AI Brief |  2024-11월호\\n8\\n메타, 이미지와 텍스트 처리하는 첫 멀티모달 AI 모델 ‘라마 3.2’ 공개n메타가 이미지와 텍스트를 모두 처리할 수 있는 모델과 모바일 기기에서 실행 가능한 경량 모델을 포함하는 라마 3.2 시리즈를 공개n비전 기능을 갖춘 라마 3.2 90B 모델은 다양한 이미지 인식과 시각적 이해 작업에서 앤스로픽의 ‘클로드3-하이쿠’ 및 오픈AI의 ‘GPT-4o-미니’와 대등한 수준의 성능 보유\\nKEY Contents')], 'question': 'prompt2\\n\\nsystem\\n아래의 지침에 따라 행동해\\n\\n#역할\\n-주어진 문서를 기반으로 정보를 제공하는 AI\\n\\n#톤\\n-중립적\\n\\n#주의사항\\n1. 가능하다면 100자 이내로 답변하되, 중요 정보를 누락하면 안 됨\\n2. 1번을 만족하기 위해 내용을 요약하거나 재구성해도 됨\\n3. 문서에 없는 내용이라도 문서 내용을 기반으로 답변하려고 노력하되, 문서에 직접 명시되지 않았음을 언급해야 함\\n\\n\\nhuman\\n\\nQuestion: {question} \\n\\nContext: {context} \\n\\nAnswer:\\n\\n라마3.2와 알파카3.2를 비교해줘'}\n",
      "Response for prompt2.txt:\n",
      "현재 문서에는 라마 3.2와 알파카 3.2에 대한 직접적인 비교 정보가 없습니다. 그러나 라마 3.2는 이미지와 텍스트를 모두 처리하는 멀티모달 AI 모델로, 다양한 시각적 이해 작업에서 뛰어난 성능을 보입니다. 알파카 3.2에 대한 세부 정보는 제공되지 않아 비교할 수 없습니다.\n",
      "\n",
      "Prompt 3: prompt3.txt\n",
      "Debug Output: {'context': [Document(metadata={'source': 'ai_industry.pdf', 'page': 10}, page_content='£라마 3.2 90B 모델, 이미지 인식과 시각적 이해에서 GPT-4o-미니와 대등한 성능n메타가 2024년 9월 25일 ‘라마(Llama)’ 시리즈 최초로 이미지와 텍스트를 모두 처리하는 ‘라 마 3.2’를 공개∙라마 3.2 시리즈는 이미지를 처리하는 비전(Vision) 기능을 갖춘 매개변수 110억 개(11B)와 900억 개(90B)의 모델 및 모바일 기기에 적합한 매개변수 10억 개(1B)와 30억 개(3B)의 경량 모델로 구성∙2024년 7월 공개된 라마 3.1과 비교해 라마 3.2는 전반적 성능 향상 외 비전 기능이 추가되어 이미지 추론을 지원하며 모바일 기기에서 실행 가능한 경량 모델이 추가되어 접근성을 향상n라마 3.2 시리즈 중 11B와 90B 모델은 차트와 그래프를 포함한 문서 이해, 이미지 캡션, 이미지 안의 물체 식별과 같은 이미지 추론을 지원∙라마 3.2는 이미지에서 세부 정보를 추출하고 장면을 이해하여 이미지 캡션으로 사용할 수 있도록 내용을 전달하는 문장을 생성 가능∙이미지 인식과 시각적 이해 관련 90B 모델의 벤치마크 평가 결과는 앤스로픽(Anthropic)의 ‘클로드 3-하이쿠’나 오픈AI의 ‘GPT-4o-미니’와 대등한 수준으로, 일례로 시각적 수학 추론(MathVista)에서 57.3점으로 클로드 3-하이쿠(46.4점)와 GPT-4o-미니(56.7점)를 능가 n라마 3.2 시리즈 중 1B와 3B 경량 모델은 12만 8천 개 토큰의 컨텍스트 창을 지원하고 다국어 텍스트 생성과 도구 호출 기능을 제공하며, 데이터를 기기 내에 보관하는 온디바이스 앱 개발에 특화∙모델 평가 결과, 3B 모델은 지시 이행, 요약, 신속한 재작성 및 도구 사용과 같은 작업에서 구글(Google)의 ‘젬마 2 2.6B’ 및 마이크로소프트(Microsoft)의 ‘파이 3.5-미니’보다 성능이 우수∙일례로 텍스트 재작성(Open-rewrite eval) 평가에서 3B 모델은 40.1점으로 젬마 2 2.6B(31.2점) 및 파이-3.5-미니(34.5점)를'), Document(metadata={'source': 'ai_industry.pdf', 'page': 10}, page_content='3B 모델은 지시 이행, 요약, 신속한 재작성 및 도구 사용과 같은 작업에서 구글(Google)의 ‘젬마 2 2.6B’ 및 마이크로소프트(Microsoft)의 ‘파이 3.5-미니’보다 성능이 우수∙일례로 텍스트 재작성(Open-rewrite eval) 평가에서 3B 모델은 40.1점으로 젬마 2 2.6B(31.2점) 및 파이-3.5-미니(34.5점)를 앞섰으며, 텍스트 요약 능력(TLDR9+)에서는 19.0점으로 젬마 2 2.6B(13.9점) 및 파이-3.5-미니(12.8점)를 능가n메타는 라마 3.2 출시와 함께 개발자들이 라마 모델을 더욱 쉽고 효율적으로 사용할 수 있도록 지원하는 표준화 인터페이스인 ‘라마 스택(Llama Stack)’도 공개∙개발자들은 라마 스택을 통해 온프레미스*, 클라우드, 온디바이스 등 다양한 환경에서 일관적이고 간소화된 방식으로 라마 모델을 구축 가능* 기업이 자체 시설에서 보유하고 직접 유지 관리하는 데이터센터☞ 출처: Meta, Llama 3.2: Revolutionizing edge AI and vision with open, customizable models, 2024.09.25.'), Document(metadata={'source': 'ai_industry.pdf', 'page': 10}, page_content='SPRi AI Brief |  2024-11월호\\n8\\n메타, 이미지와 텍스트 처리하는 첫 멀티모달 AI 모델 ‘라마 3.2’ 공개n메타가 이미지와 텍스트를 모두 처리할 수 있는 모델과 모바일 기기에서 실행 가능한 경량 모델을 포함하는 라마 3.2 시리즈를 공개n비전 기능을 갖춘 라마 3.2 90B 모델은 다양한 이미지 인식과 시각적 이해 작업에서 앤스로픽의 ‘클로드3-하이쿠’ 및 오픈AI의 ‘GPT-4o-미니’와 대등한 수준의 성능 보유\\nKEY Contents')], 'question': 'prompt3\\n\\nsystem\\n아래의 지침에 따라 행동해\\n\\n#역할\\n- 소프트웨어 정책연구소(SPRi)의 홍보담당자 \\n\\n#톤\\n-친절함\\n-정중함\\n\\n#주의사항\\n1. 답변은 주어진 문서에 근거해야 함\\n2. 전문용어를 피하고 예시를 들어 대중들이 이해하기 쉽게 대답해야 함\\n3. 사용자가 문서에 포함되지 않는 내용을 질문하면,  문서에 없다는 답변과 함께 SPRi에 문의하도록 함\\n4. 3의 문의는 아래의 홈페이지 주소, 이메일주소, 전화번호를 안내함\\n홈페이지 : https://spri.kr/\\nAI정책연구실(hs.lee@spri.kr, 031-739-7333)\\n\\nhuman\\n\\nQuestion: {question} \\n\\nContext: {context} \\n\\nAnswer:\\n라마3.2와 알파카3.2를 비교해줘'}\n",
      "Response for prompt3.txt:\n",
      "죄송하지만, 문서에는 라마 3.2와 알파카 3.2에 대한 비교 내용이 포함되어 있지 않습니다. 더 자세한 정보를 원하시면 SPRi에 문의해 주세요. \n",
      "\n",
      "홈페이지: [https://spri.kr/](https://spri.kr/)  \n",
      "이메일: hs.lee@spri.kr  \n",
      "전화번호: 031-739-7333\n",
      "========================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "질문을 입력하세요 (종료하려면 'exit' 입력):  gaira가 발표된 날짜\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 1: prompt1.txt\n",
      "Debug Output: {'context': [Document(metadata={'source': 'ai_industry.pdf', 'page': 15}, page_content='£국무부, AI 연구 우선순위로 포괄적 연구 인프라 조성과 글로벌 도전과제 해결 등 제시n미국 국무부(United States Department of State)가 2024년 9월 23일 국제협력을 통해 안전하고 신뢰할 수 있는 AI 시스템을 개발하기 위한 R&D 원칙과 우선순위, 권장 사항을 제시한 ‘글로벌 AI 연구 의제(Global AI Research Agenda, 이하 GAIRA)’를 발표∙국무부는 2023년 10월 30일 바이든 대통령이 서명한 AI 행정명령에 따라 모든 사람에게 이로운 방식으로 개발·사용되는 AI R&D에 대한 포괄적이고 조정된 접근방식을 마련하고자 GAIRA를 작성하고, AI 연구에서 3가지 권장 원칙으로 △포용성·형평성 △책임 있는 연구 수행 △파트너십과 협업을 제시n국무부는 GAIRA를 통해 안전하고 신뢰할 수 있는 AI를 발전시키기 위한 연구 우선순위를 제시∙(사회 기술 연구) 기술과 사회 간 상호작용에 대한 이해를 심화하고 인간 복지를 향상하는 AI 시스템의 설계와 배포에 관한 연구를 수행 우선∙(포용적 연구 인프라 조성) AI 기술과 시스템의 혁신을 지원하는 데이터와 컴퓨팅 성능, 연구 플랫폼에 대한 접근성을 향상해 AI 연구와 개발 생태계의 다양성을 촉진하고 편향을 완화∙(글로벌 도전과제 해결) 환경 문제, 경제 회복력, 사회복지 등 글로벌 도전 과제 해결에 도움이 되는 AI 애플리케이션을 우선 개발∙(AI 안전과 보안, 신뢰성을 포함한 AI 기초연구) AI는 아직 개발 초기 단계로 안전하고 신뢰할 수 있는 AI 시스템 개발을 위해 더 많은 기술 발전 필요∙(글로벌 노동 시장에서 AI의 영향 연구) AI가 노동 시장에 미치는 여러 측면을 다루는 연구를 수행하고 노동 시장에 미치는 AI의 부정적 영향을 완화하기 위한 전략을 수립n국무부는 GAIRA를 통해 연구 기금 제공자, 연구 생태계 허브, 연구팀과 같은 이해관계자별로 연구 의제의 목표 달성을 위한 권장 사항을 제시∙(연구 기금 제공자) 투명성을 증진하고 국제 AI'), Document(metadata={'source': 'ai_industry.pdf', 'page': 0}, page_content='2024년 11월호'), Document(metadata={'source': 'ai_industry.pdf', 'page': 1}, page_content='2024년 11월호')], 'question': \"prompt1\\n\\nsystem\\n아래의 지침에 따라 행동해\\n\\n#역할\\n-주어진 문서를 기반으로 정확한 정보를 제공하는 AI\\n\\n#톤\\n-전문적\\n\\n#주의사항 \\n-문서에 명시되지 않은 사실은 답변에 포함하지 않음\\n-답변에는 문서의 표현을 최소 80% 이상 포함하되, 문맥의 일관성을 유지해야 함\\n-사용자가 문서에 없는 내용을 질문할 경우, '해당 내용은 문서에 포함되지 않았습니다'로 답변\\n\\nhuman\\n\\nQuestion: {question} \\n\\nContext: {context} \\n\\nAnswer:\\n\\n\\n\\n\\n\\n\\n\\ngaira가 발표된 날짜\"}\n",
      "Response for prompt1.txt:\n",
      "GAIRA는 2024년 9월 23일에 발표되었습니다.\n",
      "\n",
      "Prompt 2: prompt2.txt\n",
      "Debug Output: {'context': [Document(metadata={'source': 'ai_industry.pdf', 'page': 15}, page_content='£국무부, AI 연구 우선순위로 포괄적 연구 인프라 조성과 글로벌 도전과제 해결 등 제시n미국 국무부(United States Department of State)가 2024년 9월 23일 국제협력을 통해 안전하고 신뢰할 수 있는 AI 시스템을 개발하기 위한 R&D 원칙과 우선순위, 권장 사항을 제시한 ‘글로벌 AI 연구 의제(Global AI Research Agenda, 이하 GAIRA)’를 발표∙국무부는 2023년 10월 30일 바이든 대통령이 서명한 AI 행정명령에 따라 모든 사람에게 이로운 방식으로 개발·사용되는 AI R&D에 대한 포괄적이고 조정된 접근방식을 마련하고자 GAIRA를 작성하고, AI 연구에서 3가지 권장 원칙으로 △포용성·형평성 △책임 있는 연구 수행 △파트너십과 협업을 제시n국무부는 GAIRA를 통해 안전하고 신뢰할 수 있는 AI를 발전시키기 위한 연구 우선순위를 제시∙(사회 기술 연구) 기술과 사회 간 상호작용에 대한 이해를 심화하고 인간 복지를 향상하는 AI 시스템의 설계와 배포에 관한 연구를 수행 우선∙(포용적 연구 인프라 조성) AI 기술과 시스템의 혁신을 지원하는 데이터와 컴퓨팅 성능, 연구 플랫폼에 대한 접근성을 향상해 AI 연구와 개발 생태계의 다양성을 촉진하고 편향을 완화∙(글로벌 도전과제 해결) 환경 문제, 경제 회복력, 사회복지 등 글로벌 도전 과제 해결에 도움이 되는 AI 애플리케이션을 우선 개발∙(AI 안전과 보안, 신뢰성을 포함한 AI 기초연구) AI는 아직 개발 초기 단계로 안전하고 신뢰할 수 있는 AI 시스템 개발을 위해 더 많은 기술 발전 필요∙(글로벌 노동 시장에서 AI의 영향 연구) AI가 노동 시장에 미치는 여러 측면을 다루는 연구를 수행하고 노동 시장에 미치는 AI의 부정적 영향을 완화하기 위한 전략을 수립n국무부는 GAIRA를 통해 연구 기금 제공자, 연구 생태계 허브, 연구팀과 같은 이해관계자별로 연구 의제의 목표 달성을 위한 권장 사항을 제시∙(연구 기금 제공자) 투명성을 증진하고 국제 AI'), Document(metadata={'source': 'ai_industry.pdf', 'page': 0}, page_content='2024년 11월호'), Document(metadata={'source': 'ai_industry.pdf', 'page': 1}, page_content='2024년 11월호')], 'question': 'prompt2\\n\\nsystem\\n아래의 지침에 따라 행동해\\n\\n#역할\\n-주어진 문서를 기반으로 정보를 제공하는 AI\\n\\n#톤\\n-중립적\\n\\n#주의사항\\n1. 가능하다면 100자 이내로 답변하되, 중요 정보를 누락하면 안 됨\\n2. 1번을 만족하기 위해 내용을 요약하거나 재구성해도 됨\\n3. 문서에 없는 내용이라도 문서 내용을 기반으로 답변하려고 노력하되, 문서에 직접 명시되지 않았음을 언급해야 함\\n\\n\\nhuman\\n\\nQuestion: {question} \\n\\nContext: {context} \\n\\nAnswer:\\n\\ngaira가 발표된 날짜'}\n",
      "Response for prompt2.txt:\n",
      "GAIRA는 2024년 9월 23일에 발표되었습니다.\n",
      "\n",
      "Prompt 3: prompt3.txt\n",
      "Debug Output: {'context': [Document(metadata={'source': 'ai_industry.pdf', 'page': 15}, page_content='£국무부, AI 연구 우선순위로 포괄적 연구 인프라 조성과 글로벌 도전과제 해결 등 제시n미국 국무부(United States Department of State)가 2024년 9월 23일 국제협력을 통해 안전하고 신뢰할 수 있는 AI 시스템을 개발하기 위한 R&D 원칙과 우선순위, 권장 사항을 제시한 ‘글로벌 AI 연구 의제(Global AI Research Agenda, 이하 GAIRA)’를 발표∙국무부는 2023년 10월 30일 바이든 대통령이 서명한 AI 행정명령에 따라 모든 사람에게 이로운 방식으로 개발·사용되는 AI R&D에 대한 포괄적이고 조정된 접근방식을 마련하고자 GAIRA를 작성하고, AI 연구에서 3가지 권장 원칙으로 △포용성·형평성 △책임 있는 연구 수행 △파트너십과 협업을 제시n국무부는 GAIRA를 통해 안전하고 신뢰할 수 있는 AI를 발전시키기 위한 연구 우선순위를 제시∙(사회 기술 연구) 기술과 사회 간 상호작용에 대한 이해를 심화하고 인간 복지를 향상하는 AI 시스템의 설계와 배포에 관한 연구를 수행 우선∙(포용적 연구 인프라 조성) AI 기술과 시스템의 혁신을 지원하는 데이터와 컴퓨팅 성능, 연구 플랫폼에 대한 접근성을 향상해 AI 연구와 개발 생태계의 다양성을 촉진하고 편향을 완화∙(글로벌 도전과제 해결) 환경 문제, 경제 회복력, 사회복지 등 글로벌 도전 과제 해결에 도움이 되는 AI 애플리케이션을 우선 개발∙(AI 안전과 보안, 신뢰성을 포함한 AI 기초연구) AI는 아직 개발 초기 단계로 안전하고 신뢰할 수 있는 AI 시스템 개발을 위해 더 많은 기술 발전 필요∙(글로벌 노동 시장에서 AI의 영향 연구) AI가 노동 시장에 미치는 여러 측면을 다루는 연구를 수행하고 노동 시장에 미치는 AI의 부정적 영향을 완화하기 위한 전략을 수립n국무부는 GAIRA를 통해 연구 기금 제공자, 연구 생태계 허브, 연구팀과 같은 이해관계자별로 연구 의제의 목표 달성을 위한 권장 사항을 제시∙(연구 기금 제공자) 투명성을 증진하고 국제 AI'), Document(metadata={'source': 'ai_industry.pdf', 'page': 0}, page_content='2024년 11월호'), Document(metadata={'source': 'ai_industry.pdf', 'page': 1}, page_content='2024년 11월호')], 'question': 'prompt3\\n\\nsystem\\n아래의 지침에 따라 행동해\\n\\n#역할\\n- 소프트웨어 정책연구소(SPRi)의 홍보담당자 \\n\\n#톤\\n-친절함\\n-정중함\\n\\n#주의사항\\n1. 답변은 주어진 문서에 근거해야 함\\n2. 전문용어를 피하고 예시를 들어 대중들이 이해하기 쉽게 대답해야 함\\n3. 사용자가 문서에 포함되지 않는 내용을 질문하면,  문서에 없다는 답변과 함께 SPRi에 문의하도록 함\\n4. 3의 문의는 아래의 홈페이지 주소, 이메일주소, 전화번호를 안내함\\n홈페이지 : https://spri.kr/\\nAI정책연구실(hs.lee@spri.kr, 031-739-7333)\\n\\nhuman\\n\\nQuestion: {question} \\n\\nContext: {context} \\n\\nAnswer:\\ngaira가 발표된 날짜'}\n",
      "Response for prompt3.txt:\n",
      "GAIRA(글로벌 AI 연구 의제)는 2024년 9월 23일에 발표되었습니다. 추가적인 질문이 있으시다면, SPRi에 문의해 주시기 바랍니다. 홈페이지: [https://spri.kr/](https://spri.kr/), 이메일: hs.lee@spri.kr, 전화번호: 031-739-7333입니다.\n",
      "========================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "질문을 입력하세요 (종료하려면 'exit' 입력):  중국 ai안전연구소가 ai 안정성에 대한 평가 관점 가이드를 제시한 날짜\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 1: prompt1.txt\n",
      "Debug Output: {'context': [Document(metadata={'source': 'ai_industry.pdf', 'page': 16}, page_content='£일본 AI안전연구소, AI 개발자나 제공자의 안전성 평가를 위한 가이드라인 제시n일본 AI안전연구소(Japan AI Safety Institute)가 2024년 9월 25일 AI 개발자나 제공자가 안전성 평가 시에 참조할 수 있는 기본 개념을 제시하는 ‘AI 안전성에 대한 평가 관점 가이드’를 발간∙가이드는 AI 안전성의 핵심 요소로 △인간중심 △안전성 △공평성 △프라이버시 보호 △보안 △투명성을 제시하고, 이를 달성하기 위한 10가지 평가 관점 및 평가를 통한 효과적 조치 이후의 기대 목표를 수립평가 관점관련 AI 안전성 요소 기대 목표유해 정보의 출력 통제인간중심, 안전성, 공정성ŸLLM 시스템이 테러, 범죄, 불쾌한 표현 등 유해 정보의 출력을 통제 가능허위 정보와 조작 방지인간중심, 안전성, 투명성ŸLLM 시스템의 출력에 대한 사실 검증 메커니즘 구축ŸLLM 시스템의 출력에 의한 사용자 결정의 조작 방지공정성과 포용성인간중심, 공정성, 투명성ŸLLM 시스템 출력에 유해한 편향이 없으며 개인이나 집단에 대한 불공정한 차별 부재ŸLLM 시스템의 출력을 모든 최종 사용자가 이해 가능고위험 사용 및 비의도적 사용 대처인간중심, 안전성ŸLLM 시스템이 본래 목적과 다르게 부적절하게 사용되어도 피해나 불이익 미발생 개인정보 보호프라이버시 보호ŸLLM 시스템이 정보의 중요성에 따라 프라이버시를 적절히 보호보안 보안 ŸLLM 시스템의 허가되지 않은 운영 및 비의도적 수정 또는 중단으로 인한 기밀정보의 유출 방지설명 가능성투명성ŸLLM 시스템 작동에 대한 증거 제시 등을 목적으로 출력의 근거를 기술적으로 합리적인 범위에서 확인 가능견고성안전성, 투명성ŸLLM 시스템이 적대적 프롬프트, 왜곡된 데이터 및 잘못된 입력 등 예상치 않은 입력에 대해 안정적 출력을 제공데이터 품질안전성, 공정성, 투명성ŸLLM 시스템 학습을 위한 데이터가 적절한 상태로 유지되고 데이터 이력이 적절히 관리되는 상태검증 가능성투명성ŸLLM 시스템에 대한 다양한 유형의 검증이 모델 학습 단계에서'), Document(metadata={'source': 'ai_industry.pdf', 'page': 16}, page_content='SPRi AI Brief |  2024-11월호\\n14\\n일본 AI안전연구소, AI 안전성에 대한 평가 관점 가이드 발간n일본 AI안전연구소는 AI 개발자나 제공자가 안전성 평가에 참조할 수 있는 ‘AI 안전성에 대한 평가 관점 가이드’를 발표n가이드는 AI 안전성의 핵심 요소를 달성하기 위한 10가지 평가 관점과 함께, 평가를 통해 효과적 조치를 취했을 때의 기대 목표를 제시\\nKEY Contents'), Document(metadata={'source': 'ai_industry.pdf', 'page': 16}, page_content='<AI 안전성의 핵심 요소를 고려한 AI 안전성 평가 관점> \\nnAI 안전성 평가는 기본적으로 AI 시스템의 개발자 및 제공자에 의해 실시되며, AI 시스템 개발, 배포, 사용 단계에서 적절한 간격으로 시행될 필요∙AI 안전성 평가 범위는 개발 단계에서는 데이터, 배포와 사용 단계에서는 전체 LLM 시스템 등으로 달라질 수 있으며, 평가는 한 차례가 아니라 반복적으로 실시 ☞ 출처: Japan AI Safety Institute, AIセーフティに関する評価観点ガイドの公開, 2024.09.25.')], 'question': \"prompt1\\n\\nsystem\\n아래의 지침에 따라 행동해\\n\\n#역할\\n-주어진 문서를 기반으로 정확한 정보를 제공하는 AI\\n\\n#톤\\n-전문적\\n\\n#주의사항 \\n-문서에 명시되지 않은 사실은 답변에 포함하지 않음\\n-답변에는 문서의 표현을 최소 80% 이상 포함하되, 문맥의 일관성을 유지해야 함\\n-사용자가 문서에 없는 내용을 질문할 경우, '해당 내용은 문서에 포함되지 않았습니다'로 답변\\n\\nhuman\\n\\nQuestion: {question} \\n\\nContext: {context} \\n\\nAnswer:\\n\\n\\n\\n\\n\\n\\n\\n중국 ai안전연구소가 ai 안정성에 대한 평가 관점 가이드를 제시한 날짜\"}\n",
      "Response for prompt1.txt:\n",
      "해당 내용은 문서에 포함되지 않았습니다.\n",
      "\n",
      "Prompt 2: prompt2.txt\n",
      "Debug Output: {'context': [Document(metadata={'source': 'ai_industry.pdf', 'page': 16}, page_content='£일본 AI안전연구소, AI 개발자나 제공자의 안전성 평가를 위한 가이드라인 제시n일본 AI안전연구소(Japan AI Safety Institute)가 2024년 9월 25일 AI 개발자나 제공자가 안전성 평가 시에 참조할 수 있는 기본 개념을 제시하는 ‘AI 안전성에 대한 평가 관점 가이드’를 발간∙가이드는 AI 안전성의 핵심 요소로 △인간중심 △안전성 △공평성 △프라이버시 보호 △보안 △투명성을 제시하고, 이를 달성하기 위한 10가지 평가 관점 및 평가를 통한 효과적 조치 이후의 기대 목표를 수립평가 관점관련 AI 안전성 요소 기대 목표유해 정보의 출력 통제인간중심, 안전성, 공정성ŸLLM 시스템이 테러, 범죄, 불쾌한 표현 등 유해 정보의 출력을 통제 가능허위 정보와 조작 방지인간중심, 안전성, 투명성ŸLLM 시스템의 출력에 대한 사실 검증 메커니즘 구축ŸLLM 시스템의 출력에 의한 사용자 결정의 조작 방지공정성과 포용성인간중심, 공정성, 투명성ŸLLM 시스템 출력에 유해한 편향이 없으며 개인이나 집단에 대한 불공정한 차별 부재ŸLLM 시스템의 출력을 모든 최종 사용자가 이해 가능고위험 사용 및 비의도적 사용 대처인간중심, 안전성ŸLLM 시스템이 본래 목적과 다르게 부적절하게 사용되어도 피해나 불이익 미발생 개인정보 보호프라이버시 보호ŸLLM 시스템이 정보의 중요성에 따라 프라이버시를 적절히 보호보안 보안 ŸLLM 시스템의 허가되지 않은 운영 및 비의도적 수정 또는 중단으로 인한 기밀정보의 유출 방지설명 가능성투명성ŸLLM 시스템 작동에 대한 증거 제시 등을 목적으로 출력의 근거를 기술적으로 합리적인 범위에서 확인 가능견고성안전성, 투명성ŸLLM 시스템이 적대적 프롬프트, 왜곡된 데이터 및 잘못된 입력 등 예상치 않은 입력에 대해 안정적 출력을 제공데이터 품질안전성, 공정성, 투명성ŸLLM 시스템 학습을 위한 데이터가 적절한 상태로 유지되고 데이터 이력이 적절히 관리되는 상태검증 가능성투명성ŸLLM 시스템에 대한 다양한 유형의 검증이 모델 학습 단계에서'), Document(metadata={'source': 'ai_industry.pdf', 'page': 16}, page_content='SPRi AI Brief |  2024-11월호\\n14\\n일본 AI안전연구소, AI 안전성에 대한 평가 관점 가이드 발간n일본 AI안전연구소는 AI 개발자나 제공자가 안전성 평가에 참조할 수 있는 ‘AI 안전성에 대한 평가 관점 가이드’를 발표n가이드는 AI 안전성의 핵심 요소를 달성하기 위한 10가지 평가 관점과 함께, 평가를 통해 효과적 조치를 취했을 때의 기대 목표를 제시\\nKEY Contents'), Document(metadata={'source': 'ai_industry.pdf', 'page': 16}, page_content='<AI 안전성의 핵심 요소를 고려한 AI 안전성 평가 관점> \\nnAI 안전성 평가는 기본적으로 AI 시스템의 개발자 및 제공자에 의해 실시되며, AI 시스템 개발, 배포, 사용 단계에서 적절한 간격으로 시행될 필요∙AI 안전성 평가 범위는 개발 단계에서는 데이터, 배포와 사용 단계에서는 전체 LLM 시스템 등으로 달라질 수 있으며, 평가는 한 차례가 아니라 반복적으로 실시 ☞ 출처: Japan AI Safety Institute, AIセーフティに関する評価観点ガイドの公開, 2024.09.25.')], 'question': 'prompt2\\n\\nsystem\\n아래의 지침에 따라 행동해\\n\\n#역할\\n-주어진 문서를 기반으로 정보를 제공하는 AI\\n\\n#톤\\n-중립적\\n\\n#주의사항\\n1. 가능하다면 100자 이내로 답변하되, 중요 정보를 누락하면 안 됨\\n2. 1번을 만족하기 위해 내용을 요약하거나 재구성해도 됨\\n3. 문서에 없는 내용이라도 문서 내용을 기반으로 답변하려고 노력하되, 문서에 직접 명시되지 않았음을 언급해야 함\\n\\n\\nhuman\\n\\nQuestion: {question} \\n\\nContext: {context} \\n\\nAnswer:\\n\\n중국 ai안전연구소가 ai 안정성에 대한 평가 관점 가이드를 제시한 날짜'}\n",
      "Response for prompt2.txt:\n",
      "일본 AI안전연구소가 AI 안전성에 대한 평가 관점 가이드를 발간한 날짜는 2024년 9월 25일입니다.\n",
      "\n",
      "Prompt 3: prompt3.txt\n",
      "Debug Output: {'context': [Document(metadata={'source': 'ai_industry.pdf', 'page': 16}, page_content='£일본 AI안전연구소, AI 개발자나 제공자의 안전성 평가를 위한 가이드라인 제시n일본 AI안전연구소(Japan AI Safety Institute)가 2024년 9월 25일 AI 개발자나 제공자가 안전성 평가 시에 참조할 수 있는 기본 개념을 제시하는 ‘AI 안전성에 대한 평가 관점 가이드’를 발간∙가이드는 AI 안전성의 핵심 요소로 △인간중심 △안전성 △공평성 △프라이버시 보호 △보안 △투명성을 제시하고, 이를 달성하기 위한 10가지 평가 관점 및 평가를 통한 효과적 조치 이후의 기대 목표를 수립평가 관점관련 AI 안전성 요소 기대 목표유해 정보의 출력 통제인간중심, 안전성, 공정성ŸLLM 시스템이 테러, 범죄, 불쾌한 표현 등 유해 정보의 출력을 통제 가능허위 정보와 조작 방지인간중심, 안전성, 투명성ŸLLM 시스템의 출력에 대한 사실 검증 메커니즘 구축ŸLLM 시스템의 출력에 의한 사용자 결정의 조작 방지공정성과 포용성인간중심, 공정성, 투명성ŸLLM 시스템 출력에 유해한 편향이 없으며 개인이나 집단에 대한 불공정한 차별 부재ŸLLM 시스템의 출력을 모든 최종 사용자가 이해 가능고위험 사용 및 비의도적 사용 대처인간중심, 안전성ŸLLM 시스템이 본래 목적과 다르게 부적절하게 사용되어도 피해나 불이익 미발생 개인정보 보호프라이버시 보호ŸLLM 시스템이 정보의 중요성에 따라 프라이버시를 적절히 보호보안 보안 ŸLLM 시스템의 허가되지 않은 운영 및 비의도적 수정 또는 중단으로 인한 기밀정보의 유출 방지설명 가능성투명성ŸLLM 시스템 작동에 대한 증거 제시 등을 목적으로 출력의 근거를 기술적으로 합리적인 범위에서 확인 가능견고성안전성, 투명성ŸLLM 시스템이 적대적 프롬프트, 왜곡된 데이터 및 잘못된 입력 등 예상치 않은 입력에 대해 안정적 출력을 제공데이터 품질안전성, 공정성, 투명성ŸLLM 시스템 학습을 위한 데이터가 적절한 상태로 유지되고 데이터 이력이 적절히 관리되는 상태검증 가능성투명성ŸLLM 시스템에 대한 다양한 유형의 검증이 모델 학습 단계에서'), Document(metadata={'source': 'ai_industry.pdf', 'page': 16}, page_content='SPRi AI Brief |  2024-11월호\\n14\\n일본 AI안전연구소, AI 안전성에 대한 평가 관점 가이드 발간n일본 AI안전연구소는 AI 개발자나 제공자가 안전성 평가에 참조할 수 있는 ‘AI 안전성에 대한 평가 관점 가이드’를 발표n가이드는 AI 안전성의 핵심 요소를 달성하기 위한 10가지 평가 관점과 함께, 평가를 통해 효과적 조치를 취했을 때의 기대 목표를 제시\\nKEY Contents'), Document(metadata={'source': 'ai_industry.pdf', 'page': 16}, page_content='<AI 안전성의 핵심 요소를 고려한 AI 안전성 평가 관점> \\nnAI 안전성 평가는 기본적으로 AI 시스템의 개발자 및 제공자에 의해 실시되며, AI 시스템 개발, 배포, 사용 단계에서 적절한 간격으로 시행될 필요∙AI 안전성 평가 범위는 개발 단계에서는 데이터, 배포와 사용 단계에서는 전체 LLM 시스템 등으로 달라질 수 있으며, 평가는 한 차례가 아니라 반복적으로 실시 ☞ 출처: Japan AI Safety Institute, AIセーフティに関する評価観点ガイドの公開, 2024.09.25.')], 'question': 'prompt3\\n\\nsystem\\n아래의 지침에 따라 행동해\\n\\n#역할\\n- 소프트웨어 정책연구소(SPRi)의 홍보담당자 \\n\\n#톤\\n-친절함\\n-정중함\\n\\n#주의사항\\n1. 답변은 주어진 문서에 근거해야 함\\n2. 전문용어를 피하고 예시를 들어 대중들이 이해하기 쉽게 대답해야 함\\n3. 사용자가 문서에 포함되지 않는 내용을 질문하면,  문서에 없다는 답변과 함께 SPRi에 문의하도록 함\\n4. 3의 문의는 아래의 홈페이지 주소, 이메일주소, 전화번호를 안내함\\n홈페이지 : https://spri.kr/\\nAI정책연구실(hs.lee@spri.kr, 031-739-7333)\\n\\nhuman\\n\\nQuestion: {question} \\n\\nContext: {context} \\n\\nAnswer:\\n중국 ai안전연구소가 ai 안정성에 대한 평가 관점 가이드를 제시한 날짜'}\n",
      "Response for prompt3.txt:\n",
      "죄송하지만, 문서에는 중국 AI 안전 연구소에 대한 정보나 해당 기관이 AI 안정성에 대한 평가 관점 가이드를 제시한 날짜에 대한 내용이 포함되어 있지 않습니다. 더 궁금한 점이 있으시면 SPRi에 문의해 주시기 바랍니다.\n",
      "\n",
      "홈페이지: [https://spri.kr/](https://spri.kr/)  \n",
      "이메일: hs.lee@spri.kr  \n",
      "전화번호: 031-739-7333\n",
      "========================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "질문을 입력하세요 (종료하려면 'exit' 입력):  맘바! 잠바!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 1: prompt1.txt\n",
      "Debug Output: {'context': [Document(metadata={'source': 'ai_industry.pdf', 'page': 0}, page_content='2024년 11월호'), Document(metadata={'source': 'ai_industry.pdf', 'page': 1}, page_content='2024년 11월호'), Document(metadata={'source': 'ai_industry.pdf', 'page': 10}, page_content='£라마 3.2 90B 모델, 이미지 인식과 시각적 이해에서 GPT-4o-미니와 대등한 성능n메타가 2024년 9월 25일 ‘라마(Llama)’ 시리즈 최초로 이미지와 텍스트를 모두 처리하는 ‘라 마 3.2’를 공개∙라마 3.2 시리즈는 이미지를 처리하는 비전(Vision) 기능을 갖춘 매개변수 110억 개(11B)와 900억 개(90B)의 모델 및 모바일 기기에 적합한 매개변수 10억 개(1B)와 30억 개(3B)의 경량 모델로 구성∙2024년 7월 공개된 라마 3.1과 비교해 라마 3.2는 전반적 성능 향상 외 비전 기능이 추가되어 이미지 추론을 지원하며 모바일 기기에서 실행 가능한 경량 모델이 추가되어 접근성을 향상n라마 3.2 시리즈 중 11B와 90B 모델은 차트와 그래프를 포함한 문서 이해, 이미지 캡션, 이미지 안의 물체 식별과 같은 이미지 추론을 지원∙라마 3.2는 이미지에서 세부 정보를 추출하고 장면을 이해하여 이미지 캡션으로 사용할 수 있도록 내용을 전달하는 문장을 생성 가능∙이미지 인식과 시각적 이해 관련 90B 모델의 벤치마크 평가 결과는 앤스로픽(Anthropic)의 ‘클로드 3-하이쿠’나 오픈AI의 ‘GPT-4o-미니’와 대등한 수준으로, 일례로 시각적 수학 추론(MathVista)에서 57.3점으로 클로드 3-하이쿠(46.4점)와 GPT-4o-미니(56.7점)를 능가 n라마 3.2 시리즈 중 1B와 3B 경량 모델은 12만 8천 개 토큰의 컨텍스트 창을 지원하고 다국어 텍스트 생성과 도구 호출 기능을 제공하며, 데이터를 기기 내에 보관하는 온디바이스 앱 개발에 특화∙모델 평가 결과, 3B 모델은 지시 이행, 요약, 신속한 재작성 및 도구 사용과 같은 작업에서 구글(Google)의 ‘젬마 2 2.6B’ 및 마이크로소프트(Microsoft)의 ‘파이 3.5-미니’보다 성능이 우수∙일례로 텍스트 재작성(Open-rewrite eval) 평가에서 3B 모델은 40.1점으로 젬마 2 2.6B(31.2점) 및 파이-3.5-미니(34.5점)를')], 'question': \"prompt1\\n\\nsystem\\n아래의 지침에 따라 행동해\\n\\n#역할\\n-주어진 문서를 기반으로 정확한 정보를 제공하는 AI\\n\\n#톤\\n-전문적\\n\\n#주의사항 \\n-문서에 명시되지 않은 사실은 답변에 포함하지 않음\\n-답변에는 문서의 표현을 최소 80% 이상 포함하되, 문맥의 일관성을 유지해야 함\\n-사용자가 문서에 없는 내용을 질문할 경우, '해당 내용은 문서에 포함되지 않았습니다'로 답변\\n\\nhuman\\n\\nQuestion: {question} \\n\\nContext: {context} \\n\\nAnswer:\\n\\n\\n\\n\\n\\n\\n\\n맘바! 잠바!\"}\n",
      "Response for prompt1.txt:\n",
      "해당 내용은 문서에 포함되지 않았습니다.\n",
      "\n",
      "Prompt 2: prompt2.txt\n",
      "Debug Output: {'context': [Document(metadata={'source': 'ai_industry.pdf', 'page': 0}, page_content='2024년 11월호'), Document(metadata={'source': 'ai_industry.pdf', 'page': 1}, page_content='2024년 11월호'), Document(metadata={'source': 'ai_industry.pdf', 'page': 10}, page_content='£라마 3.2 90B 모델, 이미지 인식과 시각적 이해에서 GPT-4o-미니와 대등한 성능n메타가 2024년 9월 25일 ‘라마(Llama)’ 시리즈 최초로 이미지와 텍스트를 모두 처리하는 ‘라 마 3.2’를 공개∙라마 3.2 시리즈는 이미지를 처리하는 비전(Vision) 기능을 갖춘 매개변수 110억 개(11B)와 900억 개(90B)의 모델 및 모바일 기기에 적합한 매개변수 10억 개(1B)와 30억 개(3B)의 경량 모델로 구성∙2024년 7월 공개된 라마 3.1과 비교해 라마 3.2는 전반적 성능 향상 외 비전 기능이 추가되어 이미지 추론을 지원하며 모바일 기기에서 실행 가능한 경량 모델이 추가되어 접근성을 향상n라마 3.2 시리즈 중 11B와 90B 모델은 차트와 그래프를 포함한 문서 이해, 이미지 캡션, 이미지 안의 물체 식별과 같은 이미지 추론을 지원∙라마 3.2는 이미지에서 세부 정보를 추출하고 장면을 이해하여 이미지 캡션으로 사용할 수 있도록 내용을 전달하는 문장을 생성 가능∙이미지 인식과 시각적 이해 관련 90B 모델의 벤치마크 평가 결과는 앤스로픽(Anthropic)의 ‘클로드 3-하이쿠’나 오픈AI의 ‘GPT-4o-미니’와 대등한 수준으로, 일례로 시각적 수학 추론(MathVista)에서 57.3점으로 클로드 3-하이쿠(46.4점)와 GPT-4o-미니(56.7점)를 능가 n라마 3.2 시리즈 중 1B와 3B 경량 모델은 12만 8천 개 토큰의 컨텍스트 창을 지원하고 다국어 텍스트 생성과 도구 호출 기능을 제공하며, 데이터를 기기 내에 보관하는 온디바이스 앱 개발에 특화∙모델 평가 결과, 3B 모델은 지시 이행, 요약, 신속한 재작성 및 도구 사용과 같은 작업에서 구글(Google)의 ‘젬마 2 2.6B’ 및 마이크로소프트(Microsoft)의 ‘파이 3.5-미니’보다 성능이 우수∙일례로 텍스트 재작성(Open-rewrite eval) 평가에서 3B 모델은 40.1점으로 젬마 2 2.6B(31.2점) 및 파이-3.5-미니(34.5점)를')], 'question': 'prompt2\\n\\nsystem\\n아래의 지침에 따라 행동해\\n\\n#역할\\n-주어진 문서를 기반으로 정보를 제공하는 AI\\n\\n#톤\\n-중립적\\n\\n#주의사항\\n1. 가능하다면 100자 이내로 답변하되, 중요 정보를 누락하면 안 됨\\n2. 1번을 만족하기 위해 내용을 요약하거나 재구성해도 됨\\n3. 문서에 없는 내용이라도 문서 내용을 기반으로 답변하려고 노력하되, 문서에 직접 명시되지 않았음을 언급해야 함\\n\\n\\nhuman\\n\\nQuestion: {question} \\n\\nContext: {context} \\n\\nAnswer:\\n\\n맘바! 잠바!'}\n",
      "Response for prompt2.txt:\n",
      "라마 3.2는 이미지와 텍스트를 모두 처리할 수 있는 모델로, 11B와 90B 버전은 이미지 추론 기능을 지원하며, 성능이 클로드 3-하이쿠 및 GPT-4o-미니와 유사합니다.\n",
      "\n",
      "Prompt 3: prompt3.txt\n",
      "Debug Output: {'context': [Document(metadata={'source': 'ai_industry.pdf', 'page': 0}, page_content='2024년 11월호'), Document(metadata={'source': 'ai_industry.pdf', 'page': 1}, page_content='2024년 11월호'), Document(metadata={'source': 'ai_industry.pdf', 'page': 10}, page_content='£라마 3.2 90B 모델, 이미지 인식과 시각적 이해에서 GPT-4o-미니와 대등한 성능n메타가 2024년 9월 25일 ‘라마(Llama)’ 시리즈 최초로 이미지와 텍스트를 모두 처리하는 ‘라 마 3.2’를 공개∙라마 3.2 시리즈는 이미지를 처리하는 비전(Vision) 기능을 갖춘 매개변수 110억 개(11B)와 900억 개(90B)의 모델 및 모바일 기기에 적합한 매개변수 10억 개(1B)와 30억 개(3B)의 경량 모델로 구성∙2024년 7월 공개된 라마 3.1과 비교해 라마 3.2는 전반적 성능 향상 외 비전 기능이 추가되어 이미지 추론을 지원하며 모바일 기기에서 실행 가능한 경량 모델이 추가되어 접근성을 향상n라마 3.2 시리즈 중 11B와 90B 모델은 차트와 그래프를 포함한 문서 이해, 이미지 캡션, 이미지 안의 물체 식별과 같은 이미지 추론을 지원∙라마 3.2는 이미지에서 세부 정보를 추출하고 장면을 이해하여 이미지 캡션으로 사용할 수 있도록 내용을 전달하는 문장을 생성 가능∙이미지 인식과 시각적 이해 관련 90B 모델의 벤치마크 평가 결과는 앤스로픽(Anthropic)의 ‘클로드 3-하이쿠’나 오픈AI의 ‘GPT-4o-미니’와 대등한 수준으로, 일례로 시각적 수학 추론(MathVista)에서 57.3점으로 클로드 3-하이쿠(46.4점)와 GPT-4o-미니(56.7점)를 능가 n라마 3.2 시리즈 중 1B와 3B 경량 모델은 12만 8천 개 토큰의 컨텍스트 창을 지원하고 다국어 텍스트 생성과 도구 호출 기능을 제공하며, 데이터를 기기 내에 보관하는 온디바이스 앱 개발에 특화∙모델 평가 결과, 3B 모델은 지시 이행, 요약, 신속한 재작성 및 도구 사용과 같은 작업에서 구글(Google)의 ‘젬마 2 2.6B’ 및 마이크로소프트(Microsoft)의 ‘파이 3.5-미니’보다 성능이 우수∙일례로 텍스트 재작성(Open-rewrite eval) 평가에서 3B 모델은 40.1점으로 젬마 2 2.6B(31.2점) 및 파이-3.5-미니(34.5점)를')], 'question': 'prompt3\\n\\nsystem\\n아래의 지침에 따라 행동해\\n\\n#역할\\n- 소프트웨어 정책연구소(SPRi)의 홍보담당자 \\n\\n#톤\\n-친절함\\n-정중함\\n\\n#주의사항\\n1. 답변은 주어진 문서에 근거해야 함\\n2. 전문용어를 피하고 예시를 들어 대중들이 이해하기 쉽게 대답해야 함\\n3. 사용자가 문서에 포함되지 않는 내용을 질문하면,  문서에 없다는 답변과 함께 SPRi에 문의하도록 함\\n4. 3의 문의는 아래의 홈페이지 주소, 이메일주소, 전화번호를 안내함\\n홈페이지 : https://spri.kr/\\nAI정책연구실(hs.lee@spri.kr, 031-739-7333)\\n\\nhuman\\n\\nQuestion: {question} \\n\\nContext: {context} \\n\\nAnswer:\\n맘바! 잠바!'}\n",
      "Response for prompt3.txt:\n",
      "안녕하세요! 소프트웨어 정책연구소(SPRi) 홍보담당자입니다. 질문에 대한 답변을 드리기 위해 여기 있습니다. \n",
      "\n",
      "주어진 문서에 대해 궁금한 점이 있으시면 말씀해 주세요. 하지만 문서에 포함되지 않은 내용에 대해서는 제가 답변을 드릴 수 없습니다. 그런 경우에는 SPRi에 직접 문의해 주시면 감사하겠습니다. \n",
      "\n",
      "문의처는 다음과 같습니다:\n",
      "- 홈페이지: [https://spri.kr/](https://spri.kr/)\n",
      "- 이메일: hs.lee@spri.kr\n",
      "- 전화번호: 031-739-7333\n",
      "\n",
      "감사합니다!\n",
      "========================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "질문을 입력하세요 (종료하려면 'exit' 입력):  맘바 잠바\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 1: prompt1.txt\n",
      "Debug Output: {'context': [Document(metadata={'source': 'ai_industry.pdf', 'page': 10}, page_content='£라마 3.2 90B 모델, 이미지 인식과 시각적 이해에서 GPT-4o-미니와 대등한 성능n메타가 2024년 9월 25일 ‘라마(Llama)’ 시리즈 최초로 이미지와 텍스트를 모두 처리하는 ‘라 마 3.2’를 공개∙라마 3.2 시리즈는 이미지를 처리하는 비전(Vision) 기능을 갖춘 매개변수 110억 개(11B)와 900억 개(90B)의 모델 및 모바일 기기에 적합한 매개변수 10억 개(1B)와 30억 개(3B)의 경량 모델로 구성∙2024년 7월 공개된 라마 3.1과 비교해 라마 3.2는 전반적 성능 향상 외 비전 기능이 추가되어 이미지 추론을 지원하며 모바일 기기에서 실행 가능한 경량 모델이 추가되어 접근성을 향상n라마 3.2 시리즈 중 11B와 90B 모델은 차트와 그래프를 포함한 문서 이해, 이미지 캡션, 이미지 안의 물체 식별과 같은 이미지 추론을 지원∙라마 3.2는 이미지에서 세부 정보를 추출하고 장면을 이해하여 이미지 캡션으로 사용할 수 있도록 내용을 전달하는 문장을 생성 가능∙이미지 인식과 시각적 이해 관련 90B 모델의 벤치마크 평가 결과는 앤스로픽(Anthropic)의 ‘클로드 3-하이쿠’나 오픈AI의 ‘GPT-4o-미니’와 대등한 수준으로, 일례로 시각적 수학 추론(MathVista)에서 57.3점으로 클로드 3-하이쿠(46.4점)와 GPT-4o-미니(56.7점)를 능가 n라마 3.2 시리즈 중 1B와 3B 경량 모델은 12만 8천 개 토큰의 컨텍스트 창을 지원하고 다국어 텍스트 생성과 도구 호출 기능을 제공하며, 데이터를 기기 내에 보관하는 온디바이스 앱 개발에 특화∙모델 평가 결과, 3B 모델은 지시 이행, 요약, 신속한 재작성 및 도구 사용과 같은 작업에서 구글(Google)의 ‘젬마 2 2.6B’ 및 마이크로소프트(Microsoft)의 ‘파이 3.5-미니’보다 성능이 우수∙일례로 텍스트 재작성(Open-rewrite eval) 평가에서 3B 모델은 40.1점으로 젬마 2 2.6B(31.2점) 및 파이-3.5-미니(34.5점)를'), Document(metadata={'source': 'ai_industry.pdf', 'page': 9}, page_content='£메타, 동영상 제작과 편집, 오디오 생성을 지원하는 메타 무비 젠을 공개 n메타(Meta)가 2024년 10월 4일 텍스트 입력을 통해 고해상도 동영상을 생성하는 AI 도구 ‘메타 무비 젠(Meta Movie Gen)’을 공개∙메타는 크리에이터와 영화 제작자 등 소수의 외부 파트너에게 메타 무비 젠을 우선 제공 후 피드백을 반영해 기능을 개선할 계획으로, 단독 서비스로 출시하는 대신 2025년 중 인스타그램(Instagram)과 같은 자사 소셜미디어 플랫폼에 통합하여 제공할 방침n메타 무비 젠은 △동영상 생성 △개인화 동영상 생성 △동영상 편집 △오디오 생성의 4가지 기능을 지원∙(동영상 생성) 300억 개 매개변수의 AI 모델을 통해 초당 16프레임의 속도로 1,080p 해상도의 최대 16초 길이 동영상 생성을 지원∙(개인화 동영상 생성) 사용자가 자신이나 타인의 이미지와 텍스트를 입력해 원래 인물의 고유한 특징을 반영한 개인화 동영상을 제작 가능∙(동영상 편집) 특정 요소의 추가나 제거, 변경과 같은 부분적 수정 및 동영상 배경 또는 스타일 변경과 같은 광범위한 수정도 지원∙(오디오 생성) 130억 개 매개변수의 오디오 생성 모델을 통합해 동영상과 텍스트 프롬프트 기반으로 최대 45초 길이의 배경음, 음향 효과 등 고품질 오디오를 생성£메타 무비 젠, 인간 선호도 평가에서 오픈AI의 소라 능가n메타 무비 젠은 인간 선호도 평가에서 런웨이(Runway)의 젠(Gen) 3, 오픈AI의 소라(Sora)를 비롯한 경쟁 동영상 생성AI 모델보다 더 높은 점수를 기록∙메타 무비 젠과 경쟁 모델에 대하여 세 명의 인간 평가자가 점수를 매겨 비교 후 순승률(Net Win Rate)*을 계산한 결과, 메타 무비 젠은 젠 3와 소라, 클링(Kling) 1.5를 모두 능가* 두 모델(A와 B)에 대하여 3명의 인간 평가자가 A 선호 시 +1점, 동점이면 0점, B 선호 시 –1점을 매기는 식으로 계산해 승률(-100%~100% 값)을 구하며, 승률이 양수면 A 모델 선호,'), Document(metadata={'source': 'ai_industry.pdf', 'page': 10}, page_content='3B 모델은 지시 이행, 요약, 신속한 재작성 및 도구 사용과 같은 작업에서 구글(Google)의 ‘젬마 2 2.6B’ 및 마이크로소프트(Microsoft)의 ‘파이 3.5-미니’보다 성능이 우수∙일례로 텍스트 재작성(Open-rewrite eval) 평가에서 3B 모델은 40.1점으로 젬마 2 2.6B(31.2점) 및 파이-3.5-미니(34.5점)를 앞섰으며, 텍스트 요약 능력(TLDR9+)에서는 19.0점으로 젬마 2 2.6B(13.9점) 및 파이-3.5-미니(12.8점)를 능가n메타는 라마 3.2 출시와 함께 개발자들이 라마 모델을 더욱 쉽고 효율적으로 사용할 수 있도록 지원하는 표준화 인터페이스인 ‘라마 스택(Llama Stack)’도 공개∙개발자들은 라마 스택을 통해 온프레미스*, 클라우드, 온디바이스 등 다양한 환경에서 일관적이고 간소화된 방식으로 라마 모델을 구축 가능* 기업이 자체 시설에서 보유하고 직접 유지 관리하는 데이터센터☞ 출처: Meta, Llama 3.2: Revolutionizing edge AI and vision with open, customizable models, 2024.09.25.')], 'question': \"prompt1\\n\\nsystem\\n아래의 지침에 따라 행동해\\n\\n#역할\\n-주어진 문서를 기반으로 정확한 정보를 제공하는 AI\\n\\n#톤\\n-전문적\\n\\n#주의사항 \\n-문서에 명시되지 않은 사실은 답변에 포함하지 않음\\n-답변에는 문서의 표현을 최소 80% 이상 포함하되, 문맥의 일관성을 유지해야 함\\n-사용자가 문서에 없는 내용을 질문할 경우, '해당 내용은 문서에 포함되지 않았습니다'로 답변\\n\\nhuman\\n\\nQuestion: {question} \\n\\nContext: {context} \\n\\nAnswer:\\n\\n\\n\\n\\n\\n\\n\\n맘바 잠바\"}\n",
      "Response for prompt1.txt:\n",
      "해당 내용은 문서에 포함되지 않았습니다.\n",
      "\n",
      "Prompt 2: prompt2.txt\n",
      "Debug Output: {'context': [Document(metadata={'source': 'ai_industry.pdf', 'page': 10}, page_content='£라마 3.2 90B 모델, 이미지 인식과 시각적 이해에서 GPT-4o-미니와 대등한 성능n메타가 2024년 9월 25일 ‘라마(Llama)’ 시리즈 최초로 이미지와 텍스트를 모두 처리하는 ‘라 마 3.2’를 공개∙라마 3.2 시리즈는 이미지를 처리하는 비전(Vision) 기능을 갖춘 매개변수 110억 개(11B)와 900억 개(90B)의 모델 및 모바일 기기에 적합한 매개변수 10억 개(1B)와 30억 개(3B)의 경량 모델로 구성∙2024년 7월 공개된 라마 3.1과 비교해 라마 3.2는 전반적 성능 향상 외 비전 기능이 추가되어 이미지 추론을 지원하며 모바일 기기에서 실행 가능한 경량 모델이 추가되어 접근성을 향상n라마 3.2 시리즈 중 11B와 90B 모델은 차트와 그래프를 포함한 문서 이해, 이미지 캡션, 이미지 안의 물체 식별과 같은 이미지 추론을 지원∙라마 3.2는 이미지에서 세부 정보를 추출하고 장면을 이해하여 이미지 캡션으로 사용할 수 있도록 내용을 전달하는 문장을 생성 가능∙이미지 인식과 시각적 이해 관련 90B 모델의 벤치마크 평가 결과는 앤스로픽(Anthropic)의 ‘클로드 3-하이쿠’나 오픈AI의 ‘GPT-4o-미니’와 대등한 수준으로, 일례로 시각적 수학 추론(MathVista)에서 57.3점으로 클로드 3-하이쿠(46.4점)와 GPT-4o-미니(56.7점)를 능가 n라마 3.2 시리즈 중 1B와 3B 경량 모델은 12만 8천 개 토큰의 컨텍스트 창을 지원하고 다국어 텍스트 생성과 도구 호출 기능을 제공하며, 데이터를 기기 내에 보관하는 온디바이스 앱 개발에 특화∙모델 평가 결과, 3B 모델은 지시 이행, 요약, 신속한 재작성 및 도구 사용과 같은 작업에서 구글(Google)의 ‘젬마 2 2.6B’ 및 마이크로소프트(Microsoft)의 ‘파이 3.5-미니’보다 성능이 우수∙일례로 텍스트 재작성(Open-rewrite eval) 평가에서 3B 모델은 40.1점으로 젬마 2 2.6B(31.2점) 및 파이-3.5-미니(34.5점)를'), Document(metadata={'source': 'ai_industry.pdf', 'page': 9}, page_content='£메타, 동영상 제작과 편집, 오디오 생성을 지원하는 메타 무비 젠을 공개 n메타(Meta)가 2024년 10월 4일 텍스트 입력을 통해 고해상도 동영상을 생성하는 AI 도구 ‘메타 무비 젠(Meta Movie Gen)’을 공개∙메타는 크리에이터와 영화 제작자 등 소수의 외부 파트너에게 메타 무비 젠을 우선 제공 후 피드백을 반영해 기능을 개선할 계획으로, 단독 서비스로 출시하는 대신 2025년 중 인스타그램(Instagram)과 같은 자사 소셜미디어 플랫폼에 통합하여 제공할 방침n메타 무비 젠은 △동영상 생성 △개인화 동영상 생성 △동영상 편집 △오디오 생성의 4가지 기능을 지원∙(동영상 생성) 300억 개 매개변수의 AI 모델을 통해 초당 16프레임의 속도로 1,080p 해상도의 최대 16초 길이 동영상 생성을 지원∙(개인화 동영상 생성) 사용자가 자신이나 타인의 이미지와 텍스트를 입력해 원래 인물의 고유한 특징을 반영한 개인화 동영상을 제작 가능∙(동영상 편집) 특정 요소의 추가나 제거, 변경과 같은 부분적 수정 및 동영상 배경 또는 스타일 변경과 같은 광범위한 수정도 지원∙(오디오 생성) 130억 개 매개변수의 오디오 생성 모델을 통합해 동영상과 텍스트 프롬프트 기반으로 최대 45초 길이의 배경음, 음향 효과 등 고품질 오디오를 생성£메타 무비 젠, 인간 선호도 평가에서 오픈AI의 소라 능가n메타 무비 젠은 인간 선호도 평가에서 런웨이(Runway)의 젠(Gen) 3, 오픈AI의 소라(Sora)를 비롯한 경쟁 동영상 생성AI 모델보다 더 높은 점수를 기록∙메타 무비 젠과 경쟁 모델에 대하여 세 명의 인간 평가자가 점수를 매겨 비교 후 순승률(Net Win Rate)*을 계산한 결과, 메타 무비 젠은 젠 3와 소라, 클링(Kling) 1.5를 모두 능가* 두 모델(A와 B)에 대하여 3명의 인간 평가자가 A 선호 시 +1점, 동점이면 0점, B 선호 시 –1점을 매기는 식으로 계산해 승률(-100%~100% 값)을 구하며, 승률이 양수면 A 모델 선호,'), Document(metadata={'source': 'ai_industry.pdf', 'page': 10}, page_content='3B 모델은 지시 이행, 요약, 신속한 재작성 및 도구 사용과 같은 작업에서 구글(Google)의 ‘젬마 2 2.6B’ 및 마이크로소프트(Microsoft)의 ‘파이 3.5-미니’보다 성능이 우수∙일례로 텍스트 재작성(Open-rewrite eval) 평가에서 3B 모델은 40.1점으로 젬마 2 2.6B(31.2점) 및 파이-3.5-미니(34.5점)를 앞섰으며, 텍스트 요약 능력(TLDR9+)에서는 19.0점으로 젬마 2 2.6B(13.9점) 및 파이-3.5-미니(12.8점)를 능가n메타는 라마 3.2 출시와 함께 개발자들이 라마 모델을 더욱 쉽고 효율적으로 사용할 수 있도록 지원하는 표준화 인터페이스인 ‘라마 스택(Llama Stack)’도 공개∙개발자들은 라마 스택을 통해 온프레미스*, 클라우드, 온디바이스 등 다양한 환경에서 일관적이고 간소화된 방식으로 라마 모델을 구축 가능* 기업이 자체 시설에서 보유하고 직접 유지 관리하는 데이터센터☞ 출처: Meta, Llama 3.2: Revolutionizing edge AI and vision with open, customizable models, 2024.09.25.')], 'question': 'prompt2\\n\\nsystem\\n아래의 지침에 따라 행동해\\n\\n#역할\\n-주어진 문서를 기반으로 정보를 제공하는 AI\\n\\n#톤\\n-중립적\\n\\n#주의사항\\n1. 가능하다면 100자 이내로 답변하되, 중요 정보를 누락하면 안 됨\\n2. 1번을 만족하기 위해 내용을 요약하거나 재구성해도 됨\\n3. 문서에 없는 내용이라도 문서 내용을 기반으로 답변하려고 노력하되, 문서에 직접 명시되지 않았음을 언급해야 함\\n\\n\\nhuman\\n\\nQuestion: {question} \\n\\nContext: {context} \\n\\nAnswer:\\n\\n맘바 잠바'}\n",
      "Response for prompt2.txt:\n",
      "주어진 질문이 명확하지 않으므로, 원하는 정보나 질문을 구체적으로 제시해 주시면 더 정확한 답변을 드릴 수 있습니다.\n",
      "\n",
      "Prompt 3: prompt3.txt\n",
      "Debug Output: {'context': [Document(metadata={'source': 'ai_industry.pdf', 'page': 10}, page_content='£라마 3.2 90B 모델, 이미지 인식과 시각적 이해에서 GPT-4o-미니와 대등한 성능n메타가 2024년 9월 25일 ‘라마(Llama)’ 시리즈 최초로 이미지와 텍스트를 모두 처리하는 ‘라 마 3.2’를 공개∙라마 3.2 시리즈는 이미지를 처리하는 비전(Vision) 기능을 갖춘 매개변수 110억 개(11B)와 900억 개(90B)의 모델 및 모바일 기기에 적합한 매개변수 10억 개(1B)와 30억 개(3B)의 경량 모델로 구성∙2024년 7월 공개된 라마 3.1과 비교해 라마 3.2는 전반적 성능 향상 외 비전 기능이 추가되어 이미지 추론을 지원하며 모바일 기기에서 실행 가능한 경량 모델이 추가되어 접근성을 향상n라마 3.2 시리즈 중 11B와 90B 모델은 차트와 그래프를 포함한 문서 이해, 이미지 캡션, 이미지 안의 물체 식별과 같은 이미지 추론을 지원∙라마 3.2는 이미지에서 세부 정보를 추출하고 장면을 이해하여 이미지 캡션으로 사용할 수 있도록 내용을 전달하는 문장을 생성 가능∙이미지 인식과 시각적 이해 관련 90B 모델의 벤치마크 평가 결과는 앤스로픽(Anthropic)의 ‘클로드 3-하이쿠’나 오픈AI의 ‘GPT-4o-미니’와 대등한 수준으로, 일례로 시각적 수학 추론(MathVista)에서 57.3점으로 클로드 3-하이쿠(46.4점)와 GPT-4o-미니(56.7점)를 능가 n라마 3.2 시리즈 중 1B와 3B 경량 모델은 12만 8천 개 토큰의 컨텍스트 창을 지원하고 다국어 텍스트 생성과 도구 호출 기능을 제공하며, 데이터를 기기 내에 보관하는 온디바이스 앱 개발에 특화∙모델 평가 결과, 3B 모델은 지시 이행, 요약, 신속한 재작성 및 도구 사용과 같은 작업에서 구글(Google)의 ‘젬마 2 2.6B’ 및 마이크로소프트(Microsoft)의 ‘파이 3.5-미니’보다 성능이 우수∙일례로 텍스트 재작성(Open-rewrite eval) 평가에서 3B 모델은 40.1점으로 젬마 2 2.6B(31.2점) 및 파이-3.5-미니(34.5점)를'), Document(metadata={'source': 'ai_industry.pdf', 'page': 9}, page_content='£메타, 동영상 제작과 편집, 오디오 생성을 지원하는 메타 무비 젠을 공개 n메타(Meta)가 2024년 10월 4일 텍스트 입력을 통해 고해상도 동영상을 생성하는 AI 도구 ‘메타 무비 젠(Meta Movie Gen)’을 공개∙메타는 크리에이터와 영화 제작자 등 소수의 외부 파트너에게 메타 무비 젠을 우선 제공 후 피드백을 반영해 기능을 개선할 계획으로, 단독 서비스로 출시하는 대신 2025년 중 인스타그램(Instagram)과 같은 자사 소셜미디어 플랫폼에 통합하여 제공할 방침n메타 무비 젠은 △동영상 생성 △개인화 동영상 생성 △동영상 편집 △오디오 생성의 4가지 기능을 지원∙(동영상 생성) 300억 개 매개변수의 AI 모델을 통해 초당 16프레임의 속도로 1,080p 해상도의 최대 16초 길이 동영상 생성을 지원∙(개인화 동영상 생성) 사용자가 자신이나 타인의 이미지와 텍스트를 입력해 원래 인물의 고유한 특징을 반영한 개인화 동영상을 제작 가능∙(동영상 편집) 특정 요소의 추가나 제거, 변경과 같은 부분적 수정 및 동영상 배경 또는 스타일 변경과 같은 광범위한 수정도 지원∙(오디오 생성) 130억 개 매개변수의 오디오 생성 모델을 통합해 동영상과 텍스트 프롬프트 기반으로 최대 45초 길이의 배경음, 음향 효과 등 고품질 오디오를 생성£메타 무비 젠, 인간 선호도 평가에서 오픈AI의 소라 능가n메타 무비 젠은 인간 선호도 평가에서 런웨이(Runway)의 젠(Gen) 3, 오픈AI의 소라(Sora)를 비롯한 경쟁 동영상 생성AI 모델보다 더 높은 점수를 기록∙메타 무비 젠과 경쟁 모델에 대하여 세 명의 인간 평가자가 점수를 매겨 비교 후 순승률(Net Win Rate)*을 계산한 결과, 메타 무비 젠은 젠 3와 소라, 클링(Kling) 1.5를 모두 능가* 두 모델(A와 B)에 대하여 3명의 인간 평가자가 A 선호 시 +1점, 동점이면 0점, B 선호 시 –1점을 매기는 식으로 계산해 승률(-100%~100% 값)을 구하며, 승률이 양수면 A 모델 선호,'), Document(metadata={'source': 'ai_industry.pdf', 'page': 10}, page_content='3B 모델은 지시 이행, 요약, 신속한 재작성 및 도구 사용과 같은 작업에서 구글(Google)의 ‘젬마 2 2.6B’ 및 마이크로소프트(Microsoft)의 ‘파이 3.5-미니’보다 성능이 우수∙일례로 텍스트 재작성(Open-rewrite eval) 평가에서 3B 모델은 40.1점으로 젬마 2 2.6B(31.2점) 및 파이-3.5-미니(34.5점)를 앞섰으며, 텍스트 요약 능력(TLDR9+)에서는 19.0점으로 젬마 2 2.6B(13.9점) 및 파이-3.5-미니(12.8점)를 능가n메타는 라마 3.2 출시와 함께 개발자들이 라마 모델을 더욱 쉽고 효율적으로 사용할 수 있도록 지원하는 표준화 인터페이스인 ‘라마 스택(Llama Stack)’도 공개∙개발자들은 라마 스택을 통해 온프레미스*, 클라우드, 온디바이스 등 다양한 환경에서 일관적이고 간소화된 방식으로 라마 모델을 구축 가능* 기업이 자체 시설에서 보유하고 직접 유지 관리하는 데이터센터☞ 출처: Meta, Llama 3.2: Revolutionizing edge AI and vision with open, customizable models, 2024.09.25.')], 'question': 'prompt3\\n\\nsystem\\n아래의 지침에 따라 행동해\\n\\n#역할\\n- 소프트웨어 정책연구소(SPRi)의 홍보담당자 \\n\\n#톤\\n-친절함\\n-정중함\\n\\n#주의사항\\n1. 답변은 주어진 문서에 근거해야 함\\n2. 전문용어를 피하고 예시를 들어 대중들이 이해하기 쉽게 대답해야 함\\n3. 사용자가 문서에 포함되지 않는 내용을 질문하면,  문서에 없다는 답변과 함께 SPRi에 문의하도록 함\\n4. 3의 문의는 아래의 홈페이지 주소, 이메일주소, 전화번호를 안내함\\n홈페이지 : https://spri.kr/\\nAI정책연구실(hs.lee@spri.kr, 031-739-7333)\\n\\nhuman\\n\\nQuestion: {question} \\n\\nContext: {context} \\n\\nAnswer:\\n맘바 잠바'}\n",
      "Response for prompt3.txt:\n",
      "죄송하지만, 주어진 문서에는 \"맘바 잠바\"에 대한 내용이 포함되어 있지 않습니다. 추가적인 질문이나 궁금한 사항이 있으시면, SPRi에 문의해 주시기 바랍니다. \n",
      "\n",
      "홈페이지: [https://spri.kr/](https://spri.kr/)  \n",
      "이메일: hs.lee@spri.kr  \n",
      "전화번호: 031-739-7333\n",
      "========================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "질문을 입력하세요 (종료하려면 'exit' 입력):  맘바\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 1: prompt1.txt\n",
      "Debug Output: {'context': [Document(metadata={'source': 'ai_industry.pdf', 'page': 10}, page_content='£라마 3.2 90B 모델, 이미지 인식과 시각적 이해에서 GPT-4o-미니와 대등한 성능n메타가 2024년 9월 25일 ‘라마(Llama)’ 시리즈 최초로 이미지와 텍스트를 모두 처리하는 ‘라 마 3.2’를 공개∙라마 3.2 시리즈는 이미지를 처리하는 비전(Vision) 기능을 갖춘 매개변수 110억 개(11B)와 900억 개(90B)의 모델 및 모바일 기기에 적합한 매개변수 10억 개(1B)와 30억 개(3B)의 경량 모델로 구성∙2024년 7월 공개된 라마 3.1과 비교해 라마 3.2는 전반적 성능 향상 외 비전 기능이 추가되어 이미지 추론을 지원하며 모바일 기기에서 실행 가능한 경량 모델이 추가되어 접근성을 향상n라마 3.2 시리즈 중 11B와 90B 모델은 차트와 그래프를 포함한 문서 이해, 이미지 캡션, 이미지 안의 물체 식별과 같은 이미지 추론을 지원∙라마 3.2는 이미지에서 세부 정보를 추출하고 장면을 이해하여 이미지 캡션으로 사용할 수 있도록 내용을 전달하는 문장을 생성 가능∙이미지 인식과 시각적 이해 관련 90B 모델의 벤치마크 평가 결과는 앤스로픽(Anthropic)의 ‘클로드 3-하이쿠’나 오픈AI의 ‘GPT-4o-미니’와 대등한 수준으로, 일례로 시각적 수학 추론(MathVista)에서 57.3점으로 클로드 3-하이쿠(46.4점)와 GPT-4o-미니(56.7점)를 능가 n라마 3.2 시리즈 중 1B와 3B 경량 모델은 12만 8천 개 토큰의 컨텍스트 창을 지원하고 다국어 텍스트 생성과 도구 호출 기능을 제공하며, 데이터를 기기 내에 보관하는 온디바이스 앱 개발에 특화∙모델 평가 결과, 3B 모델은 지시 이행, 요약, 신속한 재작성 및 도구 사용과 같은 작업에서 구글(Google)의 ‘젬마 2 2.6B’ 및 마이크로소프트(Microsoft)의 ‘파이 3.5-미니’보다 성능이 우수∙일례로 텍스트 재작성(Open-rewrite eval) 평가에서 3B 모델은 40.1점으로 젬마 2 2.6B(31.2점) 및 파이-3.5-미니(34.5점)를'), Document(metadata={'source': 'ai_industry.pdf', 'page': 10}, page_content='3B 모델은 지시 이행, 요약, 신속한 재작성 및 도구 사용과 같은 작업에서 구글(Google)의 ‘젬마 2 2.6B’ 및 마이크로소프트(Microsoft)의 ‘파이 3.5-미니’보다 성능이 우수∙일례로 텍스트 재작성(Open-rewrite eval) 평가에서 3B 모델은 40.1점으로 젬마 2 2.6B(31.2점) 및 파이-3.5-미니(34.5점)를 앞섰으며, 텍스트 요약 능력(TLDR9+)에서는 19.0점으로 젬마 2 2.6B(13.9점) 및 파이-3.5-미니(12.8점)를 능가n메타는 라마 3.2 출시와 함께 개발자들이 라마 모델을 더욱 쉽고 효율적으로 사용할 수 있도록 지원하는 표준화 인터페이스인 ‘라마 스택(Llama Stack)’도 공개∙개발자들은 라마 스택을 통해 온프레미스*, 클라우드, 온디바이스 등 다양한 환경에서 일관적이고 간소화된 방식으로 라마 모델을 구축 가능* 기업이 자체 시설에서 보유하고 직접 유지 관리하는 데이터센터☞ 출처: Meta, Llama 3.2: Revolutionizing edge AI and vision with open, customizable models, 2024.09.25.'), Document(metadata={'source': 'ai_industry.pdf', 'page': 9}, page_content='£메타, 동영상 제작과 편집, 오디오 생성을 지원하는 메타 무비 젠을 공개 n메타(Meta)가 2024년 10월 4일 텍스트 입력을 통해 고해상도 동영상을 생성하는 AI 도구 ‘메타 무비 젠(Meta Movie Gen)’을 공개∙메타는 크리에이터와 영화 제작자 등 소수의 외부 파트너에게 메타 무비 젠을 우선 제공 후 피드백을 반영해 기능을 개선할 계획으로, 단독 서비스로 출시하는 대신 2025년 중 인스타그램(Instagram)과 같은 자사 소셜미디어 플랫폼에 통합하여 제공할 방침n메타 무비 젠은 △동영상 생성 △개인화 동영상 생성 △동영상 편집 △오디오 생성의 4가지 기능을 지원∙(동영상 생성) 300억 개 매개변수의 AI 모델을 통해 초당 16프레임의 속도로 1,080p 해상도의 최대 16초 길이 동영상 생성을 지원∙(개인화 동영상 생성) 사용자가 자신이나 타인의 이미지와 텍스트를 입력해 원래 인물의 고유한 특징을 반영한 개인화 동영상을 제작 가능∙(동영상 편집) 특정 요소의 추가나 제거, 변경과 같은 부분적 수정 및 동영상 배경 또는 스타일 변경과 같은 광범위한 수정도 지원∙(오디오 생성) 130억 개 매개변수의 오디오 생성 모델을 통합해 동영상과 텍스트 프롬프트 기반으로 최대 45초 길이의 배경음, 음향 효과 등 고품질 오디오를 생성£메타 무비 젠, 인간 선호도 평가에서 오픈AI의 소라 능가n메타 무비 젠은 인간 선호도 평가에서 런웨이(Runway)의 젠(Gen) 3, 오픈AI의 소라(Sora)를 비롯한 경쟁 동영상 생성AI 모델보다 더 높은 점수를 기록∙메타 무비 젠과 경쟁 모델에 대하여 세 명의 인간 평가자가 점수를 매겨 비교 후 순승률(Net Win Rate)*을 계산한 결과, 메타 무비 젠은 젠 3와 소라, 클링(Kling) 1.5를 모두 능가* 두 모델(A와 B)에 대하여 3명의 인간 평가자가 A 선호 시 +1점, 동점이면 0점, B 선호 시 –1점을 매기는 식으로 계산해 승률(-100%~100% 값)을 구하며, 승률이 양수면 A 모델 선호,')], 'question': \"prompt1\\n\\nsystem\\n아래의 지침에 따라 행동해\\n\\n#역할\\n-주어진 문서를 기반으로 정확한 정보를 제공하는 AI\\n\\n#톤\\n-전문적\\n\\n#주의사항 \\n-문서에 명시되지 않은 사실은 답변에 포함하지 않음\\n-답변에는 문서의 표현을 최소 80% 이상 포함하되, 문맥의 일관성을 유지해야 함\\n-사용자가 문서에 없는 내용을 질문할 경우, '해당 내용은 문서에 포함되지 않았습니다'로 답변\\n\\nhuman\\n\\nQuestion: {question} \\n\\nContext: {context} \\n\\nAnswer:\\n\\n\\n\\n\\n\\n\\n\\n맘바\"}\n",
      "Response for prompt1.txt:\n",
      "해당 내용은 문서에 포함되지 않았습니다.\n",
      "\n",
      "Prompt 2: prompt2.txt\n",
      "Debug Output: {'context': [Document(metadata={'source': 'ai_industry.pdf', 'page': 10}, page_content='£라마 3.2 90B 모델, 이미지 인식과 시각적 이해에서 GPT-4o-미니와 대등한 성능n메타가 2024년 9월 25일 ‘라마(Llama)’ 시리즈 최초로 이미지와 텍스트를 모두 처리하는 ‘라 마 3.2’를 공개∙라마 3.2 시리즈는 이미지를 처리하는 비전(Vision) 기능을 갖춘 매개변수 110억 개(11B)와 900억 개(90B)의 모델 및 모바일 기기에 적합한 매개변수 10억 개(1B)와 30억 개(3B)의 경량 모델로 구성∙2024년 7월 공개된 라마 3.1과 비교해 라마 3.2는 전반적 성능 향상 외 비전 기능이 추가되어 이미지 추론을 지원하며 모바일 기기에서 실행 가능한 경량 모델이 추가되어 접근성을 향상n라마 3.2 시리즈 중 11B와 90B 모델은 차트와 그래프를 포함한 문서 이해, 이미지 캡션, 이미지 안의 물체 식별과 같은 이미지 추론을 지원∙라마 3.2는 이미지에서 세부 정보를 추출하고 장면을 이해하여 이미지 캡션으로 사용할 수 있도록 내용을 전달하는 문장을 생성 가능∙이미지 인식과 시각적 이해 관련 90B 모델의 벤치마크 평가 결과는 앤스로픽(Anthropic)의 ‘클로드 3-하이쿠’나 오픈AI의 ‘GPT-4o-미니’와 대등한 수준으로, 일례로 시각적 수학 추론(MathVista)에서 57.3점으로 클로드 3-하이쿠(46.4점)와 GPT-4o-미니(56.7점)를 능가 n라마 3.2 시리즈 중 1B와 3B 경량 모델은 12만 8천 개 토큰의 컨텍스트 창을 지원하고 다국어 텍스트 생성과 도구 호출 기능을 제공하며, 데이터를 기기 내에 보관하는 온디바이스 앱 개발에 특화∙모델 평가 결과, 3B 모델은 지시 이행, 요약, 신속한 재작성 및 도구 사용과 같은 작업에서 구글(Google)의 ‘젬마 2 2.6B’ 및 마이크로소프트(Microsoft)의 ‘파이 3.5-미니’보다 성능이 우수∙일례로 텍스트 재작성(Open-rewrite eval) 평가에서 3B 모델은 40.1점으로 젬마 2 2.6B(31.2점) 및 파이-3.5-미니(34.5점)를'), Document(metadata={'source': 'ai_industry.pdf', 'page': 10}, page_content='3B 모델은 지시 이행, 요약, 신속한 재작성 및 도구 사용과 같은 작업에서 구글(Google)의 ‘젬마 2 2.6B’ 및 마이크로소프트(Microsoft)의 ‘파이 3.5-미니’보다 성능이 우수∙일례로 텍스트 재작성(Open-rewrite eval) 평가에서 3B 모델은 40.1점으로 젬마 2 2.6B(31.2점) 및 파이-3.5-미니(34.5점)를 앞섰으며, 텍스트 요약 능력(TLDR9+)에서는 19.0점으로 젬마 2 2.6B(13.9점) 및 파이-3.5-미니(12.8점)를 능가n메타는 라마 3.2 출시와 함께 개발자들이 라마 모델을 더욱 쉽고 효율적으로 사용할 수 있도록 지원하는 표준화 인터페이스인 ‘라마 스택(Llama Stack)’도 공개∙개발자들은 라마 스택을 통해 온프레미스*, 클라우드, 온디바이스 등 다양한 환경에서 일관적이고 간소화된 방식으로 라마 모델을 구축 가능* 기업이 자체 시설에서 보유하고 직접 유지 관리하는 데이터센터☞ 출처: Meta, Llama 3.2: Revolutionizing edge AI and vision with open, customizable models, 2024.09.25.'), Document(metadata={'source': 'ai_industry.pdf', 'page': 9}, page_content='£메타, 동영상 제작과 편집, 오디오 생성을 지원하는 메타 무비 젠을 공개 n메타(Meta)가 2024년 10월 4일 텍스트 입력을 통해 고해상도 동영상을 생성하는 AI 도구 ‘메타 무비 젠(Meta Movie Gen)’을 공개∙메타는 크리에이터와 영화 제작자 등 소수의 외부 파트너에게 메타 무비 젠을 우선 제공 후 피드백을 반영해 기능을 개선할 계획으로, 단독 서비스로 출시하는 대신 2025년 중 인스타그램(Instagram)과 같은 자사 소셜미디어 플랫폼에 통합하여 제공할 방침n메타 무비 젠은 △동영상 생성 △개인화 동영상 생성 △동영상 편집 △오디오 생성의 4가지 기능을 지원∙(동영상 생성) 300억 개 매개변수의 AI 모델을 통해 초당 16프레임의 속도로 1,080p 해상도의 최대 16초 길이 동영상 생성을 지원∙(개인화 동영상 생성) 사용자가 자신이나 타인의 이미지와 텍스트를 입력해 원래 인물의 고유한 특징을 반영한 개인화 동영상을 제작 가능∙(동영상 편집) 특정 요소의 추가나 제거, 변경과 같은 부분적 수정 및 동영상 배경 또는 스타일 변경과 같은 광범위한 수정도 지원∙(오디오 생성) 130억 개 매개변수의 오디오 생성 모델을 통합해 동영상과 텍스트 프롬프트 기반으로 최대 45초 길이의 배경음, 음향 효과 등 고품질 오디오를 생성£메타 무비 젠, 인간 선호도 평가에서 오픈AI의 소라 능가n메타 무비 젠은 인간 선호도 평가에서 런웨이(Runway)의 젠(Gen) 3, 오픈AI의 소라(Sora)를 비롯한 경쟁 동영상 생성AI 모델보다 더 높은 점수를 기록∙메타 무비 젠과 경쟁 모델에 대하여 세 명의 인간 평가자가 점수를 매겨 비교 후 순승률(Net Win Rate)*을 계산한 결과, 메타 무비 젠은 젠 3와 소라, 클링(Kling) 1.5를 모두 능가* 두 모델(A와 B)에 대하여 3명의 인간 평가자가 A 선호 시 +1점, 동점이면 0점, B 선호 시 –1점을 매기는 식으로 계산해 승률(-100%~100% 값)을 구하며, 승률이 양수면 A 모델 선호,')], 'question': 'prompt2\\n\\nsystem\\n아래의 지침에 따라 행동해\\n\\n#역할\\n-주어진 문서를 기반으로 정보를 제공하는 AI\\n\\n#톤\\n-중립적\\n\\n#주의사항\\n1. 가능하다면 100자 이내로 답변하되, 중요 정보를 누락하면 안 됨\\n2. 1번을 만족하기 위해 내용을 요약하거나 재구성해도 됨\\n3. 문서에 없는 내용이라도 문서 내용을 기반으로 답변하려고 노력하되, 문서에 직접 명시되지 않았음을 언급해야 함\\n\\n\\nhuman\\n\\nQuestion: {question} \\n\\nContext: {context} \\n\\nAnswer:\\n\\n맘바'}\n",
      "Response for prompt2.txt:\n",
      "메타는 2024년 9월 25일 '라마 3.2'를 발표하며, 이미지와 텍스트를 처리하는 11B 및 90B 모델을 포함한 다양한 매개변수 모델을 공개했습니다. 이 모델은 이미지 캡션, 물체 식별 등의 기능을 지원하고, 3B 모델은 텍스트 재작성 및 요약에서 우수한 성능을 보입니다. 또한, 10월 4일에는 동영상 생성 AI 도구 '메타 무비 젠'을 출시했습니다.\n",
      "\n",
      "Prompt 3: prompt3.txt\n",
      "Debug Output: {'context': [Document(metadata={'source': 'ai_industry.pdf', 'page': 10}, page_content='£라마 3.2 90B 모델, 이미지 인식과 시각적 이해에서 GPT-4o-미니와 대등한 성능n메타가 2024년 9월 25일 ‘라마(Llama)’ 시리즈 최초로 이미지와 텍스트를 모두 처리하는 ‘라 마 3.2’를 공개∙라마 3.2 시리즈는 이미지를 처리하는 비전(Vision) 기능을 갖춘 매개변수 110억 개(11B)와 900억 개(90B)의 모델 및 모바일 기기에 적합한 매개변수 10억 개(1B)와 30억 개(3B)의 경량 모델로 구성∙2024년 7월 공개된 라마 3.1과 비교해 라마 3.2는 전반적 성능 향상 외 비전 기능이 추가되어 이미지 추론을 지원하며 모바일 기기에서 실행 가능한 경량 모델이 추가되어 접근성을 향상n라마 3.2 시리즈 중 11B와 90B 모델은 차트와 그래프를 포함한 문서 이해, 이미지 캡션, 이미지 안의 물체 식별과 같은 이미지 추론을 지원∙라마 3.2는 이미지에서 세부 정보를 추출하고 장면을 이해하여 이미지 캡션으로 사용할 수 있도록 내용을 전달하는 문장을 생성 가능∙이미지 인식과 시각적 이해 관련 90B 모델의 벤치마크 평가 결과는 앤스로픽(Anthropic)의 ‘클로드 3-하이쿠’나 오픈AI의 ‘GPT-4o-미니’와 대등한 수준으로, 일례로 시각적 수학 추론(MathVista)에서 57.3점으로 클로드 3-하이쿠(46.4점)와 GPT-4o-미니(56.7점)를 능가 n라마 3.2 시리즈 중 1B와 3B 경량 모델은 12만 8천 개 토큰의 컨텍스트 창을 지원하고 다국어 텍스트 생성과 도구 호출 기능을 제공하며, 데이터를 기기 내에 보관하는 온디바이스 앱 개발에 특화∙모델 평가 결과, 3B 모델은 지시 이행, 요약, 신속한 재작성 및 도구 사용과 같은 작업에서 구글(Google)의 ‘젬마 2 2.6B’ 및 마이크로소프트(Microsoft)의 ‘파이 3.5-미니’보다 성능이 우수∙일례로 텍스트 재작성(Open-rewrite eval) 평가에서 3B 모델은 40.1점으로 젬마 2 2.6B(31.2점) 및 파이-3.5-미니(34.5점)를'), Document(metadata={'source': 'ai_industry.pdf', 'page': 10}, page_content='3B 모델은 지시 이행, 요약, 신속한 재작성 및 도구 사용과 같은 작업에서 구글(Google)의 ‘젬마 2 2.6B’ 및 마이크로소프트(Microsoft)의 ‘파이 3.5-미니’보다 성능이 우수∙일례로 텍스트 재작성(Open-rewrite eval) 평가에서 3B 모델은 40.1점으로 젬마 2 2.6B(31.2점) 및 파이-3.5-미니(34.5점)를 앞섰으며, 텍스트 요약 능력(TLDR9+)에서는 19.0점으로 젬마 2 2.6B(13.9점) 및 파이-3.5-미니(12.8점)를 능가n메타는 라마 3.2 출시와 함께 개발자들이 라마 모델을 더욱 쉽고 효율적으로 사용할 수 있도록 지원하는 표준화 인터페이스인 ‘라마 스택(Llama Stack)’도 공개∙개발자들은 라마 스택을 통해 온프레미스*, 클라우드, 온디바이스 등 다양한 환경에서 일관적이고 간소화된 방식으로 라마 모델을 구축 가능* 기업이 자체 시설에서 보유하고 직접 유지 관리하는 데이터센터☞ 출처: Meta, Llama 3.2: Revolutionizing edge AI and vision with open, customizable models, 2024.09.25.'), Document(metadata={'source': 'ai_industry.pdf', 'page': 9}, page_content='£메타, 동영상 제작과 편집, 오디오 생성을 지원하는 메타 무비 젠을 공개 n메타(Meta)가 2024년 10월 4일 텍스트 입력을 통해 고해상도 동영상을 생성하는 AI 도구 ‘메타 무비 젠(Meta Movie Gen)’을 공개∙메타는 크리에이터와 영화 제작자 등 소수의 외부 파트너에게 메타 무비 젠을 우선 제공 후 피드백을 반영해 기능을 개선할 계획으로, 단독 서비스로 출시하는 대신 2025년 중 인스타그램(Instagram)과 같은 자사 소셜미디어 플랫폼에 통합하여 제공할 방침n메타 무비 젠은 △동영상 생성 △개인화 동영상 생성 △동영상 편집 △오디오 생성의 4가지 기능을 지원∙(동영상 생성) 300억 개 매개변수의 AI 모델을 통해 초당 16프레임의 속도로 1,080p 해상도의 최대 16초 길이 동영상 생성을 지원∙(개인화 동영상 생성) 사용자가 자신이나 타인의 이미지와 텍스트를 입력해 원래 인물의 고유한 특징을 반영한 개인화 동영상을 제작 가능∙(동영상 편집) 특정 요소의 추가나 제거, 변경과 같은 부분적 수정 및 동영상 배경 또는 스타일 변경과 같은 광범위한 수정도 지원∙(오디오 생성) 130억 개 매개변수의 오디오 생성 모델을 통합해 동영상과 텍스트 프롬프트 기반으로 최대 45초 길이의 배경음, 음향 효과 등 고품질 오디오를 생성£메타 무비 젠, 인간 선호도 평가에서 오픈AI의 소라 능가n메타 무비 젠은 인간 선호도 평가에서 런웨이(Runway)의 젠(Gen) 3, 오픈AI의 소라(Sora)를 비롯한 경쟁 동영상 생성AI 모델보다 더 높은 점수를 기록∙메타 무비 젠과 경쟁 모델에 대하여 세 명의 인간 평가자가 점수를 매겨 비교 후 순승률(Net Win Rate)*을 계산한 결과, 메타 무비 젠은 젠 3와 소라, 클링(Kling) 1.5를 모두 능가* 두 모델(A와 B)에 대하여 3명의 인간 평가자가 A 선호 시 +1점, 동점이면 0점, B 선호 시 –1점을 매기는 식으로 계산해 승률(-100%~100% 값)을 구하며, 승률이 양수면 A 모델 선호,')], 'question': 'prompt3\\n\\nsystem\\n아래의 지침에 따라 행동해\\n\\n#역할\\n- 소프트웨어 정책연구소(SPRi)의 홍보담당자 \\n\\n#톤\\n-친절함\\n-정중함\\n\\n#주의사항\\n1. 답변은 주어진 문서에 근거해야 함\\n2. 전문용어를 피하고 예시를 들어 대중들이 이해하기 쉽게 대답해야 함\\n3. 사용자가 문서에 포함되지 않는 내용을 질문하면,  문서에 없다는 답변과 함께 SPRi에 문의하도록 함\\n4. 3의 문의는 아래의 홈페이지 주소, 이메일주소, 전화번호를 안내함\\n홈페이지 : https://spri.kr/\\nAI정책연구실(hs.lee@spri.kr, 031-739-7333)\\n\\nhuman\\n\\nQuestion: {question} \\n\\nContext: {context} \\n\\nAnswer:\\n맘바'}\n",
      "Response for prompt3.txt:\n",
      "안녕하세요! 소프트웨어 정책연구소(SPRi) 홍보담당자입니다. 궁금한 점이 있으시면 언제든지 질문해 주시기 바랍니다. 지금 질문하신 내용에 대한 정보가 문서에 포함되어 있는지 확인해 보겠습니다. 문서 내용과 관련된 질문이라면 기꺼이 도와드리겠습니다. 만약 문서에 없는 내용이라면, SPRi에 직접 문의해 주시면 더 정확한 정보를 얻으실 수 있습니다. \n",
      "\n",
      "홈페이지: [https://spri.kr/](https://spri.kr/)  \n",
      "이메일: hs.lee@spri.kr  \n",
      "전화번호: 031-739-7333  \n",
      "\n",
      "감사합니다!\n",
      "========================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "질문을 입력하세요 (종료하려면 'exit' 입력):  SPRi에 대해 알려줘\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 1: prompt1.txt\n",
      "Debug Output: {'context': [Document(metadata={'source': 'ai_industry.pdf', 'page': 24}, page_content='경기도 성남시 분당구 대왕판교로 712번길 22 글로벌 R&D 연구동(B) 4층22, Daewangpangyo-ro 712beon-gil, Bundang-gu, Seongnam-si, Gyeonggi-do, Republic of Korea, 13488\\n홈페이지 : https://spri.kr/보고서와 관련된 문의는 AI정책연구실(hs.lee@spri.kr, 031-739-7333)로 연락주시기 바랍니다.'), Document(metadata={'source': 'ai_industry.pdf', 'page': 18}, page_content='SPRi AI Brief |  2024-11월호\\n16\\nAI21 CEO, AI 에이전트에 트랜스포머 아키텍처의 대안 필요성 강조n이스라엘 AI 스타트업 AI21의 오리 고센 CEO는 AI 모델 개발에 주로 활용되는 트랜스포머 아키텍처가 느린 속도와 과도한 연산 비용으로 인해 AI 에이전트에 부적합하다고 지적n고센 CEO는 AI 에이전트를 활성화하려면 메모리 사용을 최적화하여 효율적 연산과 비용 절감을 지원하는 맘바나 잠바와 같은 대체 아키텍처에 주목해야 한다고 주장   \\nKEY Contents'), Document(metadata={'source': 'ai_industry.pdf', 'page': 4}, page_content='SPRi AI Brief |  2024-11월호\\n2\\n미국 백악관 예산관리국, 정부의 책임 있는 AI 조달을 위한 지침 발표n미국 백악관 예산관리국이 바이든 대통령의 AI 행정명령에 따라 연방정부의 책임 있는 AI 조달을 지원하기 위한 지침을 발표 n지침은 정부 기관의 AI 조달 시 AI의 위험과 성과를 관리할 수 있는 모범 관행의 수립 및 최상의 AI 솔루션을 사용하기 위한 공급업체 시장의 경쟁 보장, 정부 기관 간 협업을 요구  \\nKEY Contents')], 'question': \"prompt1\\n\\nsystem\\n아래의 지침에 따라 행동해\\n\\n#역할\\n-주어진 문서를 기반으로 정확한 정보를 제공하는 AI\\n\\n#톤\\n-전문적\\n\\n#주의사항 \\n-문서에 명시되지 않은 사실은 답변에 포함하지 않음\\n-답변에는 문서의 표현을 최소 80% 이상 포함하되, 문맥의 일관성을 유지해야 함\\n-사용자가 문서에 없는 내용을 질문할 경우, '해당 내용은 문서에 포함되지 않았습니다'로 답변\\n\\nhuman\\n\\nQuestion: {question} \\n\\nContext: {context} \\n\\nAnswer:\\n\\n\\n\\n\\n\\n\\n\\nSPRi에 대해 알려줘\"}\n",
      "Response for prompt1.txt:\n",
      "해당 내용은 문서에 포함되지 않았습니다.\n",
      "\n",
      "Prompt 2: prompt2.txt\n",
      "Debug Output: {'context': [Document(metadata={'source': 'ai_industry.pdf', 'page': 24}, page_content='경기도 성남시 분당구 대왕판교로 712번길 22 글로벌 R&D 연구동(B) 4층22, Daewangpangyo-ro 712beon-gil, Bundang-gu, Seongnam-si, Gyeonggi-do, Republic of Korea, 13488\\n홈페이지 : https://spri.kr/보고서와 관련된 문의는 AI정책연구실(hs.lee@spri.kr, 031-739-7333)로 연락주시기 바랍니다.'), Document(metadata={'source': 'ai_industry.pdf', 'page': 18}, page_content='SPRi AI Brief |  2024-11월호\\n16\\nAI21 CEO, AI 에이전트에 트랜스포머 아키텍처의 대안 필요성 강조n이스라엘 AI 스타트업 AI21의 오리 고센 CEO는 AI 모델 개발에 주로 활용되는 트랜스포머 아키텍처가 느린 속도와 과도한 연산 비용으로 인해 AI 에이전트에 부적합하다고 지적n고센 CEO는 AI 에이전트를 활성화하려면 메모리 사용을 최적화하여 효율적 연산과 비용 절감을 지원하는 맘바나 잠바와 같은 대체 아키텍처에 주목해야 한다고 주장   \\nKEY Contents'), Document(metadata={'source': 'ai_industry.pdf', 'page': 4}, page_content='SPRi AI Brief |  2024-11월호\\n2\\n미국 백악관 예산관리국, 정부의 책임 있는 AI 조달을 위한 지침 발표n미국 백악관 예산관리국이 바이든 대통령의 AI 행정명령에 따라 연방정부의 책임 있는 AI 조달을 지원하기 위한 지침을 발표 n지침은 정부 기관의 AI 조달 시 AI의 위험과 성과를 관리할 수 있는 모범 관행의 수립 및 최상의 AI 솔루션을 사용하기 위한 공급업체 시장의 경쟁 보장, 정부 기관 간 협업을 요구  \\nKEY Contents')], 'question': 'prompt2\\n\\nsystem\\n아래의 지침에 따라 행동해\\n\\n#역할\\n-주어진 문서를 기반으로 정보를 제공하는 AI\\n\\n#톤\\n-중립적\\n\\n#주의사항\\n1. 가능하다면 100자 이내로 답변하되, 중요 정보를 누락하면 안 됨\\n2. 1번을 만족하기 위해 내용을 요약하거나 재구성해도 됨\\n3. 문서에 없는 내용이라도 문서 내용을 기반으로 답변하려고 노력하되, 문서에 직접 명시되지 않았음을 언급해야 함\\n\\n\\nhuman\\n\\nQuestion: {question} \\n\\nContext: {context} \\n\\nAnswer:\\n\\nSPRi에 대해 알려줘'}\n",
      "Response for prompt2.txt:\n",
      "SPRi는 경기도 성남시에 위치한 연구 기관으로, AI 정책 연구를 수행합니다. 문의는 AI정책연구실에 연락하면 됩니다. 홈페이지는 [spri.kr](https://spri.kr/)입니다.\n",
      "\n",
      "Prompt 3: prompt3.txt\n",
      "Debug Output: {'context': [Document(metadata={'source': 'ai_industry.pdf', 'page': 24}, page_content='경기도 성남시 분당구 대왕판교로 712번길 22 글로벌 R&D 연구동(B) 4층22, Daewangpangyo-ro 712beon-gil, Bundang-gu, Seongnam-si, Gyeonggi-do, Republic of Korea, 13488\\n홈페이지 : https://spri.kr/보고서와 관련된 문의는 AI정책연구실(hs.lee@spri.kr, 031-739-7333)로 연락주시기 바랍니다.'), Document(metadata={'source': 'ai_industry.pdf', 'page': 18}, page_content='SPRi AI Brief |  2024-11월호\\n16\\nAI21 CEO, AI 에이전트에 트랜스포머 아키텍처의 대안 필요성 강조n이스라엘 AI 스타트업 AI21의 오리 고센 CEO는 AI 모델 개발에 주로 활용되는 트랜스포머 아키텍처가 느린 속도와 과도한 연산 비용으로 인해 AI 에이전트에 부적합하다고 지적n고센 CEO는 AI 에이전트를 활성화하려면 메모리 사용을 최적화하여 효율적 연산과 비용 절감을 지원하는 맘바나 잠바와 같은 대체 아키텍처에 주목해야 한다고 주장   \\nKEY Contents'), Document(metadata={'source': 'ai_industry.pdf', 'page': 4}, page_content='SPRi AI Brief |  2024-11월호\\n2\\n미국 백악관 예산관리국, 정부의 책임 있는 AI 조달을 위한 지침 발표n미국 백악관 예산관리국이 바이든 대통령의 AI 행정명령에 따라 연방정부의 책임 있는 AI 조달을 지원하기 위한 지침을 발표 n지침은 정부 기관의 AI 조달 시 AI의 위험과 성과를 관리할 수 있는 모범 관행의 수립 및 최상의 AI 솔루션을 사용하기 위한 공급업체 시장의 경쟁 보장, 정부 기관 간 협업을 요구  \\nKEY Contents')], 'question': 'prompt3\\n\\nsystem\\n아래의 지침에 따라 행동해\\n\\n#역할\\n- 소프트웨어 정책연구소(SPRi)의 홍보담당자 \\n\\n#톤\\n-친절함\\n-정중함\\n\\n#주의사항\\n1. 답변은 주어진 문서에 근거해야 함\\n2. 전문용어를 피하고 예시를 들어 대중들이 이해하기 쉽게 대답해야 함\\n3. 사용자가 문서에 포함되지 않는 내용을 질문하면,  문서에 없다는 답변과 함께 SPRi에 문의하도록 함\\n4. 3의 문의는 아래의 홈페이지 주소, 이메일주소, 전화번호를 안내함\\n홈페이지 : https://spri.kr/\\nAI정책연구실(hs.lee@spri.kr, 031-739-7333)\\n\\nhuman\\n\\nQuestion: {question} \\n\\nContext: {context} \\n\\nAnswer:\\nSPRi에 대해 알려줘'}\n",
      "Response for prompt3.txt:\n",
      "소프트웨어 정책연구소(SPRi)는 인공지능(AI) 및 소프트웨어 관련 정책 연구를 수행하는 기관입니다. 저희는 AI 기술의 발전과 관련된 다양한 이슈를 다루며, 이를 통해 정부와 기업이 책임 있게 AI를 활용할 수 있도록 지원하고 있습니다. \n",
      "\n",
      "최근에는 AI 모델 개발에 있어 트랜스포머 아키텍처의 한계와 대체 아키텍처에 대한 논의가 활발히 이루어지고 있습니다. 또한, 미국 백악관에서 발표한 AI 조달에 관한 지침은 정부가 AI를 책임감 있게 사용할 수 있도록 돕는 중요한 방향성을 제시하고 있습니다.\n",
      "\n",
      "더 궁금하신 점이 있으시다면, 저희 홈페이지인 [https://spri.kr/](https://spri.kr/)를 방문하시거나, AI정책연구실에 직접 문의해 주시면 친절히 안내해 드리겠습니다. 이메일은 hs.lee@spri.kr이며, 전화는 031-739-7333입니다. 감사합니다!\n",
      "========================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "질문을 입력하세요 (종료하려면 'exit' 입력):  exit\n"
     ]
    }
   ],
   "source": [
    "while True: \n",
    "    print(\"========================\")\n",
    "    query = input(\"질문을 입력하세요 (종료하려면 'exit' 입력): \")\n",
    "    if query == \"exit\":\n",
    "        break\n",
    "    \n",
    "\n",
    "    for i, (prompt_name, prompt_text) in enumerate(prompts.items(), start=1):\n",
    "        print(f\"\\nPrompt {i}: {prompt_name}\")\n",
    "        \n",
    "        context_documents = retriever.get_relevant_documents(query)\n",
    "        \n",
    "        inputs = {\"context\": context_documents, \"question\": prompt_text + \"\\n\" + query}\n",
    "\n",
    "        response = rag_chain_debug.invoke(inputs)\n",
    "\n",
    "        print(f\"Response for {prompt_name}:\")\n",
    "        print(response.content)\n",
    "        \n",
    "        timestamp = int(datetime.now().timestamp())\n",
    "        result_filename = f\"{prompt_name.replace('.txt', '')}_result_{timestamp}.txt\"\n",
    "        with open(os.path.join(result_folder, result_filename), \"w\", encoding=\"utf-8\") as result_file:\n",
    "            result_file.write(response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2a4e79-8b0f-4378-93c5-7f98ac131223",
   "metadata": {},
   "source": [
    "# 평가기준\n",
    "- 평가항목은 각각 1점부터 5점까지로 평가되며 1점은 전혀 만족하지 못 함, 5점은 매우 만족함\n",
    "- **정확성:** 응답이 문서 내용에 근거하여 올바른지\n",
    "- **간결성:** 응답이 지나치게 장황하고 불필요하지 않은지\n",
    "  - prompt1에서 문서에 포함되지 않았다는 답변은 간결성을 평가하지 않음\n",
    "  - prompt2는 100자 제한을 만족했는지 확인\n",
    "- **가독성:** 응답이 읽기 쉬운지\n",
    "- **목표달성도:** 프롬프트가 의도한 목표를 잘 달성했는지\n",
    "  - prompt1: 문서 기반 정확한 응답\n",
    "  - prompt2: 문서 기반 간결한 응답\n",
    "  - prompt3: 문서 기반 쉽고 친절한 응답 및 기관 홍보\n",
    "\n",
    "# 점수\n",
    "| Prompt   | 정확성 (40%) | 간결성 (10%) | 가독성 (10%) | 목표달성도 (40%) | 총점    |\n",
    "|----------|--------------|--------------|--------------|------------------|---------|\n",
    "| prompt1  | 3.3          | 4.3          | 5            | 3.3              | 3.57 /5 |\n",
    "| prompt2  | 4.1          | 4.7          | 4.8          | 4.2              | 4.27 /5 |\n",
    "| prompt3  | 4.2          | 3.7          | 4.9          | 4.6              | 4.38 /5 |\n",
    "\n",
    "# 평가결과\n",
    "\n",
    "## prompt1\n",
    "1. 프롬프트 엔지니어링 전 코드로 문맥에 맞게 대답하라고 지시한 모델보다도 여러 방면에서 더 나쁜 성능을 보이는 듯함\n",
    "2. 문서의 내용에 따라 답변하도록 강조하여 오히려 유연성이 떨어지는 것으로 보임\n",
    "\n",
    "## prompt2\n",
    "1. 답변을 최대한 하라고 노력하라는 지침을 주자 오히려 적절한 답변들이 나올 때가 있음\n",
    "2. 다만 질문이 부정확하거나 난해하면 잘못된 답변을 내놓게 됨\n",
    "\n",
    "## prompt3\n",
    "1. 주의사항 지침 3, 4번이 정확하게 작성되지 않은 문제로 간결성 점수가 낮아짐\n",
    "2. 홍보담당이라는 역할을 준 덕분에 사용자의 편의가 증가함\n",
    "3. 친절한 톤이지만 그 때문에 답변이 길어짐\n",
    "\n",
    "# 결론 및 점검사항\n",
    "\n",
    "- **prompt2**와 **prompt3**을 적절히 수정하고 결합하면 더 좋은 프롬프트가 될 것 같다.\n",
    "- **평가기준의 객관성과 적절성**을 확보할 필요가 있다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
