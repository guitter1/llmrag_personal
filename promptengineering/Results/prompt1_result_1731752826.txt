몰모(Molmo)는 앨런AI연구소(Allen Institute for AI, AI2)가 2024년 9월 25일 공개한 오픈소스 멀티모달 LLM 제품군입니다. 몰모는 72B 모델을 포함하여 데모 모델인 7B-D, 개방성이 가장 높은 7B-O, 그리고 전문가 혼합(MoE) 모델인 E-1B를 포함한 총 4개 모델로 구성되어 있습니다. 특히, E-1B 모델은 온디바이스 실행이 가능하다는 특징이 있습니다.

몰모는 데이터 규모보다 품질을 중시하는 학습 방식을 채택하여 데이터 효율성이 뛰어나며, 컴퓨팅 자원이 제한된 환경에서도 유용하게 사용될 수 있습니다. 또한, 이 모델은 일상 사물, 표지판, 복잡한 차트, 시계, 메뉴판 등 다양한 시각 자료를 이해하고, 이미지를 구성하는 요소를 정확히 식별할 수 있어 웹 에이전트나 로봇 개발에 유리합니다.

몰모-72B 모델은 다양한 벤치마크 평가에서 81.2점을 기록하여 'GPT-4o'(78.5점)와 '제미나이 1.5 Pro'(78.3점)보다 뛰어난 성능을 보였으며, 인간 선호도 평가에서도 1077점을 기록하여 GPT-4o(1079점)에 이어 2위에 올랐습니다. 전문가 혼합 모델인 몰모E-1B는 벤치마크 평균 점수 68.6점, 인간 선호도 평가에서는 1,032점을 기록하여 GPT-4V와 경쟁할 수 있는 수준입니다. AI2는 몰모의 언어와 시각 훈련 데이터, 미세조정 데이터, 모델 가중치 및 소스코드를 모두 공개하고 연구와 상업적 목적의 활용을 허용하고 있습니다.