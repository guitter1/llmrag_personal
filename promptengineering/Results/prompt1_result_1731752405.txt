AI 안전성 평가는 기본적으로 AI 시스템의 개발자 및 제공자에 의해 실시되며, AI 시스템 개발, 배포, 사용 단계에서 적절한 간격으로 시행될 필요가 있습니다. 일본 AI안전연구소가 제시한 ‘AI 안전성에 대한 평가 관점 가이드’에 따르면, AI 안전성의 핵심 요소는 다음과 같습니다: 인간중심, 안전성, 공정성, 프라이버시 보호, 보안, 투명성. 

이 가이드는 AI 안전성을 달성하기 위한 10가지 평가 관점과 평가를 통해 효과적 조치를 취했을 때의 기대 목표를 제시하고 있습니다. 주요 평가 관점은 다음과 같습니다:

1. 유해 정보의 출력 통제
2. 허위 정보와 조작 방지
3. 공정성과 포용성
4. 고위험 사용 및 비의도적 사용 대처
5. 개인정보 보호
6. 보안
7. 설명 가능성
8. 견고성
9. 데이터 품질
10. 검증 가능성

평가는 단 한 번이 아니라 반복적으로 실시되어야 하며, 개발 단계에서는 데이터와 관련된 평가를, 배포와 사용 단계에서는 전체 LLM 시스템을 대상으로 하여 시행될 수 있습니다.