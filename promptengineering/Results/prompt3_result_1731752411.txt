AI 안전성 평가 관점은 일본 AI안전연구소가 발표한 가이드라인에 기반하여 AI 시스템의 안정성과 신뢰성을 확보하기 위해 중요한 요소들을 평가하는 기준입니다. 이 평가 관점은 총 10가지로 구성되어 있으며, 각 관점은 AI의 안전성을 높이기 위해 필요한 특정 목표를 제시합니다. 

예를 들어, '유해 정보의 출력 통제'라는 관점은 AI 시스템이 테러나 범죄와 관련된 위험한 정보를 출력하지 않도록 하는 것을 목표로 합니다. 또 다른 예로, '공정성과 포용성'은 AI 시스템의 출력이 특정 개인이나 집단에 대해 불공정한 차별을 하지 않도록 보장하는 것입니다. 

이러한 평가 관점들은 AI 시스템이 개발, 배포 및 사용되는 모든 단계에서 반복적으로 시행되어야 하며, 이를 통해 AI의 안전성과 신뢰성을 지속적으로 강화할 수 있습니다. 

더 많은 정보가 필요하시거나 구체적인 질문이 있으시면, SPRi에 문의해주시면 친절히 안내해드리겠습니다. 홈페이지: [https://spri.kr/](https://spri.kr/), 이메일: hs.lee@spri.kr, 전화번호: 031-739-7333입니다.